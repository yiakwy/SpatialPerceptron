{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多目标检测\n",
    "\n",
    "Author: Lei Wang (lwang11@mtu.edu)\n",
    "Date: July 15th, 2019\n",
    "\n",
    "### Synthetic Dataset (See [Mask RCNN](https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb) )\n",
    "\n",
    "对于多目标检测来说自由数据标注，难度更大，需要更专业的工具。为了克服这个问题，在小规模数据上，进行算法的实验和验证，我们可以通过合成数据集来完成带标注数据的采集，用来进行算法验证。\n",
    "\n",
    "合成数据集通常用于仿真实验，常用的方法包括标准集合形状，3D仿真渲染等。Intel® `Carla`项目于2017年首次公开虚拟仿真的实验设备：用Ureal4构建的仿真场景，动态仿真障碍物，通过模拟MVP矩阵计算的虚拟照相机。随后多个团队进行了相关工程和算法的跟进和开发，成为GAN之后，最具有希望解决大规模数据标注用于模型训练的方法之一。\n",
    "\n",
    "本文首先使用基于MaskRCNN `ShapeDataset`的`SyntheticDataset`生产数据，然后针对多目标算法重点对One-Stage, Two-Stage的检测方法在合成数据集上，进行了分析和实现，最后对街拍视频进行了实时分析。\n",
    "\n",
    "### One-Stage Algorithm\n",
    "\n",
    "单阶段检测方法，具有比较高的速度优势，非常适合实时性需求比较强的算法环境，比如高速行驶的无人车辆。通过剪枝和NAS优化，还可以达到更加小的体积和推理速度，从而非常合适在端部署。\n",
    "\n",
    "##### YoloV4: YoloV3 with various optimization\n",
    "\n",
    "##### SSD\n",
    "\n",
    "最开始的实现是在caffe上做的，我们将用Tensorflow-Keras重新实现上面的的算法，并且运用最新的优化技巧。\n",
    "\n",
    "\n",
    "### Two-Stage Algorithm\n",
    "\n",
    "\n",
    "##### Maks-RCNN (implemented in PaddlePaddle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.8/bin/python\n",
      "/home/ma-user/work\n",
      "[name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15872484967\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10469243867300329198\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:0c.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!pwd\n",
    "\n",
    "# nvidia-smi executed from modelarts notebook does not work\n",
    "# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "  local_device_protos = device_lib.list_local_devices()\n",
    "  return [device_proto for device_proto in local_device_protos if device_proto.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 15 Jul, 2016\n",
    "\n",
    "@author: wangyi\n",
    "'''\n",
    "\n",
    "import os\n",
    "# from config import cfg\n",
    "import importlib\n",
    "import global_settings\n",
    "\n",
    "ENVIRON_CONFIG = \"config\"\n",
    "\n",
    "try:\n",
    "  basestring\n",
    "except NameError:\n",
    "  basestring = str\n",
    "\n",
    "class ImproperlyConfigured(Exception): pass\n",
    "\n",
    "class Settings:\n",
    "\n",
    "    def __init__(self, custom_settings=None):\n",
    "        # update global settings\n",
    "        for setting in dir(global_settings):\n",
    "            if setting.isupper() and not setting.startswith(\"__\"):\n",
    "                setattr(self, setting, getattr(global_settings, setting))\n",
    "\n",
    "        if custom_settings is None:\n",
    "            custom_settings = os.environ.get(ENVIRON_CONFIG)\n",
    "        if custom_settings is not None and isinstance(custom_settings, basestring):\n",
    "            try:\n",
    "                custom_settings = importlib.import_module(custom_settings)\n",
    "            except Exception as ex:\n",
    "                raise ImproperlyConfigured(\"\")\n",
    "\n",
    "        self._setting_module = custom_settings\n",
    "        if custom_settings is not None:\n",
    "            self._overriden_vals = set()\n",
    "            for setting in dir(custom_settings):\n",
    "                if setting.isupper():\n",
    "                    val = getattr(custom_settings, setting)\n",
    "                    # do some checking\n",
    "\n",
    "                    # overriden\n",
    "                    setattr(self, setting, val)\n",
    "                    self._overriden_vals.add(setting)\n",
    "\n",
    "    def __str__(self):\n",
    "        ret = []\n",
    "        ret.append(\"\\nConfigurations:\\n\")\n",
    "        for setting in dir(self):\n",
    "            if setting.isupper() and not setting.startswith(\"__\"):\n",
    "                ret.append(\"{:30} {}\\n\".format(setting, getattr(self, setting)))\n",
    "        ret.append(\"\\n\")\n",
    "        return \"\".join(ret)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Setting Object: {}>\".format(self._setting_module.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Project Root\n",
    "Project_ROOT = os.path.abspath(\".\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个动态配置文件对象\n",
    "\n",
    "Python提供了descriptor framework，各种工程实践表明，将配置文件通过，局部py配置文件（因为Python本身是动态语言，可以动态加载代码），读取配置文件的加载对象来完成比较好。\n",
    "\n",
    "本例虽然是针对合成数据集做实验，但是仍然使用ImageNet作为预训练模型。因此要求输入图像至少满足`221x221`大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_SHAPE                    [221, 221, 3]\n",
      "IOU_LOSS_THRESH                0.5\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "VALIDATION_STEPS               5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adapt codes from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
    "class SyntheticDatasetConfig(Settings):\n",
    "    \"\"\"Configuration for training on the toy synthetic dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy synthetic dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "    # dims\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    # Used for our Image net pretrained model, at last to be 221x221\n",
    "    IMAGE_SHAPE = [221, 221, 3]\n",
    "    \n",
    "    # Yolo loss Threshold, used for compute confidence\n",
    "    IOU_LOSS_THRESH = 0.5\n",
    "    \n",
    "    # Anchors\n",
    "    ANCHORS = {2: [(10,13),(16,30),(33,23)],      # large objects detect anchors\n",
    "               1: [(30,61),(62,45),(59,119)],     # medium objects detect anchors\n",
    "               0: [(116,90),(156,198),(373,326)]} # smallest detect anchors\n",
    "\n",
    "config = SyntheticDatasetConfig()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 15 Jul, 2019\n",
    "\n",
    "@author: wangyi\n",
    "'''\n",
    "\n",
    "# numpy array utils. \n",
    "# warning: the utilities should accept tensors as input.\n",
    "\n",
    "def read_img(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise ValueError(\"Image path [%s] does not exist.\" % (file_path))\n",
    "    im = cv2.imread(file_path)\n",
    "    im = im.astype(np.float32, copy=False)\n",
    "    im = cv2.resize(im, (config.HEIGHT, config.WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    return im\n",
    "\n",
    "def load_images(files):\n",
    "    count = len(files)\n",
    "    X = np.ndarray((count, config.HEIGHT, config.WIDTH, config.CHANNEL), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(files):\n",
    "        image = read_img(image_file)\n",
    "        X[i] = image\n",
    "    return X\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] * (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def IoU_numeric(left_box, right_box, left_area, right_area):\n",
    "    # Compute intersection areas\n",
    "    x1 = max(left_box[0], right_box[0])\n",
    "    y1 = max(left_box[1], right_box[1])\n",
    "    x2 = min(left_box[2], right_box[2])\n",
    "    y2 = min(left_box[3], right_box[3])\n",
    "    \n",
    "    h = max(0, y2 - y1)\n",
    "    w = max(0, x2 - x1)\n",
    "    \n",
    "    overlap = float(w * h)\n",
    "    union = left_area + right_area - overlap\n",
    "    iou = overlap / union\n",
    "    return iou\n",
    "\n",
    "# Non-Max Suppression: simliar to tf.image.non_max_suppression for non-symbolic computation\n",
    "# see https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/utils.py\n",
    "def nms(boxes, scores=None, threshold=0.3):\n",
    "    \"\"\"\n",
    "    @param boxes: np.array with standard tensorflow box order, [x1, y1, x2, y2]\n",
    "    @param scores: np.array\n",
    "    @param threshold: float32\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Compute box area: (x2 - x1) * (y2 - y1)\n",
    "    area = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:,1])\n",
    "    \n",
    "    if scores is not None:\n",
    "        # Sort boxes indices by box scores\n",
    "        idx = scores.argsort()[::-1]\n",
    "    else:\n",
    "        # see https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/\n",
    "        # Sort boxes indices by bottom-right y-coordinates of bounding box\n",
    "        idx = np.argsort(boxes[:,3])\n",
    "        \n",
    "    picked = []\n",
    "    \n",
    "    while len(idx) > 0:\n",
    "        # Pick one to the list\n",
    "        i = idx[0]\n",
    "        picked.append(i)\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = np.array([IoU_numeric(boxes[i], boxes[j], area[i], area[j]) for j in idx[1:]])\n",
    "        remove_idx = np.where(ious > threshold)[0] + 1\n",
    "        # Remove indices of overlapped boxes\n",
    "        idx = np.delete(idx, remove_idx)\n",
    "        idx = np.delete(idx, 0)\n",
    "    return np.array(picked, dtype=np.int32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 20 May, 2019\n",
    "\n",
    "@author: wangyi\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# visualization toolkits\n",
    "\n",
    "def save_instances(image, boxes, masks, class_ids, class_names, scores):\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "    scores = scores or [1.0] * n_instances\n",
    "    \n",
    "    if not n_instances:\n",
    "        print(\"No instances to display!\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    out = masked_image\n",
    "    \n",
    "    for i in range(n_instances):\n",
    "        color = colors[i]\n",
    "        \n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        \n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        mask = masks[:, :, i]\n",
    "        \n",
    "        class_id = class_ids[i]\n",
    "        score = scores[i]\n",
    "        label = class_names[class_id]\n",
    "        \n",
    "        if label is not 'person':\n",
    "            continue;\n",
    "        \n",
    "        caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        \n",
    "        masked_image = apply_mask(masked_image, mask, color)\n",
    "        masked_image_with_boxes = cv2.rectangle(masked_image, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Mask Polygon\n",
    "        padded_mask = np.zeros(\n",
    "          (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8\n",
    "        )\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        # contours = find_contours(padded_mask, 0.5)\n",
    "        _, contours, _ = cv2.findContours(padded_mask, \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        masked_image_with_contours_plus_boxes = cv2.drawContours(masked_image_with_boxes, contours, -1, (0, 255, 0), 1)\n",
    "        \n",
    "        out = cv2.putText(\n",
    "            masked_image_with_contours_plus_boxes, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "\n",
    "        masked_image = out\n",
    "    return out\n",
    "\n",
    "def display(im, ax=None):\n",
    "    figsize = (16,16)\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "    height, width = im.shape[:2]\n",
    "    size = (width, height)\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(im.astype(np.uint8))\n",
    "    return ax\n",
    "    \n",
    "def set_title(ax, caption):\n",
    "    ax.set_title(caption, fontsize=9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Lei Wang\n",
    "# Date: July 15th, 2019\n",
    "# Email: lwang11@mtu.edu, lwang019@e.ntu.edu.sg, L.WANG@ntu.edu.sg, yiak.wy@gmail.com\n",
    "\n",
    "\n",
    "import os # path, directory utilities\n",
    "import cv2\n",
    "import glob # used for extract images from data_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import colorsys\n",
    "\n",
    "# @todo : TODO\n",
    "class Dataset:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self._name = name\n",
    "        self._class_names = []\n",
    "        self._data_path = None\n",
    "        self._dataset_path = None\n",
    "        self._dataset_meta = {}\n",
    "        self._images_info = []\n",
    "        \n",
    "        # used for data data augumentation\n",
    "        self._augumented = True\n",
    "        self._datagen = None\n",
    "        \n",
    "    def set_datagen(self, datagen):\n",
    "        self._datagen = datagen\n",
    "\n",
    "    def augument_data(self, data):\n",
    "        raise Exception(\"Not Implemented Yet!\")\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "\n",
    "    @property\n",
    "    def images_info(self):\n",
    "        return self._images_info\n",
    "    \n",
    "    @property\n",
    "    def data_path(self):\n",
    "        return self._data_path\n",
    "    \n",
    "    # @todo TODO\n",
    "    def add_class(self):\n",
    "        pass\n",
    "    \n",
    "    def add_image(self, source, image_id, path, **kwargs):\n",
    "        image_info = {\n",
    "            \"source\": source,\n",
    "            \"id\": image_id,\n",
    "            \"path\": path\n",
    "        }\n",
    "        image_info.update(kwargs)\n",
    "        self._images_info.append(image_info)\n",
    "\n",
    "\n",
    "class Preprocessor():\n",
    "    \n",
    "    def __init__(self, feature_wise_norm=True, ZCA_Whitening=True):\n",
    "        self._preprocessed = False\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.row_axis = 1\n",
    "        self.col_axis = 2\n",
    "        self.feature_wise_norm = feature_wise_norm\n",
    "        self.ZCA_Whitening = ZCA_Whitening\n",
    "        self.zca_epsilon = 1e-6\n",
    "        self.principle_components = None\n",
    "        \n",
    "        self.type = \"Images-Annotations\"\n",
    "        \n",
    "    def __call__(self, data, bboxes=None, masks=None, labels=None, crop=None):\n",
    "        data = data.astype('float32')\n",
    "        if  self._preprocessed is False:\n",
    "            # Feature wise normalization\n",
    "            self.mean = np.mean(data, axis=(0, self.row_axis, self.col_axis))\n",
    "            self.std = np.std(data, axis=(0, self.row_axis, self.col_axis))\n",
    "            \n",
    "            if ZCA_Whitening:\n",
    "                # ZCA Whitening，see https://arxiv.org/pdf/1512.00809.pdf\n",
    "                # There is a diverse range of methods to decorrelate input data in statistic analysis.\n",
    "                # Images, as a special configuration of a distribution are subjected to maxtrix theory.\n",
    "                # PCA and ZCA differ by a rotation.\n",
    "                # Also see keras preprocessing logics for ZCA whitening: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/image_data_generator.py\n",
    "                flat_x = np.reshape(data, (-1, np.prod(data.shape[-3:])))\n",
    "                covar = np.dot(flat_x.T, flat.x) / flat_x.shape[0]\n",
    "                import scipy\n",
    "                from scipy import linalg\n",
    "                u, sigma, _ = linalg.svd(covar)\n",
    "                sigma_inverse = 1. / np.sqrt(sigma[np.newaxis] + self.zca_epsilon)\n",
    "                self.principle_components = (u * sigma_inverse).dot(u.T)\n",
    "            \n",
    "            self._preprocessed = True\n",
    "\n",
    "        data = (data - self.mean) / (self.std + 1e-6)\n",
    "        original_shape = data.shape\n",
    "        \n",
    "        if ZCA_Whitening:\n",
    "            # @todo : TODO\n",
    "            flat_x = np.reshape(data, (-1, np.prod(data.shape[-3:])))\n",
    "            # apply zca whitening\n",
    "            embedding = np.dot(flat_x, self.principle_components)\n",
    "            data = np.reshape(embedding, data.shape)\n",
    "        \n",
    "        # scale images\n",
    "        H, W, CHANNEL = orignal_shape\n",
    "        data = data.astype(np.float32, copy=False)\n",
    "        data = cv2.resize(data, (config.HEIGHT, config.WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "        scales = (config.Height / float(H), config.WIDTH / float(W))\n",
    "        \n",
    "        annotatins = []\n",
    "        if bboxes is not None:\n",
    "            # (N, 2) * (1,2) broadcasting\n",
    "            bboxes[:, [0,2]] = bboxes[:, [0,2]] * scales[1] # Width -> x\n",
    "            bboxes[:, [1,3]] = bboxes[:, [1,3]] * scales[0] # Height -> y\n",
    "            annotations.append(bboxes)\n",
    "        if masks is not None:\n",
    "            raise Exception(\"Not Implemented Yet!\")\n",
    "        if  labels is not None:\n",
    "            labels = keras.utils.to_categorical(labels, config.NUM_CLASSES)\n",
    "            annotations.append(labels)\n",
    "        return (data, *annotations)\n",
    "\n",
    "    # @todo : TODO dumping zca components\n",
    "    def save(self, exported_path):\n",
    "        data = {\n",
    "        \"mean\": to_unicode(self.mean),\n",
    "        \"std\": to_unicode(self.std)\n",
    "        }\n",
    "        \n",
    "        with io.open(exported_path, 'w', encoding='utf8') as f:\n",
    "            dumped = json.dumps(data,\n",
    "                    indent=4, sort_keys=True,\n",
    "                    separators=(',', ': '), ensure_ascii=False)\n",
    "\n",
    "            f.write(to_unicode(dumped))\n",
    "        \n",
    "        # dump zca components\n",
    "        \n",
    "        self.principle_components.dump(\"{}/name\".format(base_dir, name))\n",
    "\n",
    "    # @todo : TODO deserialize zca components\n",
    "    @staticmethod\n",
    "    def load_from(exported_path):\n",
    "        with open(exported_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            preprocessor = Preprocessor()\n",
    "            preprocessor.mean = data['mean']\n",
    "            preprocessor.std = data['std']\n",
    "            return preprocessor\n",
    "\n",
    "\n",
    "class YoloV3AnnotationsPreprocessor()\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # to generate `y_true` used in loss of the keras model\n",
    "    # YoloV3 Losses: the key part of the detectron\n",
    "    # In practice self.anchors_per_grid == gt_per_grid makes loss easy to be expressed via tensor operations\n",
    "    #  scales = [32, 16, 8] # config\n",
    "    #  y_true = [KL.Input(shape=(int(H/scale), \n",
    "    #                            int(W/scale), \n",
    "    #                            self.anchors_per_grid, config.NUM_CLASSES+5)) for scale in scales]\n",
    "    # @todo : TODO\n",
    "    def __call__(bboxes, input_shape, anchors, num_classes):\n",
    "        y_true = []\n",
    "        return y_true\n",
    "\n",
    "    \n",
    "# adapt codes from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
    "# we want to use the generated data to train our yolov4 neural network\n",
    "class SyntheticDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mode=None, name=\"SyntheticShapes\", mask_on=True, config=None):\n",
    "        Dataset.__init__(self, name)\n",
    "        # _data_path is None\n",
    "        # _dataset_path is None\n",
    "        self._class_names = [\n",
    "            {\"source\": \"\", \"id\": 0, \"name\": \"BG\"},\n",
    "            {\"source\": \"\", \"id\": 1, \"name\": \"Square\"},\n",
    "            {\"source\": \"\", \"id\": 2, \"name\": \"Circle\"},\n",
    "            {\"source\": \"\", \"id\": 3, \"name\": \"Triangle\"}\n",
    "        ]\n",
    "        self._mode = mode # defaults to training\n",
    "        self._mask_on = mask_on\n",
    "        \n",
    "        self._RANDOM_SAMPLING_ON = True\n",
    "        self._rois = []\n",
    "        # config\n",
    "        self._config = config\n",
    "        # images preprocessor\n",
    "        self._images_preprocessor = Preprocessor()\n",
    "        # yolov3(yolov4) annotations preprocesor\n",
    "        self._annotations_preprocessor = YoloV3AnnotationsPreprocessor()\n",
    "        # data holders\n",
    "        self._train_data = None\n",
    "        self._train_annotations = None\n",
    "        self._test_data = None\n",
    "        self._test_annotations = None\n",
    "        # sampling \n",
    "        self._samplingRatio = 0.2 # The best sampling raitio ca be computd from limits (1/n)^n, where n is the total number of samples\n",
    "        self._mini_samples = 10000\n",
    "        \n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return [c[\"name\"] for c in self._class_names]\n",
    "    \n",
    "    # TODO: implement `load_${specific_name_for_the_dataset_to_be_loaded}` method\n",
    "    def load_synthetic_geometries(self, count, height, width, test_size=0.25):\n",
    "        self.count = count\n",
    "        # Add images & Rois\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_shape_rois(height, width)\n",
    "            self.add_image(\"\", image_id=i, path=None,\n",
    "                          height=height, width=width,\n",
    "                          bg_color=bg_color, shapes=shapes)\n",
    "            self.add_annotations(i)\n",
    "            \n",
    "        \n",
    "        labeled_images = self._images_info\n",
    "        rois = self._rois\n",
    "        \n",
    "        train_data, test_data, train_annotations, test_annotations = train_test_split(labeled_images, rois, test_size=test_size, random_state=10)\n",
    "        \n",
    "        self._train_data = train_data\n",
    "        self._train_annotations = train_annotations\n",
    "        self._test_data  = test_data\n",
    "        self._test_annotations  = test_annotations\n",
    "        \n",
    "        return (train_data, \n",
    "                train_annotations,\n",
    "                 test_data, \n",
    "                 test_annotations)\n",
    "        \n",
    "    def augument_data(self, data):\n",
    "        raise Exception(\"Not Implemented Yet!\")\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1,1,3]) * 255 # channel last\n",
    "        background_img = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        background_img = background_img * bg_color.astype(np.uint8)\n",
    "        image = background_img\n",
    "        for shape, color, roi in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, roi, color)\n",
    "            if self._mask_on:\n",
    "                # @todo TODO load mask: This may consume large volumne of memory\n",
    "                pass\n",
    "        return image\n",
    "    \n",
    "    def add_annotations(self, image_id):\n",
    "        boxes = self.load_bbox(image_id)\n",
    "        labels = self.load_klass(image_id)\n",
    "        self._rois.append({\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"mask\": None\n",
    "        })\n",
    "        \n",
    "    def load_klass(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        return [shape for shape, color, roi in info['shapes']]\n",
    "    \n",
    "    def load_bbox(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        return [roi for shape, color, roi in info['shapes']]\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, roi) in enumerate(shapes):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(), shape, roi, 1)\n",
    "            \n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Extract class_ids\n",
    "        class_ids = np.array([img_desc[0] for img_desc in shapes], dtype=np.int32)\n",
    "        return mask.astype(np.bool), class_ids\n",
    "    \n",
    "    def draw_shape(self, img, shape, roi, color):\n",
    "        x1, y1, x2, y2 = roi\n",
    "        centre_x = int((x1 + x2) / 2)\n",
    "        centre_y = int((y1 + y2) / 2)\n",
    "        r = int((x2 - x1) / 2)\n",
    "        \n",
    "        if hasattr(color, \"__len__\"):\n",
    "            color = list(map(lambda c: c * 255, color))\n",
    "        else:\n",
    "            color = color * 255\n",
    "        \n",
    "        # in OpenCV3, there is no cv2.CV_AA attribute, see http://bugsinmycodes.blogspot.com/2016/11/opencv3-no-attribute-name-cvaa.html\n",
    "        # Despite of choice of integer 8 as line type, I recommend you to use Anti-aliased algorithm: https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm\n",
    "        try:\n",
    "            LINE_TYPE = cv2.CV_AA\n",
    "        except:\n",
    "            LINE_TYPE = cv2.LINE_AA\n",
    "        \n",
    "        class_names = self.class_names\n",
    "        if class_names[shape] == 'Square':\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, -1, lineType=LINE_TYPE, shift=0)\n",
    "        elif class_names[shape] == 'Circle':\n",
    "            cv2.circle(img, (centre_x, centre_y), r, color, -1, lineType=LINE_TYPE, shift=0)\n",
    "        elif class_names[shape] == 'Triangle':\n",
    "            Points = np.array([[\n",
    "                                (centre_x, centre_y-r),\n",
    "                                (centre_x-r/math.sin(math.radians(60)), centre_y+r),\n",
    "                                (centre_x+r/math.sin(math.radians(60)), centre_y+r)\n",
    "                              ]], dtype=np.int32)\n",
    "            # linear scanning algorithm\n",
    "            cv2.fillPoly(img, Points, color, lineType=LINE_TYPE, shift=0)\n",
    "        return img\n",
    "    \n",
    "    # @todo TODO\n",
    "    def random_shape(self, height, width):\n",
    "        # shape\n",
    "        shape = random.choice(range(1,4))\n",
    "        # center x, y\n",
    "        radius = 20\n",
    "        y = random.randint(radius, height - radius - 1)\n",
    "        x = random.randint(radius, width - radius - 1)\n",
    "        # size\n",
    "        r = random.randint(radius, int(height / 4))\n",
    "        roi = (x-r, y-r, x+r, y+r)\n",
    "        return shape, roi\n",
    "    \n",
    "    def random_shape_rois(self, height, width, threshold=0.3):        \n",
    "        # Generate shapes and rois\n",
    "        shapes = []\n",
    "        rois = []\n",
    "        N = random.randint(1, 4)\n",
    "        # Pick a random color for background with sequence 0\n",
    "        colors = random_colors(N+1)\n",
    "        bg_color = colors[0]\n",
    "        for i in range(N):\n",
    "            shape, roi = self.random_shape(height, width)\n",
    "            shapes.append((shape, colors[i+1], roi))\n",
    "            rois.append(roi)\n",
    "            \n",
    "        # Apply Non-Max Suppression (NMS) with the threshold (defaults to 0.3) to avoid shapes covering each other\n",
    "        kept_idx = nms(np.array(rois), np.arange(N), threshold)\n",
    "        shapes = [shape for i, shape in enumerate(shapes) if i in kept_idx]\n",
    "        # \n",
    "        return bg_color, shapes\n",
    "    \n",
    "    def load_image_annotations(self, image_id, mask_on, augumented):\n",
    "        \"\"\"\n",
    "            reference: https://github.com/aleju/imgaug\n",
    "            \n",
    "            One of the most difficult things to augument an image is to obtain augumented images and the correspoinding annotations which \n",
    "            include masks, bounding boxes and labels.\n",
    "            \n",
    "            The later requires us to apply the same transfromation upon images to annotations data like masks and bounding boxes if that changes \n",
    "            the geometry of images. As for some special tasks like human face recognition, we need special data as part of annotations like key points, rotated bounding boxes. \n",
    "            \n",
    "            Transformation affects geometry\n",
    "            \n",
    "            @return (image, bbounding boxes, masks, class_ids)\n",
    "        \"\"\"\n",
    "        image = dataset.load_image(idx)\n",
    "        bboxes = dataset.load_bbox(idx)\n",
    "        \n",
    "        aug_keywords = {\n",
    "            'bounding_boxes':bbs\n",
    "        }\n",
    "        \n",
    "        if mask_on:\n",
    "            masks, class_ids = dataset.load_mask(idx)\n",
    "            aug_keywords['segmentation_maps'] = masks\n",
    "        \n",
    "        original_shape = image.shape\n",
    "        \n",
    "        image, bboxes = self._image_preprocessor(image, bboxes=bboxes)\n",
    "        if augumented:\n",
    "            import imgaug\n",
    "            from imgaug import augmenters as aug\n",
    "            from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImages\n",
    "            \n",
    "            bbs = BoundingBoxesOnImage([\n",
    "                BoundingBox(x1=bbox[0], y1=bbox[1], x2=bbox[2], y2=bbox[3]) for bbox in bboxes\n",
    "            ], shape=image.shape)\n",
    "            \n",
    "            # get maximum bounding boxes\n",
    "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "            crop_top = max_bbox[1]\n",
    "            crop_right = image.shape[1] - max_bbox[2] # Width - max_bbox.x2\n",
    "            crop_bottom = image.shape[0] - max_bbox[3] # Height - max_bbox.y2\n",
    "            crop_left = max_bbox[0]\n",
    "            \n",
    "            # set possiblity of applying augumenters \n",
    "            def sometimes(p, aug_ops):\n",
    "                return aug.Sometimes(p, aug_ops)\n",
    "            \n",
    "            aug_seq = aug.Sequential([\n",
    "                # apply filters\n",
    "                sometimes(0.2, aug.GammaContrast((0.5, 1.5))),\n",
    "                sometimes(0.2, aug.GaussianBlur((0, 3.0))),\n",
    "                \n",
    "                # flip of images\n",
    "                aug.Fliplr(0.2), # flip horizontally\n",
    "                aug.Flipud(0.1), # flip vertially\n",
    "                \n",
    "                # crop images\n",
    "                sometimes(0.2, aug.CropAndPad(\n",
    "                    px=((0, crop_top), (0, crop_right), (0, crop_bottom), (0, crop_left)),\n",
    "                    pad_mode=aug.ALL,\n",
    "                    pad_cval=(0, 128)\n",
    "                ))\n",
    "                \n",
    "                # affine transformation\n",
    "                aug.OneOf([\n",
    "                    # X translate\n",
    "                    sometimes(0.1, aug.Affine(translate_percent={\"x\": 0.1}, scale=0.8)),\n",
    "                    # Y translate\n",
    "                    sometimes(0.1, aug.Affine(translate_percent={\"y\": 0.1}, scale=0.8)),\n",
    "                    # Rotation\n",
    "                    sometimes(0.4, aug.Affine(rotate=(-5, 5))),\n",
    "                    # Shear\n",
    "                    sometimes(0.1, aug.Affine(shear=(-10, -10)))\n",
    "                ])\n",
    "                \n",
    "                # additive gausion noise\n",
    "                sometimes(0.1, aug.AdditiveGaussionNoise(scale=0.1*255))\n",
    "            ], random_order=True)\n",
    "            \n",
    "            if mask_on:\n",
    "                # make the augumentation deterministic\n",
    "                aug_seg.to_deterministic()\n",
    "            image, bboxes = aug_seq(image=image, bounding_boxes=bbs)\n",
    "            if mask_on:\n",
    "                # apply to a mask and assert the mask is with the same shape of an image\n",
    "                raise Exception(\"Not Implemented Yet!\")\n",
    "        \n",
    "        if mask_on:\n",
    "            return image, bboxes, masks, class_ids\n",
    "        else:\n",
    "            return image, bboxes, class_ids\n",
    "        \n",
    "    \n",
    "    def get_minibatch(self, images_info, batch_size):\n",
    "        \"\"\"\n",
    "        Since I am planning to use keras to train the model, the get_mini_batch function should work exactly as what \n",
    "        [ImageDataGenerator](https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L233) does.\n",
    "        The data generator will generate batches of non-symbolic tensor data with real-time data augumentation.\n",
    "    \n",
    "        It is an common mistake to use `ImageDataGenerator` with images with annotations of multiple rois because `ImageDataGenerator`\n",
    "        does not care about shape, coordiantes of annotations.\n",
    "        \n",
    "        @return python generator. Each time calling next() on it, the generator returns two lists, inputs and outputs.\n",
    "        \n",
    "        By default Keras, use fit to prepare statistcs computed from input data and use them to normalize the generted batch of data:\n",
    "        - featurewise_center: means on batch, rowaxis and column axis\n",
    "        - featurewise_std_normalization: std on batch, rowaxis and column axis\n",
    "        - zca_whiting: compute pca components\n",
    "        \n",
    "        references: https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py#L1630\n",
    "                    https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/image_data_generator.py\n",
    "                    \n",
    "        \"\"\"\n",
    "        n = len(images_info)\n",
    "        images_ids = np.array(range(n))\n",
    "        i = 0\n",
    "        # Keras requires a generator to run indefinitely\n",
    "        while True:\n",
    "            try:\n",
    "                if self._RANDOM_SAMPLING_ON and i == 0:\n",
    "                    # shuffle labeled_images and rois\n",
    "                    np.random.shuffle(images_ids)\n",
    "                    \n",
    "                image_data = []\n",
    "                bbox_data = []\n",
    "                for b in range(batch_size):\n",
    "                    # load data\n",
    "                    # @todo : TODO\n",
    "                    image, bboxes, class_ids = self.load_image_annotations(i, self._mask_on, self._augumented)\n",
    "                    # skip images without any rois\n",
    "                    if len(class_ids) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    image_data.append(image)\n",
    "                    bbox_data.append(bboxes)\n",
    "                    i = (i+1) % n\n",
    "                image_data = np.array(image_data)\n",
    "                # generate annotations used for YoloV4 model\n",
    "                y_true = self._annotations_preprocessor(bbox_data, self._config.IMAGE_SHAPE, self._config.ANCHORS, self._conifg.NUM_CLASSES)\n",
    "                # see inputs and outputs of YoloV4.get_model\n",
    "                yield [image_data, *y_true], np.zeros(batch_size)\n",
    "            except (StopIteration, KeyboardInterrupt):\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                raise(e)\n",
    "    \n",
    "    def train_reader(self):\n",
    "        \n",
    "        # Loading samples = min(self.count * self._samplingRatio, self.mini_samples)\n",
    "        samples = min(self.count * self._samplingRatio, self._mini_samples)\n",
    "        # Used for fitting data normalization assumptions\n",
    "        X_Sampled_train = np.random.choice(self._train_data, samples)\n",
    "        self._images_preprocessor(X_Sampled_train)\n",
    "        \n",
    "        def reader():\n",
    "            yield self.get_minibatch(self._train_data, self._config.BATCH_SIZE)\n",
    "        \n",
    "        return reader\n",
    "    \n",
    "    def infer_reader(self):\n",
    "        \n",
    "        def reader():\n",
    "            yield self.get_minibatch(self._test_data, self._config.BATCH_SIZE)\n",
    "        \n",
    "        return reader\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集生成测试\n",
    "\n",
    "生成数据的核心是生成需要人工标注的BBouding Box，对于需要做实例分割(Instance Segmentation)的基准真值(Ground True)，还需要生成掩码标注，可以极大的节省人力对模型进行初步训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 374 info:\n",
      "bg_color (0.0, 1.0, 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/matplotlib/figure.py:2299: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/matplotlib/figure.py:2117: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n",
      "  warnings.warn(\"This figure was using constrained_layout==True, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 320 info:\n",
      "bg_color (0.0, 0.40000000000000036, 1.0)\n",
      "images 171 info:\n",
      "bg_color (0.8000000000000007, 0.0, 1.0)\n",
      "images 281 info:\n",
      "bg_color (0.0, 1.0, 0.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = SyntheticDataset()\n",
    "dataset.load_synthetic_geometries(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "\n",
    "N = 4\n",
    "sample_idx = np.random.choice(range(dataset.count), N)\n",
    "images_info = dataset.images_info\n",
    "\n",
    "for idx in sample_idx:\n",
    "    info = images_info[idx]\n",
    "    print(\"images %s info:\" % idx)\n",
    "    print(\"bg_color\", info['bg_color'])\n",
    "    \n",
    "    image = dataset.load_image(idx)\n",
    "    boxes = dataset.load_bbox(idx)\n",
    "    \n",
    "    masks, class_ids = dataset.load_mask(idx)\n",
    "    \n",
    "    # masked_image = save_instances(image, np.array(boxes), masks, class_ids, dataset.class_names, None)\n",
    "    # display(masked_image)\n",
    "    \n",
    "    n_instances = len(class_ids)\n",
    "    cols = n_instances\n",
    "    mask_color = [1, 1, 1]\n",
    "    \n",
    "    # Since we have various of columns images for each row, \n",
    "    # https://matplotlib.org/3.1.1/tutorials/intermediate/gridspec.html\n",
    "    \n",
    "    figsize = (16, int(16 / (N+1)))\n",
    "\n",
    "    grids_kw = { \n",
    "        \"wspace\": 0.05\n",
    "    }\n",
    "    _, axes = plt.subplots(1, N+1, figsize=figsize,\n",
    "                                      constrained_layout=True,\n",
    "                                      sharey='all',\n",
    "                                      gridspec_kw=grids_kw)\n",
    "    \n",
    "    if cols == 0:\n",
    "        axes = [axes]\n",
    "    display(image, ax=axes[0])\n",
    "    set_title(axes[0], \"{} shapes: H x W = {}x{}\".format(len(info['shapes']), image.shape[0], image.shape[1]))\n",
    "        \n",
    "    for i in range(n_instances):\n",
    "        class_id = class_ids[i]\n",
    "        mask = masks[:, :, i]\n",
    "        masked_image = image.copy()\n",
    "        masked_image = apply_mask(masked_image, mask, mask_color, alpha=1.0)\n",
    "        shape_id = info['shapes'][i][0]\n",
    "        title = dataset.class_names[shape_id]\n",
    "        ax = axes[i+1]\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        ax.imshow(masked_image.astype(np.uint8), cmap=\"Blues_r\",\n",
    "                 norm=None, interpolation=None)\n",
    "    for i in range(n_instances, N):\n",
    "        ax = axes[i+1]\n",
    "        ax.axis(\"off\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YoloV4\n",
    "\n",
    "YoloV4基于YoloV3. YoloV3由imagenet主干网络，ResNet50, ResNet101, DarkNet，组成其前身是yolo, SSD, 成于Faster RCNN， MaskRCNN之后，以较快的速度、较小的模型参数适用在对推理速度，体积大小要求比较高的实时场景：比如无人车感知模块模块，IOT设备中的摄像头感知模块等。\n",
    "\n",
    "除了常用的Data Agumentation，BN，Batch-Optimizer选取等技巧，这里参考Stronger Yolov3[1]的研究成果，通过Keras给出实现（见Keras 2 tensorflow代码用于部署），重点对一下组网模块，在合成数据集进行研究。本文还参考了[2]，尤其是paddleCV[3][4], Keras-Yolov3[5], 对实现进行了改进。\n",
    "\n",
    "- ImageNet特征提取模组\n",
    "    - ResNet50\n",
    "    - Darknet\n",
    "- FPN特征尺度适配模组\n",
    "- cosine learning rate[1]\n",
    "- GIOU[2]\n",
    "\n",
    "在YoloV3输出的每一个像素在深度上，对应一组BBox：每个BBox坐标(4个自由度)，前景概率分数(Objectness)(1个自由度)，以及类别识别分数（C）。因此YoloV3是一个将分类器，回归器都用，回归的目标函数求解的目标检测模型。\n",
    "\n",
    "```\n",
    "# Didn't employ anchor in its yolo loss implementation. \n",
    "[1] https://github.com/Stinky-Tofu/Stronger-yolo/tree/master/v2\n",
    "[2] https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/?source=post_page---------------------------\n",
    "[3] https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/yolov3\n",
    "[4] http://en.paddlepaddle.org/documentation/docs/en/1.3/api/layers.html#yolov3_loss\n",
    "[5] https://github.com/qqwweee/keras-yolo3/blob/master/yolo3/model.py\n",
    "# The first yolov3 implementation. \n",
    "[6] https://github.com/ultralytics/yolov3/\n",
    "# It is actually very similar to [1]. But it didn't reference [1]'s implementation in its readme.md\n",
    "[7] https://github.com/YunYang1994/tensorflow-yolov3/blob/master/core/yolov3.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator # used for data augumentation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.engine as KE\n",
    "import keras.models as KM\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': ['n01440764', 'tench'], '1': ['n01443537', 'goldfish'], '2': ['n01484850', 'great_white_shark'], '3': ['n01491361', 'tiger_shark'], '4': ['n01494475', 'hammerhead'], '5': ['n01496331', 'electric_ray'], '6': ['n01498041', 'stingray'], '7': ['n01514668', 'cock'], '8': ['n01514859', 'hen'], '9': ['n01518878', 'ostrich'], '10': ['n01530575', 'brambling'], '11': ['n01531178', 'goldfinch'], '12': ['n01532829', 'house_finch'], '13': ['n01534433', 'junco'], '14': ['n01537544', 'indigo_bunting'], '15': ['n01558993', 'robin'], '16': ['n01560419', 'bulbul'], '17': ['n01580077', 'jay'], '18': ['n01582220', 'magpie'], '19': ['n01592084', 'chickadee'], '20': ['n01601694', 'water_ouzel'], '21': ['n01608432', 'kite'], '22': ['n01614925', 'bald_eagle'], '23': ['n01616318', 'vulture'], '24': ['n01622779', 'great_grey_owl'], '25': ['n01629819', 'European_fire_salamander'], '26': ['n01630670', 'common_newt'], '27': ['n01631663', 'eft'], '28': ['n01632458', 'spotted_salamander'], '29': ['n01632777', 'axolotl'], '30': ['n01641577', 'bullfrog'], '31': ['n01644373', 'tree_frog'], '32': ['n01644900', 'tailed_frog'], '33': ['n01664065', 'loggerhead'], '34': ['n01665541', 'leatherback_turtle'], '35': ['n01667114', 'mud_turtle'], '36': ['n01667778', 'terrapin'], '37': ['n01669191', 'box_turtle'], '38': ['n01675722', 'banded_gecko'], '39': ['n01677366', 'common_iguana'], '40': ['n01682714', 'American_chameleon'], '41': ['n01685808', 'whiptail'], '42': ['n01687978', 'agama'], '43': ['n01688243', 'frilled_lizard'], '44': ['n01689811', 'alligator_lizard'], '45': ['n01692333', 'Gila_monster'], '46': ['n01693334', 'green_lizard'], '47': ['n01694178', 'African_chameleon'], '48': ['n01695060', 'Komodo_dragon'], '49': ['n01697457', 'African_crocodile'], '50': ['n01698640', 'American_alligator'], '51': ['n01704323', 'triceratops'], '52': ['n01728572', 'thunder_snake'], '53': ['n01728920', 'ringneck_snake'], '54': ['n01729322', 'hognose_snake'], '55': ['n01729977', 'green_snake'], '56': ['n01734418', 'king_snake'], '57': ['n01735189', 'garter_snake'], '58': ['n01737021', 'water_snake'], '59': ['n01739381', 'vine_snake'], '60': ['n01740131', 'night_snake'], '61': ['n01742172', 'boa_constrictor'], '62': ['n01744401', 'rock_python'], '63': ['n01748264', 'Indian_cobra'], '64': ['n01749939', 'green_mamba'], '65': ['n01751748', 'sea_snake'], '66': ['n01753488', 'horned_viper'], '67': ['n01755581', 'diamondback'], '68': ['n01756291', 'sidewinder'], '69': ['n01768244', 'trilobite'], '70': ['n01770081', 'harvestman'], '71': ['n01770393', 'scorpion'], '72': ['n01773157', 'black_and_gold_garden_spider'], '73': ['n01773549', 'barn_spider'], '74': ['n01773797', 'garden_spider'], '75': ['n01774384', 'black_widow'], '76': ['n01774750', 'tarantula'], '77': ['n01775062', 'wolf_spider'], '78': ['n01776313', 'tick'], '79': ['n01784675', 'centipede'], '80': ['n01795545', 'black_grouse'], '81': ['n01796340', 'ptarmigan'], '82': ['n01797886', 'ruffed_grouse'], '83': ['n01798484', 'prairie_chicken'], '84': ['n01806143', 'peacock'], '85': ['n01806567', 'quail'], '86': ['n01807496', 'partridge'], '87': ['n01817953', 'African_grey'], '88': ['n01818515', 'macaw'], '89': ['n01819313', 'sulphur-crested_cockatoo'], '90': ['n01820546', 'lorikeet'], '91': ['n01824575', 'coucal'], '92': ['n01828970', 'bee_eater'], '93': ['n01829413', 'hornbill'], '94': ['n01833805', 'hummingbird'], '95': ['n01843065', 'jacamar'], '96': ['n01843383', 'toucan'], '97': ['n01847000', 'drake'], '98': ['n01855032', 'red-breasted_merganser'], '99': ['n01855672', 'goose'], '100': ['n01860187', 'black_swan'], '101': ['n01871265', 'tusker'], '102': ['n01872401', 'echidna'], '103': ['n01873310', 'platypus'], '104': ['n01877812', 'wallaby'], '105': ['n01882714', 'koala'], '106': ['n01883070', 'wombat'], '107': ['n01910747', 'jellyfish'], '108': ['n01914609', 'sea_anemone'], '109': ['n01917289', 'brain_coral'], '110': ['n01924916', 'flatworm'], '111': ['n01930112', 'nematode'], '112': ['n01943899', 'conch'], '113': ['n01944390', 'snail'], '114': ['n01945685', 'slug'], '115': ['n01950731', 'sea_slug'], '116': ['n01955084', 'chiton'], '117': ['n01968897', 'chambered_nautilus'], '118': ['n01978287', 'Dungeness_crab'], '119': ['n01978455', 'rock_crab'], '120': ['n01980166', 'fiddler_crab'], '121': ['n01981276', 'king_crab'], '122': ['n01983481', 'American_lobster'], '123': ['n01984695', 'spiny_lobster'], '124': ['n01985128', 'crayfish'], '125': ['n01986214', 'hermit_crab'], '126': ['n01990800', 'isopod'], '127': ['n02002556', 'white_stork'], '128': ['n02002724', 'black_stork'], '129': ['n02006656', 'spoonbill'], '130': ['n02007558', 'flamingo'], '131': ['n02009229', 'little_blue_heron'], '132': ['n02009912', 'American_egret'], '133': ['n02011460', 'bittern'], '134': ['n02012849', 'crane'], '135': ['n02013706', 'limpkin'], '136': ['n02017213', 'European_gallinule'], '137': ['n02018207', 'American_coot'], '138': ['n02018795', 'bustard'], '139': ['n02025239', 'ruddy_turnstone'], '140': ['n02027492', 'red-backed_sandpiper'], '141': ['n02028035', 'redshank'], '142': ['n02033041', 'dowitcher'], '143': ['n02037110', 'oystercatcher'], '144': ['n02051845', 'pelican'], '145': ['n02056570', 'king_penguin'], '146': ['n02058221', 'albatross'], '147': ['n02066245', 'grey_whale'], '148': ['n02071294', 'killer_whale'], '149': ['n02074367', 'dugong'], '150': ['n02077923', 'sea_lion'], '151': ['n02085620', 'Chihuahua'], '152': ['n02085782', 'Japanese_spaniel'], '153': ['n02085936', 'Maltese_dog'], '154': ['n02086079', 'Pekinese'], '155': ['n02086240', 'Shih-Tzu'], '156': ['n02086646', 'Blenheim_spaniel'], '157': ['n02086910', 'papillon'], '158': ['n02087046', 'toy_terrier'], '159': ['n02087394', 'Rhodesian_ridgeback'], '160': ['n02088094', 'Afghan_hound'], '161': ['n02088238', 'basset'], '162': ['n02088364', 'beagle'], '163': ['n02088466', 'bloodhound'], '164': ['n02088632', 'bluetick'], '165': ['n02089078', 'black-and-tan_coonhound'], '166': ['n02089867', 'Walker_hound'], '167': ['n02089973', 'English_foxhound'], '168': ['n02090379', 'redbone'], '169': ['n02090622', 'borzoi'], '170': ['n02090721', 'Irish_wolfhound'], '171': ['n02091032', 'Italian_greyhound'], '172': ['n02091134', 'whippet'], '173': ['n02091244', 'Ibizan_hound'], '174': ['n02091467', 'Norwegian_elkhound'], '175': ['n02091635', 'otterhound'], '176': ['n02091831', 'Saluki'], '177': ['n02092002', 'Scottish_deerhound'], '178': ['n02092339', 'Weimaraner'], '179': ['n02093256', 'Staffordshire_bullterrier'], '180': ['n02093428', 'American_Staffordshire_terrier'], '181': ['n02093647', 'Bedlington_terrier'], '182': ['n02093754', 'Border_terrier'], '183': ['n02093859', 'Kerry_blue_terrier'], '184': ['n02093991', 'Irish_terrier'], '185': ['n02094114', 'Norfolk_terrier'], '186': ['n02094258', 'Norwich_terrier'], '187': ['n02094433', 'Yorkshire_terrier'], '188': ['n02095314', 'wire-haired_fox_terrier'], '189': ['n02095570', 'Lakeland_terrier'], '190': ['n02095889', 'Sealyham_terrier'], '191': ['n02096051', 'Airedale'], '192': ['n02096177', 'cairn'], '193': ['n02096294', 'Australian_terrier'], '194': ['n02096437', 'Dandie_Dinmont'], '195': ['n02096585', 'Boston_bull'], '196': ['n02097047', 'miniature_schnauzer'], '197': ['n02097130', 'giant_schnauzer'], '198': ['n02097209', 'standard_schnauzer'], '199': ['n02097298', 'Scotch_terrier'], '200': ['n02097474', 'Tibetan_terrier'], '201': ['n02097658', 'silky_terrier'], '202': ['n02098105', 'soft-coated_wheaten_terrier'], '203': ['n02098286', 'West_Highland_white_terrier'], '204': ['n02098413', 'Lhasa'], '205': ['n02099267', 'flat-coated_retriever'], '206': ['n02099429', 'curly-coated_retriever'], '207': ['n02099601', 'golden_retriever'], '208': ['n02099712', 'Labrador_retriever'], '209': ['n02099849', 'Chesapeake_Bay_retriever'], '210': ['n02100236', 'German_short-haired_pointer'], '211': ['n02100583', 'vizsla'], '212': ['n02100735', 'English_setter'], '213': ['n02100877', 'Irish_setter'], '214': ['n02101006', 'Gordon_setter'], '215': ['n02101388', 'Brittany_spaniel'], '216': ['n02101556', 'clumber'], '217': ['n02102040', 'English_springer'], '218': ['n02102177', 'Welsh_springer_spaniel'], '219': ['n02102318', 'cocker_spaniel'], '220': ['n02102480', 'Sussex_spaniel'], '221': ['n02102973', 'Irish_water_spaniel'], '222': ['n02104029', 'kuvasz'], '223': ['n02104365', 'schipperke'], '224': ['n02105056', 'groenendael'], '225': ['n02105162', 'malinois'], '226': ['n02105251', 'briard'], '227': ['n02105412', 'kelpie'], '228': ['n02105505', 'komondor'], '229': ['n02105641', 'Old_English_sheepdog'], '230': ['n02105855', 'Shetland_sheepdog'], '231': ['n02106030', 'collie'], '232': ['n02106166', 'Border_collie'], '233': ['n02106382', 'Bouvier_des_Flandres'], '234': ['n02106550', 'Rottweiler'], '235': ['n02106662', 'German_shepherd'], '236': ['n02107142', 'Doberman'], '237': ['n02107312', 'miniature_pinscher'], '238': ['n02107574', 'Greater_Swiss_Mountain_dog'], '239': ['n02107683', 'Bernese_mountain_dog'], '240': ['n02107908', 'Appenzeller'], '241': ['n02108000', 'EntleBucher'], '242': ['n02108089', 'boxer'], '243': ['n02108422', 'bull_mastiff'], '244': ['n02108551', 'Tibetan_mastiff'], '245': ['n02108915', 'French_bulldog'], '246': ['n02109047', 'Great_Dane'], '247': ['n02109525', 'Saint_Bernard'], '248': ['n02109961', 'Eskimo_dog'], '249': ['n02110063', 'malamute'], '250': ['n02110185', 'Siberian_husky'], '251': ['n02110341', 'dalmatian'], '252': ['n02110627', 'affenpinscher'], '253': ['n02110806', 'basenji'], '254': ['n02110958', 'pug'], '255': ['n02111129', 'Leonberg'], '256': ['n02111277', 'Newfoundland'], '257': ['n02111500', 'Great_Pyrenees'], '258': ['n02111889', 'Samoyed'], '259': ['n02112018', 'Pomeranian'], '260': ['n02112137', 'chow'], '261': ['n02112350', 'keeshond'], '262': ['n02112706', 'Brabancon_griffon'], '263': ['n02113023', 'Pembroke'], '264': ['n02113186', 'Cardigan'], '265': ['n02113624', 'toy_poodle'], '266': ['n02113712', 'miniature_poodle'], '267': ['n02113799', 'standard_poodle'], '268': ['n02113978', 'Mexican_hairless'], '269': ['n02114367', 'timber_wolf'], '270': ['n02114548', 'white_wolf'], '271': ['n02114712', 'red_wolf'], '272': ['n02114855', 'coyote'], '273': ['n02115641', 'dingo'], '274': ['n02115913', 'dhole'], '275': ['n02116738', 'African_hunting_dog'], '276': ['n02117135', 'hyena'], '277': ['n02119022', 'red_fox'], '278': ['n02119789', 'kit_fox'], '279': ['n02120079', 'Arctic_fox'], '280': ['n02120505', 'grey_fox'], '281': ['n02123045', 'tabby'], '282': ['n02123159', 'tiger_cat'], '283': ['n02123394', 'Persian_cat'], '284': ['n02123597', 'Siamese_cat'], '285': ['n02124075', 'Egyptian_cat'], '286': ['n02125311', 'cougar'], '287': ['n02127052', 'lynx'], '288': ['n02128385', 'leopard'], '289': ['n02128757', 'snow_leopard'], '290': ['n02128925', 'jaguar'], '291': ['n02129165', 'lion'], '292': ['n02129604', 'tiger'], '293': ['n02130308', 'cheetah'], '294': ['n02132136', 'brown_bear'], '295': ['n02133161', 'American_black_bear'], '296': ['n02134084', 'ice_bear'], '297': ['n02134418', 'sloth_bear'], '298': ['n02137549', 'mongoose'], '299': ['n02138441', 'meerkat'], '300': ['n02165105', 'tiger_beetle'], '301': ['n02165456', 'ladybug'], '302': ['n02167151', 'ground_beetle'], '303': ['n02168699', 'long-horned_beetle'], '304': ['n02169497', 'leaf_beetle'], '305': ['n02172182', 'dung_beetle'], '306': ['n02174001', 'rhinoceros_beetle'], '307': ['n02177972', 'weevil'], '308': ['n02190166', 'fly'], '309': ['n02206856', 'bee'], '310': ['n02219486', 'ant'], '311': ['n02226429', 'grasshopper'], '312': ['n02229544', 'cricket'], '313': ['n02231487', 'walking_stick'], '314': ['n02233338', 'cockroach'], '315': ['n02236044', 'mantis'], '316': ['n02256656', 'cicada'], '317': ['n02259212', 'leafhopper'], '318': ['n02264363', 'lacewing'], '319': ['n02268443', 'dragonfly'], '320': ['n02268853', 'damselfly'], '321': ['n02276258', 'admiral'], '322': ['n02277742', 'ringlet'], '323': ['n02279972', 'monarch'], '324': ['n02280649', 'cabbage_butterfly'], '325': ['n02281406', 'sulphur_butterfly'], '326': ['n02281787', 'lycaenid'], '327': ['n02317335', 'starfish'], '328': ['n02319095', 'sea_urchin'], '329': ['n02321529', 'sea_cucumber'], '330': ['n02325366', 'wood_rabbit'], '331': ['n02326432', 'hare'], '332': ['n02328150', 'Angora'], '333': ['n02342885', 'hamster'], '334': ['n02346627', 'porcupine'], '335': ['n02356798', 'fox_squirrel'], '336': ['n02361337', 'marmot'], '337': ['n02363005', 'beaver'], '338': ['n02364673', 'guinea_pig'], '339': ['n02389026', 'sorrel'], '340': ['n02391049', 'zebra'], '341': ['n02395406', 'hog'], '342': ['n02396427', 'wild_boar'], '343': ['n02397096', 'warthog'], '344': ['n02398521', 'hippopotamus'], '345': ['n02403003', 'ox'], '346': ['n02408429', 'water_buffalo'], '347': ['n02410509', 'bison'], '348': ['n02412080', 'ram'], '349': ['n02415577', 'bighorn'], '350': ['n02417914', 'ibex'], '351': ['n02422106', 'hartebeest'], '352': ['n02422699', 'impala'], '353': ['n02423022', 'gazelle'], '354': ['n02437312', 'Arabian_camel'], '355': ['n02437616', 'llama'], '356': ['n02441942', 'weasel'], '357': ['n02442845', 'mink'], '358': ['n02443114', 'polecat'], '359': ['n02443484', 'black-footed_ferret'], '360': ['n02444819', 'otter'], '361': ['n02445715', 'skunk'], '362': ['n02447366', 'badger'], '363': ['n02454379', 'armadillo'], '364': ['n02457408', 'three-toed_sloth'], '365': ['n02480495', 'orangutan'], '366': ['n02480855', 'gorilla'], '367': ['n02481823', 'chimpanzee'], '368': ['n02483362', 'gibbon'], '369': ['n02483708', 'siamang'], '370': ['n02484975', 'guenon'], '371': ['n02486261', 'patas'], '372': ['n02486410', 'baboon'], '373': ['n02487347', 'macaque'], '374': ['n02488291', 'langur'], '375': ['n02488702', 'colobus'], '376': ['n02489166', 'proboscis_monkey'], '377': ['n02490219', 'marmoset'], '378': ['n02492035', 'capuchin'], '379': ['n02492660', 'howler_monkey'], '380': ['n02493509', 'titi'], '381': ['n02493793', 'spider_monkey'], '382': ['n02494079', 'squirrel_monkey'], '383': ['n02497673', 'Madagascar_cat'], '384': ['n02500267', 'indri'], '385': ['n02504013', 'Indian_elephant'], '386': ['n02504458', 'African_elephant'], '387': ['n02509815', 'lesser_panda'], '388': ['n02510455', 'giant_panda'], '389': ['n02514041', 'barracouta'], '390': ['n02526121', 'eel'], '391': ['n02536864', 'coho'], '392': ['n02606052', 'rock_beauty'], '393': ['n02607072', 'anemone_fish'], '394': ['n02640242', 'sturgeon'], '395': ['n02641379', 'gar'], '396': ['n02643566', 'lionfish'], '397': ['n02655020', 'puffer'], '398': ['n02666196', 'abacus'], '399': ['n02667093', 'abaya'], '400': ['n02669723', 'academic_gown'], '401': ['n02672831', 'accordion'], '402': ['n02676566', 'acoustic_guitar'], '403': ['n02687172', 'aircraft_carrier'], '404': ['n02690373', 'airliner'], '405': ['n02692877', 'airship'], '406': ['n02699494', 'altar'], '407': ['n02701002', 'ambulance'], '408': ['n02704792', 'amphibian'], '409': ['n02708093', 'analog_clock'], '410': ['n02727426', 'apiary'], '411': ['n02730930', 'apron'], '412': ['n02747177', 'ashcan'], '413': ['n02749479', 'assault_rifle'], '414': ['n02769748', 'backpack'], '415': ['n02776631', 'bakery'], '416': ['n02777292', 'balance_beam'], '417': ['n02782093', 'balloon'], '418': ['n02783161', 'ballpoint'], '419': ['n02786058', 'Band_Aid'], '420': ['n02787622', 'banjo'], '421': ['n02788148', 'bannister'], '422': ['n02790996', 'barbell'], '423': ['n02791124', 'barber_chair'], '424': ['n02791270', 'barbershop'], '425': ['n02793495', 'barn'], '426': ['n02794156', 'barometer'], '427': ['n02795169', 'barrel'], '428': ['n02797295', 'barrow'], '429': ['n02799071', 'baseball'], '430': ['n02802426', 'basketball'], '431': ['n02804414', 'bassinet'], '432': ['n02804610', 'bassoon'], '433': ['n02807133', 'bathing_cap'], '434': ['n02808304', 'bath_towel'], '435': ['n02808440', 'bathtub'], '436': ['n02814533', 'beach_wagon'], '437': ['n02814860', 'beacon'], '438': ['n02815834', 'beaker'], '439': ['n02817516', 'bearskin'], '440': ['n02823428', 'beer_bottle'], '441': ['n02823750', 'beer_glass'], '442': ['n02825657', 'bell_cote'], '443': ['n02834397', 'bib'], '444': ['n02835271', 'bicycle-built-for-two'], '445': ['n02837789', 'bikini'], '446': ['n02840245', 'binder'], '447': ['n02841315', 'binoculars'], '448': ['n02843684', 'birdhouse'], '449': ['n02859443', 'boathouse'], '450': ['n02860847', 'bobsled'], '451': ['n02865351', 'bolo_tie'], '452': ['n02869837', 'bonnet'], '453': ['n02870880', 'bookcase'], '454': ['n02871525', 'bookshop'], '455': ['n02877765', 'bottlecap'], '456': ['n02879718', 'bow'], '457': ['n02883205', 'bow_tie'], '458': ['n02892201', 'brass'], '459': ['n02892767', 'brassiere'], '460': ['n02894605', 'breakwater'], '461': ['n02895154', 'breastplate'], '462': ['n02906734', 'broom'], '463': ['n02909870', 'bucket'], '464': ['n02910353', 'buckle'], '465': ['n02916936', 'bulletproof_vest'], '466': ['n02917067', 'bullet_train'], '467': ['n02927161', 'butcher_shop'], '468': ['n02930766', 'cab'], '469': ['n02939185', 'caldron'], '470': ['n02948072', 'candle'], '471': ['n02950826', 'cannon'], '472': ['n02951358', 'canoe'], '473': ['n02951585', 'can_opener'], '474': ['n02963159', 'cardigan'], '475': ['n02965783', 'car_mirror'], '476': ['n02966193', 'carousel'], '477': ['n02966687', \"carpenter's_kit\"], '478': ['n02971356', 'carton'], '479': ['n02974003', 'car_wheel'], '480': ['n02977058', 'cash_machine'], '481': ['n02978881', 'cassette'], '482': ['n02979186', 'cassette_player'], '483': ['n02980441', 'castle'], '484': ['n02981792', 'catamaran'], '485': ['n02988304', 'CD_player'], '486': ['n02992211', 'cello'], '487': ['n02992529', 'cellular_telephone'], '488': ['n02999410', 'chain'], '489': ['n03000134', 'chainlink_fence'], '490': ['n03000247', 'chain_mail'], '491': ['n03000684', 'chain_saw'], '492': ['n03014705', 'chest'], '493': ['n03016953', 'chiffonier'], '494': ['n03017168', 'chime'], '495': ['n03018349', 'china_cabinet'], '496': ['n03026506', 'Christmas_stocking'], '497': ['n03028079', 'church'], '498': ['n03032252', 'cinema'], '499': ['n03041632', 'cleaver'], '500': ['n03042490', 'cliff_dwelling'], '501': ['n03045698', 'cloak'], '502': ['n03047690', 'clog'], '503': ['n03062245', 'cocktail_shaker'], '504': ['n03063599', 'coffee_mug'], '505': ['n03063689', 'coffeepot'], '506': ['n03065424', 'coil'], '507': ['n03075370', 'combination_lock'], '508': ['n03085013', 'computer_keyboard'], '509': ['n03089624', 'confectionery'], '510': ['n03095699', 'container_ship'], '511': ['n03100240', 'convertible'], '512': ['n03109150', 'corkscrew'], '513': ['n03110669', 'cornet'], '514': ['n03124043', 'cowboy_boot'], '515': ['n03124170', 'cowboy_hat'], '516': ['n03125729', 'cradle'], '517': ['n03126707', 'crane'], '518': ['n03127747', 'crash_helmet'], '519': ['n03127925', 'crate'], '520': ['n03131574', 'crib'], '521': ['n03133878', 'Crock_Pot'], '522': ['n03134739', 'croquet_ball'], '523': ['n03141823', 'crutch'], '524': ['n03146219', 'cuirass'], '525': ['n03160309', 'dam'], '526': ['n03179701', 'desk'], '527': ['n03180011', 'desktop_computer'], '528': ['n03187595', 'dial_telephone'], '529': ['n03188531', 'diaper'], '530': ['n03196217', 'digital_clock'], '531': ['n03197337', 'digital_watch'], '532': ['n03201208', 'dining_table'], '533': ['n03207743', 'dishrag'], '534': ['n03207941', 'dishwasher'], '535': ['n03208938', 'disk_brake'], '536': ['n03216828', 'dock'], '537': ['n03218198', 'dogsled'], '538': ['n03220513', 'dome'], '539': ['n03223299', 'doormat'], '540': ['n03240683', 'drilling_platform'], '541': ['n03249569', 'drum'], '542': ['n03250847', 'drumstick'], '543': ['n03255030', 'dumbbell'], '544': ['n03259280', 'Dutch_oven'], '545': ['n03271574', 'electric_fan'], '546': ['n03272010', 'electric_guitar'], '547': ['n03272562', 'electric_locomotive'], '548': ['n03290653', 'entertainment_center'], '549': ['n03291819', 'envelope'], '550': ['n03297495', 'espresso_maker'], '551': ['n03314780', 'face_powder'], '552': ['n03325584', 'feather_boa'], '553': ['n03337140', 'file'], '554': ['n03344393', 'fireboat'], '555': ['n03345487', 'fire_engine'], '556': ['n03347037', 'fire_screen'], '557': ['n03355925', 'flagpole'], '558': ['n03372029', 'flute'], '559': ['n03376595', 'folding_chair'], '560': ['n03379051', 'football_helmet'], '561': ['n03384352', 'forklift'], '562': ['n03388043', 'fountain'], '563': ['n03388183', 'fountain_pen'], '564': ['n03388549', 'four-poster'], '565': ['n03393912', 'freight_car'], '566': ['n03394916', 'French_horn'], '567': ['n03400231', 'frying_pan'], '568': ['n03404251', 'fur_coat'], '569': ['n03417042', 'garbage_truck'], '570': ['n03424325', 'gasmask'], '571': ['n03425413', 'gas_pump'], '572': ['n03443371', 'goblet'], '573': ['n03444034', 'go-kart'], '574': ['n03445777', 'golf_ball'], '575': ['n03445924', 'golfcart'], '576': ['n03447447', 'gondola'], '577': ['n03447721', 'gong'], '578': ['n03450230', 'gown'], '579': ['n03452741', 'grand_piano'], '580': ['n03457902', 'greenhouse'], '581': ['n03459775', 'grille'], '582': ['n03461385', 'grocery_store'], '583': ['n03467068', 'guillotine'], '584': ['n03476684', 'hair_slide'], '585': ['n03476991', 'hair_spray'], '586': ['n03478589', 'half_track'], '587': ['n03481172', 'hammer'], '588': ['n03482405', 'hamper'], '589': ['n03483316', 'hand_blower'], '590': ['n03485407', 'hand-held_computer'], '591': ['n03485794', 'handkerchief'], '592': ['n03492542', 'hard_disc'], '593': ['n03494278', 'harmonica'], '594': ['n03495258', 'harp'], '595': ['n03496892', 'harvester'], '596': ['n03498962', 'hatchet'], '597': ['n03527444', 'holster'], '598': ['n03529860', 'home_theater'], '599': ['n03530642', 'honeycomb'], '600': ['n03532672', 'hook'], '601': ['n03534580', 'hoopskirt'], '602': ['n03535780', 'horizontal_bar'], '603': ['n03538406', 'horse_cart'], '604': ['n03544143', 'hourglass'], '605': ['n03584254', 'iPod'], '606': ['n03584829', 'iron'], '607': ['n03590841', \"jack-o'-lantern\"], '608': ['n03594734', 'jean'], '609': ['n03594945', 'jeep'], '610': ['n03595614', 'jersey'], '611': ['n03598930', 'jigsaw_puzzle'], '612': ['n03599486', 'jinrikisha'], '613': ['n03602883', 'joystick'], '614': ['n03617480', 'kimono'], '615': ['n03623198', 'knee_pad'], '616': ['n03627232', 'knot'], '617': ['n03630383', 'lab_coat'], '618': ['n03633091', 'ladle'], '619': ['n03637318', 'lampshade'], '620': ['n03642806', 'laptop'], '621': ['n03649909', 'lawn_mower'], '622': ['n03657121', 'lens_cap'], '623': ['n03658185', 'letter_opener'], '624': ['n03661043', 'library'], '625': ['n03662601', 'lifeboat'], '626': ['n03666591', 'lighter'], '627': ['n03670208', 'limousine'], '628': ['n03673027', 'liner'], '629': ['n03676483', 'lipstick'], '630': ['n03680355', 'Loafer'], '631': ['n03690938', 'lotion'], '632': ['n03691459', 'loudspeaker'], '633': ['n03692522', 'loupe'], '634': ['n03697007', 'lumbermill'], '635': ['n03706229', 'magnetic_compass'], '636': ['n03709823', 'mailbag'], '637': ['n03710193', 'mailbox'], '638': ['n03710637', 'maillot'], '639': ['n03710721', 'maillot'], '640': ['n03717622', 'manhole_cover'], '641': ['n03720891', 'maraca'], '642': ['n03721384', 'marimba'], '643': ['n03724870', 'mask'], '644': ['n03729826', 'matchstick'], '645': ['n03733131', 'maypole'], '646': ['n03733281', 'maze'], '647': ['n03733805', 'measuring_cup'], '648': ['n03742115', 'medicine_chest'], '649': ['n03743016', 'megalith'], '650': ['n03759954', 'microphone'], '651': ['n03761084', 'microwave'], '652': ['n03763968', 'military_uniform'], '653': ['n03764736', 'milk_can'], '654': ['n03769881', 'minibus'], '655': ['n03770439', 'miniskirt'], '656': ['n03770679', 'minivan'], '657': ['n03773504', 'missile'], '658': ['n03775071', 'mitten'], '659': ['n03775546', 'mixing_bowl'], '660': ['n03776460', 'mobile_home'], '661': ['n03777568', 'Model_T'], '662': ['n03777754', 'modem'], '663': ['n03781244', 'monastery'], '664': ['n03782006', 'monitor'], '665': ['n03785016', 'moped'], '666': ['n03786901', 'mortar'], '667': ['n03787032', 'mortarboard'], '668': ['n03788195', 'mosque'], '669': ['n03788365', 'mosquito_net'], '670': ['n03791053', 'motor_scooter'], '671': ['n03792782', 'mountain_bike'], '672': ['n03792972', 'mountain_tent'], '673': ['n03793489', 'mouse'], '674': ['n03794056', 'mousetrap'], '675': ['n03796401', 'moving_van'], '676': ['n03803284', 'muzzle'], '677': ['n03804744', 'nail'], '678': ['n03814639', 'neck_brace'], '679': ['n03814906', 'necklace'], '680': ['n03825788', 'nipple'], '681': ['n03832673', 'notebook'], '682': ['n03837869', 'obelisk'], '683': ['n03838899', 'oboe'], '684': ['n03840681', 'ocarina'], '685': ['n03841143', 'odometer'], '686': ['n03843555', 'oil_filter'], '687': ['n03854065', 'organ'], '688': ['n03857828', 'oscilloscope'], '689': ['n03866082', 'overskirt'], '690': ['n03868242', 'oxcart'], '691': ['n03868863', 'oxygen_mask'], '692': ['n03871628', 'packet'], '693': ['n03873416', 'paddle'], '694': ['n03874293', 'paddlewheel'], '695': ['n03874599', 'padlock'], '696': ['n03876231', 'paintbrush'], '697': ['n03877472', 'pajama'], '698': ['n03877845', 'palace'], '699': ['n03884397', 'panpipe'], '700': ['n03887697', 'paper_towel'], '701': ['n03888257', 'parachute'], '702': ['n03888605', 'parallel_bars'], '703': ['n03891251', 'park_bench'], '704': ['n03891332', 'parking_meter'], '705': ['n03895866', 'passenger_car'], '706': ['n03899768', 'patio'], '707': ['n03902125', 'pay-phone'], '708': ['n03903868', 'pedestal'], '709': ['n03908618', 'pencil_box'], '710': ['n03908714', 'pencil_sharpener'], '711': ['n03916031', 'perfume'], '712': ['n03920288', 'Petri_dish'], '713': ['n03924679', 'photocopier'], '714': ['n03929660', 'pick'], '715': ['n03929855', 'pickelhaube'], '716': ['n03930313', 'picket_fence'], '717': ['n03930630', 'pickup'], '718': ['n03933933', 'pier'], '719': ['n03935335', 'piggy_bank'], '720': ['n03937543', 'pill_bottle'], '721': ['n03938244', 'pillow'], '722': ['n03942813', 'ping-pong_ball'], '723': ['n03944341', 'pinwheel'], '724': ['n03947888', 'pirate'], '725': ['n03950228', 'pitcher'], '726': ['n03954731', 'plane'], '727': ['n03956157', 'planetarium'], '728': ['n03958227', 'plastic_bag'], '729': ['n03961711', 'plate_rack'], '730': ['n03967562', 'plow'], '731': ['n03970156', 'plunger'], '732': ['n03976467', 'Polaroid_camera'], '733': ['n03976657', 'pole'], '734': ['n03977966', 'police_van'], '735': ['n03980874', 'poncho'], '736': ['n03982430', 'pool_table'], '737': ['n03983396', 'pop_bottle'], '738': ['n03991062', 'pot'], '739': ['n03992509', \"potter's_wheel\"], '740': ['n03995372', 'power_drill'], '741': ['n03998194', 'prayer_rug'], '742': ['n04004767', 'printer'], '743': ['n04005630', 'prison'], '744': ['n04008634', 'projectile'], '745': ['n04009552', 'projector'], '746': ['n04019541', 'puck'], '747': ['n04023962', 'punching_bag'], '748': ['n04026417', 'purse'], '749': ['n04033901', 'quill'], '750': ['n04033995', 'quilt'], '751': ['n04037443', 'racer'], '752': ['n04039381', 'racket'], '753': ['n04040759', 'radiator'], '754': ['n04041544', 'radio'], '755': ['n04044716', 'radio_telescope'], '756': ['n04049303', 'rain_barrel'], '757': ['n04065272', 'recreational_vehicle'], '758': ['n04067472', 'reel'], '759': ['n04069434', 'reflex_camera'], '760': ['n04070727', 'refrigerator'], '761': ['n04074963', 'remote_control'], '762': ['n04081281', 'restaurant'], '763': ['n04086273', 'revolver'], '764': ['n04090263', 'rifle'], '765': ['n04099969', 'rocking_chair'], '766': ['n04111531', 'rotisserie'], '767': ['n04116512', 'rubber_eraser'], '768': ['n04118538', 'rugby_ball'], '769': ['n04118776', 'rule'], '770': ['n04120489', 'running_shoe'], '771': ['n04125021', 'safe'], '772': ['n04127249', 'safety_pin'], '773': ['n04131690', 'saltshaker'], '774': ['n04133789', 'sandal'], '775': ['n04136333', 'sarong'], '776': ['n04141076', 'sax'], '777': ['n04141327', 'scabbard'], '778': ['n04141975', 'scale'], '779': ['n04146614', 'school_bus'], '780': ['n04147183', 'schooner'], '781': ['n04149813', 'scoreboard'], '782': ['n04152593', 'screen'], '783': ['n04153751', 'screw'], '784': ['n04154565', 'screwdriver'], '785': ['n04162706', 'seat_belt'], '786': ['n04179913', 'sewing_machine'], '787': ['n04192698', 'shield'], '788': ['n04200800', 'shoe_shop'], '789': ['n04201297', 'shoji'], '790': ['n04204238', 'shopping_basket'], '791': ['n04204347', 'shopping_cart'], '792': ['n04208210', 'shovel'], '793': ['n04209133', 'shower_cap'], '794': ['n04209239', 'shower_curtain'], '795': ['n04228054', 'ski'], '796': ['n04229816', 'ski_mask'], '797': ['n04235860', 'sleeping_bag'], '798': ['n04238763', 'slide_rule'], '799': ['n04239074', 'sliding_door'], '800': ['n04243546', 'slot'], '801': ['n04251144', 'snorkel'], '802': ['n04252077', 'snowmobile'], '803': ['n04252225', 'snowplow'], '804': ['n04254120', 'soap_dispenser'], '805': ['n04254680', 'soccer_ball'], '806': ['n04254777', 'sock'], '807': ['n04258138', 'solar_dish'], '808': ['n04259630', 'sombrero'], '809': ['n04263257', 'soup_bowl'], '810': ['n04264628', 'space_bar'], '811': ['n04265275', 'space_heater'], '812': ['n04266014', 'space_shuttle'], '813': ['n04270147', 'spatula'], '814': ['n04273569', 'speedboat'], '815': ['n04275548', 'spider_web'], '816': ['n04277352', 'spindle'], '817': ['n04285008', 'sports_car'], '818': ['n04286575', 'spotlight'], '819': ['n04296562', 'stage'], '820': ['n04310018', 'steam_locomotive'], '821': ['n04311004', 'steel_arch_bridge'], '822': ['n04311174', 'steel_drum'], '823': ['n04317175', 'stethoscope'], '824': ['n04325704', 'stole'], '825': ['n04326547', 'stone_wall'], '826': ['n04328186', 'stopwatch'], '827': ['n04330267', 'stove'], '828': ['n04332243', 'strainer'], '829': ['n04335435', 'streetcar'], '830': ['n04336792', 'stretcher'], '831': ['n04344873', 'studio_couch'], '832': ['n04346328', 'stupa'], '833': ['n04347754', 'submarine'], '834': ['n04350905', 'suit'], '835': ['n04355338', 'sundial'], '836': ['n04355933', 'sunglass'], '837': ['n04356056', 'sunglasses'], '838': ['n04357314', 'sunscreen'], '839': ['n04366367', 'suspension_bridge'], '840': ['n04367480', 'swab'], '841': ['n04370456', 'sweatshirt'], '842': ['n04371430', 'swimming_trunks'], '843': ['n04371774', 'swing'], '844': ['n04372370', 'switch'], '845': ['n04376876', 'syringe'], '846': ['n04380533', 'table_lamp'], '847': ['n04389033', 'tank'], '848': ['n04392985', 'tape_player'], '849': ['n04398044', 'teapot'], '850': ['n04399382', 'teddy'], '851': ['n04404412', 'television'], '852': ['n04409515', 'tennis_ball'], '853': ['n04417672', 'thatch'], '854': ['n04418357', 'theater_curtain'], '855': ['n04423845', 'thimble'], '856': ['n04428191', 'thresher'], '857': ['n04429376', 'throne'], '858': ['n04435653', 'tile_roof'], '859': ['n04442312', 'toaster'], '860': ['n04443257', 'tobacco_shop'], '861': ['n04447861', 'toilet_seat'], '862': ['n04456115', 'torch'], '863': ['n04458633', 'totem_pole'], '864': ['n04461696', 'tow_truck'], '865': ['n04462240', 'toyshop'], '866': ['n04465501', 'tractor'], '867': ['n04467665', 'trailer_truck'], '868': ['n04476259', 'tray'], '869': ['n04479046', 'trench_coat'], '870': ['n04482393', 'tricycle'], '871': ['n04483307', 'trimaran'], '872': ['n04485082', 'tripod'], '873': ['n04486054', 'triumphal_arch'], '874': ['n04487081', 'trolleybus'], '875': ['n04487394', 'trombone'], '876': ['n04493381', 'tub'], '877': ['n04501370', 'turnstile'], '878': ['n04505470', 'typewriter_keyboard'], '879': ['n04507155', 'umbrella'], '880': ['n04509417', 'unicycle'], '881': ['n04515003', 'upright'], '882': ['n04517823', 'vacuum'], '883': ['n04522168', 'vase'], '884': ['n04523525', 'vault'], '885': ['n04525038', 'velvet'], '886': ['n04525305', 'vending_machine'], '887': ['n04532106', 'vestment'], '888': ['n04532670', 'viaduct'], '889': ['n04536866', 'violin'], '890': ['n04540053', 'volleyball'], '891': ['n04542943', 'waffle_iron'], '892': ['n04548280', 'wall_clock'], '893': ['n04548362', 'wallet'], '894': ['n04550184', 'wardrobe'], '895': ['n04552348', 'warplane'], '896': ['n04553703', 'washbasin'], '897': ['n04554684', 'washer'], '898': ['n04557648', 'water_bottle'], '899': ['n04560804', 'water_jug'], '900': ['n04562935', 'water_tower'], '901': ['n04579145', 'whiskey_jug'], '902': ['n04579432', 'whistle'], '903': ['n04584207', 'wig'], '904': ['n04589890', 'window_screen'], '905': ['n04590129', 'window_shade'], '906': ['n04591157', 'Windsor_tie'], '907': ['n04591713', 'wine_bottle'], '908': ['n04592741', 'wing'], '909': ['n04596742', 'wok'], '910': ['n04597913', 'wooden_spoon'], '911': ['n04599235', 'wool'], '912': ['n04604644', 'worm_fence'], '913': ['n04606251', 'wreck'], '914': ['n04612504', 'yawl'], '915': ['n04613696', 'yurt'], '916': ['n06359193', 'web_site'], '917': ['n06596364', 'comic_book'], '918': ['n06785654', 'crossword_puzzle'], '919': ['n06794110', 'street_sign'], '920': ['n06874185', 'traffic_light'], '921': ['n07248320', 'book_jacket'], '922': ['n07565083', 'menu'], '923': ['n07579787', 'plate'], '924': ['n07583066', 'guacamole'], '925': ['n07584110', 'consomme'], '926': ['n07590611', 'hot_pot'], '927': ['n07613480', 'trifle'], '928': ['n07614500', 'ice_cream'], '929': ['n07615774', 'ice_lolly'], '930': ['n07684084', 'French_loaf'], '931': ['n07693725', 'bagel'], '932': ['n07695742', 'pretzel'], '933': ['n07697313', 'cheeseburger'], '934': ['n07697537', 'hotdog'], '935': ['n07711569', 'mashed_potato'], '936': ['n07714571', 'head_cabbage'], '937': ['n07714990', 'broccoli'], '938': ['n07715103', 'cauliflower'], '939': ['n07716358', 'zucchini'], '940': ['n07716906', 'spaghetti_squash'], '941': ['n07717410', 'acorn_squash'], '942': ['n07717556', 'butternut_squash'], '943': ['n07718472', 'cucumber'], '944': ['n07718747', 'artichoke'], '945': ['n07720875', 'bell_pepper'], '946': ['n07730033', 'cardoon'], '947': ['n07734744', 'mushroom'], '948': ['n07742313', 'Granny_Smith'], '949': ['n07745940', 'strawberry'], '950': ['n07747607', 'orange'], '951': ['n07749582', 'lemon'], '952': ['n07753113', 'fig'], '953': ['n07753275', 'pineapple'], '954': ['n07753592', 'banana'], '955': ['n07754684', 'jackfruit'], '956': ['n07760859', 'custard_apple'], '957': ['n07768694', 'pomegranate'], '958': ['n07802026', 'hay'], '959': ['n07831146', 'carbonara'], '960': ['n07836838', 'chocolate_sauce'], '961': ['n07860988', 'dough'], '962': ['n07871810', 'meat_loaf'], '963': ['n07873807', 'pizza'], '964': ['n07875152', 'potpie'], '965': ['n07880968', 'burrito'], '966': ['n07892512', 'red_wine'], '967': ['n07920052', 'espresso'], '968': ['n07930864', 'cup'], '969': ['n07932039', 'eggnog'], '970': ['n09193705', 'alp'], '971': ['n09229709', 'bubble'], '972': ['n09246464', 'cliff'], '973': ['n09256479', 'coral_reef'], '974': ['n09288635', 'geyser'], '975': ['n09332890', 'lakeside'], '976': ['n09399592', 'promontory'], '977': ['n09421951', 'sandbar'], '978': ['n09428293', 'seashore'], '979': ['n09468604', 'valley'], '980': ['n09472597', 'volcano'], '981': ['n09835506', 'ballplayer'], '982': ['n10148035', 'groom'], '983': ['n10565667', 'scuba_diver'], '984': ['n11879895', 'rapeseed'], '985': ['n11939491', 'daisy'], '986': ['n12057211', \"yellow_lady's_slipper\"], '987': ['n12144580', 'corn'], '988': ['n12267677', 'acorn'], '989': ['n12620546', 'hip'], '990': ['n12768682', 'buckeye'], '991': ['n12985857', 'coral_fungus'], '992': ['n12998815', 'agaric'], '993': ['n13037406', 'gyromitra'], '994': ['n13040303', 'stinkhorn'], '995': ['n13044778', 'earthstar'], '996': ['n13052670', 'hen-of-the-woods'], '997': ['n13054560', 'bolete'], '998': ['n13133613', 'ear'], '999': ['n15075141', 'toilet_tissue']}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.utils as keras_utils\n",
    "import json\n",
    "\n",
    "ROOT=\"/home/ma-user/work\" # see !pwd\n",
    "os.system(\"mkdir -p {}/output\".format(ROOT))\n",
    "\n",
    "CLASS_INDEX = None\n",
    "CLASS_INDEX_PATH = ('https://storage.googleapis.com/download.tensorflow.org/'\n",
    "                    'data/imagenet_class_index.json')\n",
    "\n",
    "cache_dir=\"{}/output/imagenet\".format(ROOT)\n",
    "if not os.path.isdir(cache_dir):\n",
    "    os.mkdir(cache_dir)\n",
    "\n",
    "fpath = keras_utils.get_file(\n",
    "    'imagenet_class_index.json',\n",
    "    CLASS_INDEX_PATH,\n",
    "    cache_subdir=cache_dir,\n",
    "    file_hash='c2c37ea517e94d9795004a39431a14cb'\n",
    ")\n",
    "\n",
    "with open(fpath) as f:\n",
    "    CLASS_INDEX = json.load(f)\n",
    "    \n",
    "print(CLASS_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for decode predictions\n",
    "!cp ./output/imagenet/imagenet_class_index.json /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/keras_applications/\n",
    "# In some machines, you should use \"/opt/conda/envs/python36_tf/lib/python3.6/site-packages/keras_applications/\" instead. Check sys.executable inside python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model: DenseNet\n",
    "\n",
    "DenseNet作为特征提取层具有均衡的准确度和大小尺度。Keras团队的实现的benchmark可以支持这个观点：\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th align=\"right\">Size</th>\n",
    "<th align=\"right\">Top-1 Accuracy</th>\n",
    "<th align=\"right\">Top-5 Accuracy</th>\n",
    "<th align=\"right\">Parameters</th>\n",
    "<th align=\"right\">Depth</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><a href=\"#xception\">Xception</a></td>\n",
    "<td align=\"right\">88 MB</td>\n",
    "<td align=\"right\">0.790</td>\n",
    "<td align=\"right\">0.945</td>\n",
    "<td align=\"right\">22,910,480</td>\n",
    "<td align=\"right\">126</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#vgg16\">VGG16</a></td>\n",
    "<td align=\"right\">528 MB</td>\n",
    "<td align=\"right\">0.713</td>\n",
    "<td align=\"right\">0.901</td>\n",
    "<td align=\"right\">138,357,544</td>\n",
    "<td align=\"right\">23</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#vgg19\">VGG19</a></td>\n",
    "<td align=\"right\">549 MB</td>\n",
    "<td align=\"right\">0.713</td>\n",
    "<td align=\"right\">0.900</td>\n",
    "<td align=\"right\">143,667,240</td>\n",
    "<td align=\"right\">26</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet50</a></td>\n",
    "<td align=\"right\">98 MB</td>\n",
    "<td align=\"right\">0.749</td>\n",
    "<td align=\"right\">0.921</td>\n",
    "<td align=\"right\">25,636,712</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet101</a></td>\n",
    "<td align=\"right\">171 MB</td>\n",
    "<td align=\"right\">0.764</td>\n",
    "<td align=\"right\">0.928</td>\n",
    "<td align=\"right\">44,707,176</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet152</a></td>\n",
    "<td align=\"right\">232 MB</td>\n",
    "<td align=\"right\">0.766</td>\n",
    "<td align=\"right\">0.931</td>\n",
    "<td align=\"right\">60,419,944</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet50V2</a></td>\n",
    "<td align=\"right\">98 MB</td>\n",
    "<td align=\"right\">0.760</td>\n",
    "<td align=\"right\">0.930</td>\n",
    "<td align=\"right\">25,613,800</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet101V2</a></td>\n",
    "<td align=\"right\">171 MB</td>\n",
    "<td align=\"right\">0.772</td>\n",
    "<td align=\"right\">0.938</td>\n",
    "<td align=\"right\">44,675,560</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet152V2</a></td>\n",
    "<td align=\"right\">232 MB</td>\n",
    "<td align=\"right\">0.780</td>\n",
    "<td align=\"right\">0.942</td>\n",
    "<td align=\"right\">60,380,648</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNeXt50</a></td>\n",
    "<td align=\"right\">96 MB</td>\n",
    "<td align=\"right\">0.777</td>\n",
    "<td align=\"right\">0.938</td>\n",
    "<td align=\"right\">25,097,128</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNeXt101</a></td>\n",
    "<td align=\"right\">170 MB</td>\n",
    "<td align=\"right\">0.787</td>\n",
    "<td align=\"right\">0.943</td>\n",
    "<td align=\"right\">44,315,560</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#inceptionv3\">InceptionV3</a></td>\n",
    "<td align=\"right\">92 MB</td>\n",
    "<td align=\"right\">0.779</td>\n",
    "<td align=\"right\">0.937</td>\n",
    "<td align=\"right\">23,851,784</td>\n",
    "<td align=\"right\">159</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#inceptionresnetv2\">InceptionResNetV2</a></td>\n",
    "<td align=\"right\">215 MB</td>\n",
    "<td align=\"right\">0.803</td>\n",
    "<td align=\"right\">0.953</td>\n",
    "<td align=\"right\">55,873,736</td>\n",
    "<td align=\"right\">572</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#mobilenet\">MobileNet</a></td>\n",
    "<td align=\"right\">16 MB</td>\n",
    "<td align=\"right\">0.704</td>\n",
    "<td align=\"right\">0.895</td>\n",
    "<td align=\"right\">4,253,864</td>\n",
    "<td align=\"right\">88</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#mobilenetv2\">MobileNetV2</a></td>\n",
    "<td align=\"right\">14 MB</td>\n",
    "<td align=\"right\">0.713</td>\n",
    "<td align=\"right\">0.901</td>\n",
    "<td align=\"right\">3,538,984</td>\n",
    "<td align=\"right\">88</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#densenet\">DenseNet121</a></td>\n",
    "<td align=\"right\">33 MB</td>\n",
    "<td align=\"right\">0.750</td>\n",
    "<td align=\"right\">0.923</td>\n",
    "<td align=\"right\">8,062,504</td>\n",
    "<td align=\"right\">121</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#densenet\">DenseNet169</a></td>\n",
    "<td align=\"right\">57 MB</td>\n",
    "<td align=\"right\">0.762</td>\n",
    "<td align=\"right\">0.932</td>\n",
    "<td align=\"right\">14,307,880</td>\n",
    "<td align=\"right\">169</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#densenet\">DenseNet201</a></td>\n",
    "<td align=\"right\">80 MB</td>\n",
    "<td align=\"right\">0.773</td>\n",
    "<td align=\"right\">0.936</td>\n",
    "<td align=\"right\">20,242,984</td>\n",
    "<td align=\"right\">201</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#nasnet\">NASNetMobile</a></td>\n",
    "<td align=\"right\">23 MB</td>\n",
    "<td align=\"right\">0.744</td>\n",
    "<td align=\"right\">0.919</td>\n",
    "<td align=\"right\">5,326,716</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#nasnet\">NASNetLarge</a></td>\n",
    "<td align=\"right\">343 MB</td>\n",
    "<td align=\"right\">0.825</td>\n",
    "<td align=\"right\">0.960</td>\n",
    "<td align=\"right\">88,949,818</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "在上一期，我们通过调整一些感受野尺寸的，数据增强，预训练模型，以及通过增加新算子调整卷积块结构，获得了较强的vgg16模型。除了vgg16，imagenet还涌现了许多模型，但因为没有ROI提取功能，不适合多目标检测，还不是十分实用。现在我们将通过预训练使用它们进行组网，写新的模型YoloV3变种YoloV4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "53182464/53178568 [==============================] - 137s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# loading pretrained model\n",
    "from keras.applications.densenet import DenseNet169, preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# exclude fully connected layers\n",
    "base_model = DenseNet169(include_top=False, weights='imagenet', \n",
    "                         input_tensor=None, input_shape=(config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], config.IMAGE_SHAPE[2]), pooling='avg_pool', \n",
    "                         classes=config.NUM_CLASSES)\n",
    "\n",
    "def init_base_model(base_model):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return base_model\n",
    "        \n",
    "backbone = init_base_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 221, 221, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 227, 227, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 111, 111, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 111, 111, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 111, 111, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 113, 113, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1280) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 640)  819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 640)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 640)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 640)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 672)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 672)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 704)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 704)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 736)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 736)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 768)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 768)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 800)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 800)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 800)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 832)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 832)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 832)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 864)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 864)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 864)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 896)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 896)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 896)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 928)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 960)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 992)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 1024)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1024)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 1024)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 1056)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1056)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 1056)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 1088)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1088)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 1088)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 1120)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1120)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 1120)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1152)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1152)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 7, 7, 1152)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 7, 7, 1184)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 7, 7, 1216)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 7, 7, 1248)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 7, 7, 1280)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 7, 7, 1312)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 7, 7, 1344)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 7, 7, 1376)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 7, 7, 1408)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 7, 7, 1440)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 7, 7, 1472)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 7, 7, 1504)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 7, 7, 1536)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 7, 7, 1568)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 7, 7, 1600)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 12,642,880\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,642,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YoloV4 Architecture\n",
    "\n",
    "YoloV4和YoloV3相似。首先通过DarkNet获取3个尺度的特征。至于为什么没有使用FPN的bottom-up和top-down模组组网，是一个需要进一步研究的问题。初步猜测，YoloV3的主要优势还是在比较高的速度上，还获得接近其他模型的准确度，因此为了保持速度优势，没有加入FPN模组组网。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.merge.Concatenate object at 0x7efc4e3e6be0>\n",
      "<keras.layers.merge.Concatenate object at 0x7efc42905a58>\n",
      "<keras.layers.merge.Concatenate object at 0x7efc3f0269b0>\n"
     ]
    }
   ],
   "source": [
    "def extract_densenet169_residual_route(backbone):\n",
    "    \"\"\"\n",
    "    Keras denset169 implements 5 stages residual blocks (named as \"dense_block\"). Each residual blocks\n",
    "    correspond to sequence of [6, 12, 32, 32].\n",
    "    \n",
    "    The numbers of filters of each 2d convolution used for the internal simple residual block are fixed at 128 and 32 with 1x1 and 3x3\n",
    "    kernels in order.\n",
    "    \n",
    "    In this experiment, since we want to use parameters trained on imagenet, we use that simple residual block. However,\n",
    "    as you can figure out from my other implementation of residual block, we can promise you a better one.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    model_name = 'densenet169'\n",
    "    stage_tmpl = \"conv{}_block{}_concat\"\n",
    "    conv_repeated_series = [12, 32, 32]\n",
    "    for seq, conv_repeated in enumerate(conv_repeated_series):\n",
    "        blocks.append(backbone.get_layer(stage_tmpl.format(seq+3, conv_repeated)))\n",
    "    return blocks\n",
    "\n",
    "# Not let's check it\n",
    "blocks = extract_densenet169_residual_route(backbone)\n",
    "for block in blocks:\n",
    "    print(block)\n",
    "# We've done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general intersection over union: https://giou.stanford.edu/\n",
    "# compared to L1 & L2 norm, jaccard index is scale invariant and have fine scale of values for different overlaps.\n",
    "# GIoU is especially useful for trainning if we want improve a bad prediction\n",
    "\n",
    "# All the methods can be generalized to 3d cases and left as future work\n",
    "\n",
    "# Vallina implementation for IoU\n",
    "def IoU(left_boxes, right_boxes):\n",
    "    \"\"\"\n",
    "    @param left_boxes: Tensor, shape=(i, 4) x1y1x2y2\n",
    "    @param right_boxes: Tensor, shape=(j,4), x1y1x2y2\n",
    "    @return \n",
    "        ious: Tensor, shape=(i,j)\n",
    "        overlap: Tensor, shape=(i,j)\n",
    "        union: Tensor, shape=(i,j)\n",
    "    \"\"\"\n",
    "    left_boxes = K.expand_dims(left_boxes, -2)\n",
    "    right_boxes = K.expand_dims(right_boxes, -3)\n",
    "    # Tensor Broadcasting see https://www.tensorflow.org/xla/broadcasting\n",
    "    # Since left_boxes, right_boxes are keras tensors, we compute ious using keras operators\n",
    "    x1y1 = K.maximum(left_boxes[...,:2], right_boxes[...,:2])\n",
    "    x2y2 = K.minimum(left_boxes[...,2:], right_boxes[...,2:])\n",
    "    \n",
    "    # Compute box area: (x2 - x1) * (y2 - y1)\n",
    "    left_area = (left_boxes[...,2] - left_boxes[...,0]) * (left_boxes[...,3] - left_boxes[...,1])\n",
    "    right_area = (right_boxes[...,2] - right_boxes[...,0]) * (right_boxes[...,3] - right_boxes[...,1])\n",
    "    \n",
    "    # Pay attention to this equation here, the numbers zero should be written as \"0.0\" to avoid complain from tensorflow backend\n",
    "    intersected_boxes = K.maximum(0.0, x2y2 - x1y1)\n",
    "    overlap = intersected_boxes[..., 0] * intersected_boxes[..., 1]\n",
    "    \n",
    "    union = left_area + right_area - overlap\n",
    "    ious = overlap / (union+1e-6)\n",
    "    return ious, overlap, union\n",
    "\n",
    "# @todo : TODO\n",
    "# see this paper : https://arxiv.org/pdf/1608.01471.pdf\n",
    "def IoU_UnitBox(left_boxes, right_boxes):\n",
    "    \"\"\"\n",
    "    @param left_boxes: Tensor, shape=(i, 4) x1y1x2y2\n",
    "    @param right_boxes: Tensor, shape=(j,4), x1y1x2y2\n",
    "    @return ious: Tensor, shape=(i,j)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def GIoU(left_boxes, right_boxes):\n",
    "    \"\"\"\n",
    "    @param left_boxes: Tensor, shape=(i, 4) x1y1x2y2\n",
    "    @param right_boxes: Tensor, shape=(j,4), x1y1x2y2\n",
    "    @return ious: Tensor, shape=(i,j)\n",
    "    \"\"\"\n",
    "    ious, _, union = IoU(left_boxes, right_boxes)\n",
    "    \n",
    "    left_boxes = K.expand_dims(left_boxes, -2)\n",
    "    right_boxes = K.expand_dims(right_boxes, -3)\n",
    "    # Tensor Broadcasting see https://www.tensorflow.org/xla/broadcasting\n",
    "    # Since left_boxes, right_boxes are keras tensors, we compute ious using keras operators\n",
    "    x1y1 = K.minimum(left_boxes[...,:2], right_boxes[...,:2])\n",
    "    x2y2 = K.maximum(left_boxes[...,2:], right_boxes[...,2:])\n",
    "    \n",
    "    # compute minimum convex hull\n",
    "    # Pay attention to this equation here, the numbers zero should be written as \"0.0\" to avoid complain from tensorflow backend\n",
    "    chul = K.maximum(0.0, x2y2 - x1y1)\n",
    "    chul_area = chul[...,0] * chul[...,1]\n",
    "    \n",
    "    gious = ious - (chul_area - union) / chul_area\n",
    "    return gious\n",
    "    \n",
    "def Universal_IoU(left_boxes, right_boxes):\n",
    "    \"\"\"\n",
    "    @param left_boxes: Tensor, shape=(i, 4) x1y1x2y2\n",
    "    @param right_boxes: Tensor, shape=(j,4), x1y1x2y2\n",
    "    @return ious: Tensor, shape=(i,j)\n",
    "    \"\"\"\n",
    "    ious, overlap, union = IoU(left_boxes, right_boxes)\n",
    "    \n",
    "    left_boxes = K.expand_dims(left_boxes, -2)\n",
    "    right_boxes = K.expand_dims(right_boxes, -3)\n",
    "    # Tensor Broadcasting see https://www.tensorflow.org/xla/broadcasting\n",
    "    # Since left_boxes, right_boxes are keras tensors, we compute ious using keras operators\n",
    "    x1y1 = K.minimum(left_boxes[...,:2], right_boxes[...,:2])\n",
    "    x2y2 = K.maximum(left_boxes[...,2:], right_boxes[...,2:])\n",
    "    \n",
    "    # compute minimum convex hull\n",
    "    # Pay attention to this equation here, the numbers zero should be written as \"0.0\" to avoid complain from tensorflow backend\n",
    "    chul = K.maximum(0.0, x2y2 - x1y1)\n",
    "    chul_area = chul[...,0] * chul[...,1]\n",
    "    \n",
    "    # uious = uious - (chul_area - union + overlap) / chul_area\n",
    "    \n",
    "    # something like items assignment below\n",
    "    # uious[uious==0] = - (chul_area - union + overlap) / chul_area\n",
    "    mask = K.equal(ious, 0)\n",
    "    mask = K.cast(mask, dtype='float32')\n",
    "    uious = (1-mask)*ious - mask*((chul_area - union + overlap) / chul_area)\n",
    "    return uious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Keras GIoU Behaviors\n",
    "\n",
    "现在我们需要书写测试检测该算子。类似于利用tensorflow的session对象运行算子，我们可以利用keras.backend.function获取从输入tensor，到输出tensor的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU computation results: [[0.47058824 0.14285715 0.         0.        ]]\n",
      "GIoU computation results: [array([[ 0.41503268, -0.07936507, -0.6571429 , -0.75      ]],\n",
      "      dtype=float32)]\n",
      "UIoU computation results: [array([[ 0.47058824,  0.14285715, -0.6571429 , -0.75      ],\n",
      "       [ 0.47058824,  0.14285715, -0.6571429 , -0.75      ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def test_IoU():\n",
    "    left_boxes_ops = KL.Input(shape=(1,4))\n",
    "    right_boxes_ops = KL.Input(shape=(4,4))\n",
    "    ious_ops, overlap_ops, union_ops= IoU(left_boxes_ops, right_boxes_ops)\n",
    "    func = K.function([left_boxes_ops, right_boxes_ops], [ious_ops, overlap_ops, union_ops])\n",
    "    \n",
    "    left_boxes_vals = np.array([[10, 10, 20, 20]])\n",
    "    right_boxes_vals = np.array([[12, 12, 22, 22], [15, 15, 25, 25], [25, 25, 35, 45], [30, 30, 50, 40]])\n",
    "    \n",
    "    ious, overlap, union = func([left_boxes_vals, right_boxes_vals])\n",
    "    \n",
    "    print(\"IoU computation results:\",ious)\n",
    "    \n",
    "def test_GIoU():\n",
    "    left_boxes_ops = KL.Input(shape=(1,4))\n",
    "    right_boxes_ops = KL.Input(shape=(4,4))\n",
    "    gious_ops = GIoU(left_boxes_ops, right_boxes_ops)\n",
    "    func = K.function([left_boxes_ops, right_boxes_ops], [gious_ops])\n",
    "    \n",
    "    left_boxes_vals = np.array([[10, 10, 20, 20]])\n",
    "    right_boxes_vals = np.array([[12, 12, 22, 22], [15, 15, 25, 25], [25, 25, 35, 45], [30, 30, 50, 40]])\n",
    "    \n",
    "    gious = func([left_boxes_vals, right_boxes_vals])\n",
    "    \n",
    "    print(\"GIoU computation results:\", gious)\n",
    "\n",
    "def test_UIoU():\n",
    "    left_boxes_ops = KL.Input(shape=(2,4))\n",
    "    right_boxes_ops = KL.Input(shape=(4,4))\n",
    "    uious_ops = Universal_IoU(left_boxes_ops, right_boxes_ops)\n",
    "    func = K.function([left_boxes_ops, right_boxes_ops], [uious_ops])\n",
    "    \n",
    "    left_boxes_vals = np.array([[10, 10, 20, 20], [10, 10, 20, 20]])\n",
    "    right_boxes_vals = np.array([[12, 12, 22, 22], [15, 15, 25, 25], [25, 25, 35, 45], [30, 30, 50, 40]])\n",
    "    \n",
    "    uious = func([left_boxes_vals, right_boxes_vals])\n",
    "    \n",
    "    print(\"UIoU computation results:\", uious)\n",
    "    \n",
    "# uint test utilites examples here\n",
    "test_IoU()\n",
    "test_GIoU()\n",
    "test_UIoU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Lei Wang\"\n",
    "__email__ = [\"lwang11@mtu.edu\", \"L.WANG@ntu.edu.sg\", \"lwang019@e.ntu.edu.sg\", \"yiak.wy@gmail.com\"]\n",
    "__date__ = \"July 25th, 2019\"\n",
    "\n",
    "# see https://keras.io/activations/\n",
    "try:\n",
    "    from keras.layers.advanced_activations import LeakyReLU\n",
    "except:\n",
    "    from keras.layers import LeakyReLu\n",
    "import skimage.transform\n",
    "try:\n",
    "    import functools\n",
    "    from functools import reduce as reduce\n",
    "except:\n",
    "    pass\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "def lr_schedule_callback(epoch):\n",
    "    lr = 1e-2\n",
    "    if epoch > 75:\n",
    "        lr = 5*1e-4\n",
    "    elif epoch > 100:\n",
    "        lr = 3*1e-4\n",
    "    return lr\n",
    "\n",
    "# adpot from mask rcnn : https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py\n",
    "class BatchNorm(KL.BatchNormalization):\n",
    "    \"\"\"Extends the Keras BatchNormalization class to allow a central place\n",
    "    to make changes if needed.\n",
    "    Batch normalization has a negative effect on training if batches are small\n",
    "    so this layer is often frozen (via setting in Config class) and functions\n",
    "    as linear layer.\n",
    "    \"\"\"\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Note about training values:\n",
    "            None: Train BN layers. This is the normal mode\n",
    "            False: Freeze BN layers. Good when batch size is small\n",
    "            True: (don't use). Set layer in training mode even when making inferences\n",
    "        \"\"\"\n",
    "        return super(self.__class__, self).call(inputs, training=training)\n",
    "\n",
    "def Conv2DBlock(inp, filters, kernel_size=(3, 3), dropouts=None, conv_repeated=1, pooling=False, padding='same', stage=None):\n",
    "    name = 'conv%s' % stage\n",
    "    # print(\"calling %s\" % name)\n",
    "    out = inp\n",
    "    for i in range(conv_repeated):\n",
    "        conv = KL.Conv2D(filters, kernel_size, padding=padding, name=\"{}_conv2d{}\".format(name, i))(out)\n",
    "        bn = BatchNorm(name=\"{}_bn{}\".format(name, i))(conv, training=True)\n",
    "        # using LeakyRelu with alpah equal to 0.1\n",
    "        act = KL.LeakyReLU(alpha=0.1, name=\"{}_act{}\".format(name, i))(bn)\n",
    "        if dropouts is not None and len(dropouts) > 0:\n",
    "            dropout = KL.Dropout(dropouts[i], name=\"{}_dp{}\".format(name, i))(act)\n",
    "            out = dropout\n",
    "        else:\n",
    "            out = act\n",
    "    \n",
    "    if pooling:\n",
    "        pooled = KL.MaxPooling2D(pool_size=(2,2), name=\"{}_maxpooling2d{}\".format(name_stage))(out)\n",
    "        out = pooled\n",
    "    return out\n",
    "\n",
    "def Conv2DBlockLayer(filters, kernel_size=(3, 3), dropouts=None, conv_repeated=1, pooling=False, padding='same', stage=None):\n",
    "    # KL.Lamda has some problems in composing functions, hence discarded\n",
    "    func = KL.Lambda(Conv2DBlock, name=\"lambda{}\".format(stage),\n",
    "                    arguments={\n",
    "                        'filters': filters,\n",
    "                        'kernel_size': kernel_size,\n",
    "                        'dropouts': dropouts,\n",
    "                        'conv_repeated': conv_repeated,\n",
    "                        'pooling': pooling,\n",
    "                        'padding': padding,\n",
    "                        'stage': stage\n",
    "                    })\n",
    "    func1 = functools.partial(Conv2DBlock, \n",
    "                              filters=filters,\n",
    "                              kernel_size=kernel_size, \n",
    "                              dropouts=dropouts, \n",
    "                              conv_repeated=conv_repeated, \n",
    "                              pooling=pooling, \n",
    "                              padding=padding, \n",
    "                              stage=stage)\n",
    "    return func1\n",
    "\n",
    "def Stack(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    def _stack(pre, cur): \n",
    "        # print(\"produce a composing func\")\n",
    "        def wrapped(*args, **kw):\n",
    "            # print(\"call a composing func\")\n",
    "            return cur(pre(*args, **kw))\n",
    "        return wrapped\n",
    "    \n",
    "    if funcs:\n",
    "        return reduce(lambda pre, cur: _stack(pre, cur), funcs, lambda x: x)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "def Conv2BBox(inp, filters, boxes_dim, stage):\n",
    "    if not isinstance(stage, str):\n",
    "        stage = str(stage)\n",
    "    print(\"Conv2BBox inp\", inp)\n",
    "    assert_symbolic_tensor(inp)\n",
    "    conv = Stack(\n",
    "        Conv2DBlockLayer(filters, (1,1), stage=stage+\"/1\"),\n",
    "        Conv2DBlockLayer(filters*2, (3,3), stage=stage+\"/2\"),\n",
    "        Conv2DBlockLayer(filters, (1,1), stage=stage+\"/3\"),\n",
    "        Conv2DBlockLayer(filters*2, (3,3), stage=stage+\"/4\"),\n",
    "        Conv2DBlockLayer(filters, (1,1), stage=stage+\"/5\")\n",
    "    )(inp)\n",
    "    assert_symbolic_tensor(conv)\n",
    "    out = Stack(\n",
    "        Conv2DBlockLayer(filters*2,(3,3), stage=stage+\"/6\"),\n",
    "        KL.Conv2D(boxes_dim, (1,1), name=\"conv{}_conv2d{}\".format(stage+\"/7\", 0))\n",
    "    )(conv)\n",
    "    return conv, out\n",
    "\n",
    "def UpSampling_BilinearInterpolation(inp, factor):\n",
    "    return KL.UpSampling2D(size=(factor, factor))(inp)\n",
    "\n",
    "def Decode(feat, anchors_per_grid, num_classes, anchors):\n",
    "    \"\"\"\n",
    "    Decode feature map to bounding boxes with shape = (batch_size, out_nm_h, out_nm_w, anchors_per_grid * (5+num_classes))\n",
    "    \n",
    "    :param feat: Tensor, shape=(batch_size, out_nm_h, out_nm_w, anchors_per_grid * (5+num_classes))\n",
    "    :param anchors_per_grid: integer, anchors per sliding window\n",
    "    :num_classes: numbers of classes to predict\n",
    "    :stride: \n",
    "    :return\n",
    "        pred_bbox: Tensor, shape=(batch_size, out_nm_h, out_nm_w, anchors_per_grid * (5+num_classes))\n",
    "    \"\"\"\n",
    "    shape = K.shape(feat)\n",
    "    batch_size = shape[0]\n",
    "    out_nm = shape[1:3]\n",
    "    \n",
    "    # Create XY Grid:\n",
    "    # Just like create a grid in numpy using np.tile and np.arange\n",
    "    # >>> y = np.tile(np.arange(3).reshape(3,1), [1, 4])\n",
    "    # array([[0, 0, 0, 0],\n",
    "    #        [1, 1, 1, 1],\n",
    "    #        [2, 2, 2, 2]])\n",
    "    # >>> x = np.tile(np.arange(4).reshape(1,4), [3, 1])\n",
    "    # array([[0, 1, 2, 3],\n",
    "    #        [0, 1, 2, 3],\n",
    "    #        [0, 1, 2, 3]])\n",
    "    # >>> grid = np.concatenate([np.expand_dims(x, axis=-1), np.expand_dims(cy axis=-1)], axis=-1) # shape=(3,4,2)\n",
    "    # array([[[0, 0],\n",
    "    #         [1, 0],\n",
    "    #         [2, 0],\n",
    "    #         [3, 0]],\n",
    "    #\n",
    "    #        [[0, 1],\n",
    "    #         [1, 1],\n",
    "    #         [2, 1],\n",
    "    #         [3, 1]],\n",
    "    #\n",
    "    #        [[0, 2],\n",
    "    #         [1, 2],\n",
    "    #         [2, 2],\n",
    "    #         [3, 2]]])\n",
    "    grid_y  = K.tile(K.expand_dims(K.arange(0, stop=out_nm[0]), axis=1), [1, out_nm[1]]) #repeat along width direction\n",
    "    grid_x  = K.tile(K.expand_dims(K.arange(0, stop=out_nm[1]), axis=0), [out_nm[0], 1]) #repeat along height direction \n",
    "    grid_xy = K.concatenate([K.expand_dims(grid_x, axis=-1), K.expand_dims(grid_y, axis=-1)], axis=-1)\n",
    "    grid_xy = K.cast(grid_xy, K.dtype(feat))\n",
    "    \n",
    "    feat = K.reshape(feat, [-1, out_nm[0], out_nm[1], anchors_per_grid, 5+num_classes])\n",
    "    anchor_tensor = K.reshape(K.constant(anchors), [1,1,1, anchors_per_grid, 2])\n",
    "    grid_shape = out_nm\n",
    "    \n",
    "    # Yolo predicts offsets (dx, dy, dh, dw) and adjust boxes generated from anchors instead of predicting bbox coordinates where\n",
    "    # bx = (cx + sigmoid(dx)) * downsampling_rate\n",
    "    # by = (cy + sigmoid(dy)) * downsampling_rate\n",
    "    # bh = exp^dh * anchor_h  * downsampling_rate\n",
    "    # bw = exp^dw * anchor_w  * downsampling_rate\n",
    "    # where, downsampling_rate = input_shape / grid_shape (shape=(2,1))\n",
    "    # For Coco dataset we could use prior anchor sizes computed via K-Means++ : 10x13，16x30，33x23，30x61，62x45，59x119，116x90，156x198，373x326\n",
    "    # See [MetaAnchor: Learning to Detect Objects with Customized Anchors](https://arxiv.org/abs/1807.00980?source=post_page---------------------------) and\n",
    "    # https://www.liip.ch/en/blog/face-detection-an-overview-and-comparison-of-different-solutions-part1?source=post_page---------------------------\n",
    "    \n",
    "    # Compute normalized bboxes\n",
    "    bboxes_xy = grid_xy + K.sigmoid(feat[...,:2]) / K.cast(grid_shape[::-1], K.dtype(feat))\n",
    "    bboxes_wh = K.exp(feat[..., 2:4]) * anchor_tensor / K.cast(grid_shape[::-1], K.dtype(feat))\n",
    "    bboxes_x1y1 = bboxes_xy - bboxes_wh / 2.0\n",
    "    bboxes_x2y2 = bboxes_xy + bboxes_wh / 2.0\n",
    "    pred_corner = K.concatenate([bboxes_x1y1, bboxes_x2y2], axis=-1)\n",
    "    \n",
    "    # logloss of confidence\n",
    "    pred_conf = K.sigmoid(feat[..., 4:5])\n",
    "    \n",
    "    # logloss of One-Hot encoding of predicted classes\n",
    "    pred_class_probs = K.sigmoid(feat[..., 5:])\n",
    "    \n",
    "    pred_bboxes = K.concatenate([pred_corner, pred_conf, pred_class_probs], axis=-1)\n",
    "    return pred_bboxes\n",
    "\n",
    "def assert_symbolic_tensor(inp):\n",
    "    try:\n",
    "        K.is_keras_tensor(inp)\n",
    "    except ValueError as e:\n",
    "        raise(e)\n",
    "\n",
    "# also see implementation for other models in SpatialDetectron\n",
    "class YoloV4(object):\n",
    "    \n",
    "    def __init__(self, mode, config, model_dir,\n",
    "                 backbone=None):\n",
    "        self.mode = mode\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.backbone = backbone\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        self.scales = [32, 16, 8]\n",
    "        self.anchors = {2: [(10,13),(16,30),(33,23)],     # large objects detect anchors\n",
    "                        1: [(30,61),(62,45),(59,119)],    # medium objects detect anchors\n",
    "                        0: [(116,90),(156,198),(373,326)]} # smallest detect anchors\n",
    "        self.anchors_per_grid = 3\n",
    "        self.iou_loss_threshold = 0.7\n",
    "        # Here we use customer loss\n",
    "        self.model = self.get_model(mode=self.mode, backbone=self.backbone)\n",
    "        \n",
    "    def get_model(self, mode, backbone):\n",
    "        config = self.config\n",
    "        # Darknet features pyramid (similar to FPN without top-down network block and restricted to 3 feature layers extraction)\n",
    "        if backbone is None:\n",
    "            base_model = DenseNet169(include_top=False, weights='imagenet', \n",
    "                         input_tensor=None, input_shape=(config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], config.IMAGE_SHAPE[2]), pooling='avg_pool', \n",
    "                         classes=config.NUM_CLASSES)\n",
    "            backbone = init_base_model(base_model)\n",
    "            \n",
    "        blocks = extract_densenet169_residual_route(backbone)\n",
    "        \n",
    "        self.inputs = backbone.inputs\n",
    "        self.input_size = K.shape(self.inputs[0]) \n",
    "        H, W, CHANNELS = config.IMAGE_SHAPE\n",
    "        self.outputs = []\n",
    "        \n",
    "        # YoloV4 Detectron Body\n",
    "        # make bolcks in reverse order\n",
    "        blocks = blocks[::-1]\n",
    "        # the darknet output for small objects\n",
    "        x = blocks[0].output\n",
    "        assert_symbolic_tensor(x)\n",
    "        boxes_dim = self.anchors_per_grid * (config.NUM_CLASSES+5)\n",
    "        filters = [512, 256, 128] # config\n",
    "        self.featmaps = []\n",
    "        for i, block in enumerate(blocks):\n",
    "            if i > 0:\n",
    "                x = Conv2DBlock(x, filters[i], (1,1), stage=str(i)+\"/0\")\n",
    "                x = UpSampling_BilinearInterpolation(x, 2)\n",
    "                x = KL.Concatenate()([x, block.output])\n",
    "                \n",
    "            x, out = Conv2BBox(x, filters[i], boxes_dim, stage=i)\n",
    "            print(\"Add featmap %s\" % i)\n",
    "            self.featmaps.append(out)\n",
    "        \n",
    "        # YoloV3 Losses: the key part of the detectron\n",
    "        # In practice self.anchors_per_grid == gt_per_grid makes loss easy to be expressed via tensor operations\n",
    "        scales = [32, 16, 8] # config\n",
    "        y_true = [KL.Input(shape=(int(H/scale), \n",
    "                                  int(W/scale), \n",
    "                                  self.anchors_per_grid, config.NUM_CLASSES+5)) for scale in scales]\n",
    "        import inspect\n",
    "        inspect.signature(self.loss)\n",
    "        loss = KL.Lambda(self.loss, output_shape=(1,), name=\"yolo_loss\",\n",
    "                         arguments={'y_true': y_true})(self.featmaps)\n",
    "        self._loss = loss\n",
    "        \n",
    "        # Model\n",
    "        # calling to keras.engine.network.Network._init_graph_network (L137) method to initialize computational graph\n",
    "        model = KM.Model([self.inputs[0], *y_true], loss)\n",
    "        return model\n",
    "    \n",
    "    # The most important function\n",
    "    # also see decode func (which is the reference implementation for loss) in https://github.com/Stinky-Tofu/Stronger-yolo/blob/master/v2/model/layers.py\n",
    "    def loss(self, featmaps, y_true):\n",
    "        config = self.config\n",
    "        losses = 0.0\n",
    "        for i,fm in enumerate(featmaps):\n",
    "            # compute normalized predicted bbox\n",
    "            print(\"Shape of fm:\", fm.get_shape())\n",
    "            pred_bboxes = Decode(fm, self.anchors_per_grid, config.NUM_CLASSES, self.anchors[i])\n",
    "            print(\"Shape of pred_bboxes:\", pred_bboxes.get_shape())\n",
    "            shape = K.shape(fm)\n",
    "            out_nm = shape[1:3]\n",
    "            fm = K.reshape(fm, [-1, out_nm[0], out_nm[1], self.anchors_per_grid, 5+config.NUM_CLASSES])\n",
    "            print(\"Shape of fm after dimension expansion:\", fm.get_shape())\n",
    "            batch_size = self.input_size[0]\n",
    "            # important!\n",
    "            batch_size = K.cast(batch_size, K.dtype(fm))\n",
    "            \n",
    "            # loss of predicted bounding boxes using Universal_IoU\n",
    "            # uious tensor of the shape [batch_size, h, w, anchor_per_grid, gt_per_grid], where anchor_per_grid == gt_per_grid in practice\n",
    "            uious = Universal_IoU(pred_bboxes[..., 0:4], y_true[i][..., 0:4])\n",
    "            gt_hw = y_true[i][...,2:4]\n",
    "            # weights tensor of the shape [batch_size, h, w, gt_per_grid, 1]\n",
    "            weights = 2.0 - gt_hw[...,0:1] * gt_hw[...,1:2]\n",
    "            fg_mask = y_true[i][..., 4:5]\n",
    "            uious_loss = fg_mask * weights * (1-uious)\n",
    "            \n",
    "            # loss of confidence\n",
    "            ious, _, _= IoU(pred_bboxes[...,0:4], y_true[i][..., 0:4])\n",
    "            print(\"Shape of ious:\", ious.get_shape())\n",
    "            # see implementation of K.max at https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py\n",
    "            # it is equivalent to tf.reduce_max\n",
    "            max_ious = K.max(ious, axis=-1)\n",
    "            print(\"Shape of max_ious:\", max_ious.get_shape())\n",
    "            max_ious = K.expand_dims(max_ious, axis=-1)\n",
    "            print(\"Shape of max_ious after expansion:\", max_ious.get_shape())\n",
    "            # [batch_size, h, w, gt_per_grid, 1] * [batch_size, h, w, anchor_per_grid, 1]\n",
    "            bg_mask = (1.0 - fg_mask) * K.cast(max_ious < self.iou_loss_threshold, dtype='float32')\n",
    "            alpha = 1\n",
    "            gamma = 2\n",
    "            conf_focal = alpha * K.pow(K.abs(fg_mask-pred_bboxes[...,4:5]), gamma) # L2 norm\n",
    "            print(\"Shape of fm[...,4:5]:\", fm[...,4:5].get_shape())\n",
    "            conf_loss = conf_focal * (\n",
    "                fg_mask * K.binary_crossentropy(fg_mask, fm[...,4:5], from_logits=True)\n",
    "                +\n",
    "                bg_mask * K.binary_crossentropy(fg_mask, fm[...,4:5], from_logits=True)\n",
    "            )\n",
    "            \n",
    "            # loss of one-hot encoding of classes\n",
    "            class_probs_loss = fg_mask * K.binary_crossentropy(y_true[i][...,5:], fm[...,5:], from_logits=True)\n",
    "            \n",
    "            # gather total loss\n",
    "            print(\"type of uious_loss:\", K.dtype(uious_loss))\n",
    "            print(\"type of conf_loss:\", K.dtype(conf_loss))\n",
    "            print(\"type of class_probs_loss:\", K.dtype(class_probs_loss))\n",
    "            loss = (K.sum(uious_loss) + K.sum(conf_loss) + K.sum(class_probs_loss)) / batch_size\n",
    "            losses += loss\n",
    "        return losses\n",
    "    \n",
    "    def fit(self, dataset, optimizer_type='rmsprop', data_gen=True, data_augumented=True):\n",
    "        model = self.model\n",
    "        # Initate optimizer\n",
    "        if optimizer_type is 'rmsprop':\n",
    "            optimizer = RMSprop(lr=1e-2, decay=1e-6)\n",
    "        else:\n",
    "            optimizer = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "        # compile the program\n",
    "        model.compile(loss={\n",
    "            'yolo_loss': lambda y_true, y_pred: ypred\n",
    "        }, optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # early stopping strategy\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') \n",
    "        history = LossHistory()\n",
    "        \n",
    "        filepath=\"{}/weights.best.checkpoint.hdf5\".format(self.model_dir)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        \n",
    "        learning_rate_schedule = LearningRateScheduler(lr_schedule_callback)\n",
    "        \n",
    "        if data_augumented:\n",
    "            # data augumentation\n",
    "            # adapted from https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
    "            datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                # randomly shift images horizontally (fraction of total width)\n",
    "                width_shift_range=0.1,\n",
    "                # randomly shift images vertically (fraction of total height)\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=0.,  # set range for random shear\n",
    "                zoom_range=0.,  # set range for random zoom\n",
    "                channel_shift_range=0.,  # set range for random channel shifts\n",
    "                # set mode for filling points outside the input boundaries\n",
    "                fill_mode='nearest',\n",
    "                cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False,  # randomly flip images\n",
    "                # set rescaling factor (applied before any other transformation)\n",
    "                rescale=None,\n",
    "                # set function that will be applied on each input\n",
    "                preprocessing_function=None,\n",
    "                # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                data_format=None,\n",
    "                # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "                validation_split=0.25)\n",
    "        \n",
    "        # begin to train\n",
    "        if not data_gen:\n",
    "            # load a small dataset for test in CPU mode and generate train_data, train_annotations to feed model\n",
    "            # @todo : TODO\n",
    "            raise Exception(\"train_data, train_annotations without data_gen are not implemented.\")\n",
    "            # fit model using train data\n",
    "            model.fit(\n",
    "                train_data,\n",
    "                train_annotations,\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                epochs=self.config.EPOCHES,\n",
    "                validation_split=0.25, # trainning, 25% of data used for validation\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                callbacks=[history, early_stopping, checkpoint, learning_rate_schedule])\n",
    "        else:\n",
    "            # trainning for large scale datasets\n",
    "            train_reader = dataset.train_reader()\n",
    "            val_reader = dataset.infer_reader()\n",
    "\n",
    "            model.fit_generator(train_reader,\n",
    "                                validation_data=val_reader,\n",
    "                                epochs=self.config.EPOCHES,\n",
    "                                workers=8,\n",
    "                                verbose=2,\n",
    "                                callbacks=[history, checkpoint])\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, weights=None):\n",
    "        if weights is None:\n",
    "            filepath=\"{}/weights.best.checkpoint.hdf5\".format(self.model_dir)\n",
    "        else:\n",
    "            filepath=weights\n",
    "            \n",
    "        if os.path.isfile(filepath):\n",
    "            model = self.model\n",
    "            model.load_weights(filepath)\n",
    "        else:\n",
    "            print(\"{} does not exit!\".format(filepath))\n",
    "    \n",
    "    def infer(self, imgs, verbose=0):\n",
    "        model = self.model\n",
    "        results = model.predict(imgs, verbose=verbose)\n",
    "        return results\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "    \n",
    "    def get_layers(self):\n",
    "        return self.model.layers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2BBox inp Tensor(\"conv5_block32_concat/concat:0\", shape=(?, 7, 7, 1664), dtype=float32)\n",
      "Add featmap 0\n",
      "Conv2BBox inp Tensor(\"concatenate_15/concat:0\", shape=(?, 14, 14, 1536), dtype=float32)\n",
      "Add featmap 1\n",
      "Conv2BBox inp Tensor(\"concatenate_16/concat:0\", shape=(?, 28, 28, 640), dtype=float32)\n",
      "Add featmap 2\n",
      "Shape of fm: (?, 7, 7, 27)\n",
      "Shape of pred_bboxes: (?, ?, ?, 3, 9)\n",
      "Shape of fm after dimension expansion: (?, ?, ?, 3, 9)\n",
      "Shape of ious: (?, 6, 6, 3, 3)\n",
      "Shape of max_ious: (?, 6, 6, 3)\n",
      "Shape of max_ious after expansion: (?, 6, 6, 3, 1)\n",
      "Shape of fm[...,4:5]: (?, ?, ?, 3, 1)\n",
      "type of uious_loss: float32\n",
      "type of conf_loss: float32\n",
      "type of class_probs_loss: float32\n",
      "Shape of fm: (?, 14, 14, 27)\n",
      "Shape of pred_bboxes: (?, ?, ?, 3, 9)\n",
      "Shape of fm after dimension expansion: (?, ?, ?, 3, 9)\n",
      "Shape of ious: (?, 13, 13, 3, 3)\n",
      "Shape of max_ious: (?, 13, 13, 3)\n",
      "Shape of max_ious after expansion: (?, 13, 13, 3, 1)\n",
      "Shape of fm[...,4:5]: (?, ?, ?, 3, 1)\n",
      "type of uious_loss: float32\n",
      "type of conf_loss: float32\n",
      "type of class_probs_loss: float32\n",
      "Shape of fm: (?, 28, 28, 27)\n",
      "Shape of pred_bboxes: (?, ?, ?, 3, 9)\n",
      "Shape of fm after dimension expansion: (?, ?, ?, 3, 9)\n",
      "Shape of ious: (?, 27, 27, 3, 3)\n",
      "Shape of max_ious: (?, 27, 27, 3)\n",
      "Shape of max_ious after expansion: (?, 27, 27, 3, 1)\n",
      "Shape of fm[...,4:5]: (?, ?, ?, 3, 1)\n",
      "type of uious_loss: float32\n",
      "type of conf_loss: float32\n",
      "type of class_probs_loss: float32\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 221, 221, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 227, 227, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 111, 111, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 111, 111, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 111, 111, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 113, 113, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1280) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 640)  819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 640)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 640)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 640)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 672)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 672)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 704)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 704)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 736)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 736)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 768)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 768)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 800)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 800)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 800)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 832)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 832)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 832)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 864)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 864)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 864)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 896)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 896)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 896)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 928)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 960)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 992)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 1024)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1024)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 1024)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 1056)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1056)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 1056)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 1088)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1088)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 1088)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 1120)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1120)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 1120)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1152)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1152)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 7, 7, 1152)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 7, 7, 1184)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 7, 7, 1216)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 7, 7, 1248)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 7, 7, 1280)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 7, 7, 1312)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 7, 7, 1344)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 7, 7, 1376)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 7, 7, 1408)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 7, 7, 1440)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 7, 7, 1472)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 7, 7, 1504)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 7, 7, 1536)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 7, 7, 1568)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 7, 7, 1600)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv0/1_conv2d0 (Conv2D)        (None, 7, 7, 512)    852480      conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv0/1_bn0 (BatchNorm)         (None, 7, 7, 512)    2048        conv0/1_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv0/1_act0 (LeakyReLU)        (None, 7, 7, 512)    0           conv0/1_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0/2_conv2d0 (Conv2D)        (None, 7, 7, 1024)   4719616     conv0/1_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv0/2_bn0 (BatchNorm)         (None, 7, 7, 1024)   4096        conv0/2_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv0/2_act0 (LeakyReLU)        (None, 7, 7, 1024)   0           conv0/2_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0/3_conv2d0 (Conv2D)        (None, 7, 7, 512)    524800      conv0/2_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv0/3_bn0 (BatchNorm)         (None, 7, 7, 512)    2048        conv0/3_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv0/3_act0 (LeakyReLU)        (None, 7, 7, 512)    0           conv0/3_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0/4_conv2d0 (Conv2D)        (None, 7, 7, 1024)   4719616     conv0/3_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv0/4_bn0 (BatchNorm)         (None, 7, 7, 1024)   4096        conv0/4_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv0/4_act0 (LeakyReLU)        (None, 7, 7, 1024)   0           conv0/4_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0/5_conv2d0 (Conv2D)        (None, 7, 7, 512)    524800      conv0/4_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv0/5_bn0 (BatchNorm)         (None, 7, 7, 512)    2048        conv0/5_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv0/5_act0 (LeakyReLU)        (None, 7, 7, 512)    0           conv0/5_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1/0_conv2d0 (Conv2D)        (None, 7, 7, 256)    131328      conv0/5_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/0_bn0 (BatchNorm)         (None, 7, 7, 256)    1024        conv1/0_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/0_act0 (LeakyReLU)        (None, 7, 7, 256)    0           conv1/0_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 14, 14, 256)  0           conv1/0_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 14, 14, 1536) 0           up_sampling2d_15[0][0]           \n",
      "                                                                 conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1/1_conv2d0 (Conv2D)        (None, 14, 14, 256)  393472      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/1_bn0 (BatchNorm)         (None, 14, 14, 256)  1024        conv1/1_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/1_act0 (LeakyReLU)        (None, 14, 14, 256)  0           conv1/1_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1/2_conv2d0 (Conv2D)        (None, 14, 14, 512)  1180160     conv1/1_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/2_bn0 (BatchNorm)         (None, 14, 14, 512)  2048        conv1/2_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/2_act0 (LeakyReLU)        (None, 14, 14, 512)  0           conv1/2_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1/3_conv2d0 (Conv2D)        (None, 14, 14, 256)  131328      conv1/2_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/3_bn0 (BatchNorm)         (None, 14, 14, 256)  1024        conv1/3_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/3_act0 (LeakyReLU)        (None, 14, 14, 256)  0           conv1/3_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1/4_conv2d0 (Conv2D)        (None, 14, 14, 512)  1180160     conv1/3_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/4_bn0 (BatchNorm)         (None, 14, 14, 512)  2048        conv1/4_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/4_act0 (LeakyReLU)        (None, 14, 14, 512)  0           conv1/4_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1/5_conv2d0 (Conv2D)        (None, 14, 14, 256)  131328      conv1/4_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/5_bn0 (BatchNorm)         (None, 14, 14, 256)  1024        conv1/5_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/5_act0 (LeakyReLU)        (None, 14, 14, 256)  0           conv1/5_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/0_conv2d0 (Conv2D)        (None, 14, 14, 128)  32896       conv1/5_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/0_bn0 (BatchNorm)         (None, 14, 14, 128)  512         conv2/0_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/0_act0 (LeakyReLU)        (None, 14, 14, 128)  0           conv2/0_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 28, 28, 128)  0           conv2/0_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 28, 28, 640)  0           up_sampling2d_16[0][0]           \n",
      "                                                                 conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2/1_conv2d0 (Conv2D)        (None, 28, 28, 128)  82048       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2/1_bn0 (BatchNorm)         (None, 28, 28, 128)  512         conv2/1_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/1_act0 (LeakyReLU)        (None, 28, 28, 128)  0           conv2/1_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/2_conv2d0 (Conv2D)        (None, 28, 28, 256)  295168      conv2/1_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/2_bn0 (BatchNorm)         (None, 28, 28, 256)  1024        conv2/2_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/2_act0 (LeakyReLU)        (None, 28, 28, 256)  0           conv2/2_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3_conv2d0 (Conv2D)        (None, 28, 28, 128)  32896       conv2/2_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3_bn0 (BatchNorm)         (None, 28, 28, 128)  512         conv2/3_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3_act0 (LeakyReLU)        (None, 28, 28, 128)  0           conv2/3_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/4_conv2d0 (Conv2D)        (None, 28, 28, 256)  295168      conv2/3_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/4_bn0 (BatchNorm)         (None, 28, 28, 256)  1024        conv2/4_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/4_act0 (LeakyReLU)        (None, 28, 28, 256)  0           conv2/4_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/5_conv2d0 (Conv2D)        (None, 28, 28, 128)  32896       conv2/4_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/5_bn0 (BatchNorm)         (None, 28, 28, 128)  512         conv2/5_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/5_act0 (LeakyReLU)        (None, 28, 28, 128)  0           conv2/5_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0/6_conv2d0 (Conv2D)        (None, 7, 7, 1024)   4719616     conv0/5_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/6_conv2d0 (Conv2D)        (None, 14, 14, 512)  1180160     conv1/5_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/6_conv2d0 (Conv2D)        (None, 28, 28, 256)  295168      conv2/5_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv0/6_bn0 (BatchNorm)         (None, 7, 7, 1024)   4096        conv0/6_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/6_bn0 (BatchNorm)         (None, 14, 14, 512)  2048        conv1/6_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2/6_bn0 (BatchNorm)         (None, 28, 28, 256)  1024        conv2/6_conv2d0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv0/6_act0 (LeakyReLU)        (None, 7, 7, 1024)   0           conv0/6_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1/6_act0 (LeakyReLU)        (None, 14, 14, 512)  0           conv1/6_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/6_act0 (LeakyReLU)        (None, 28, 28, 256)  0           conv2/6_bn0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0/7_conv2d0 (Conv2D)        (None, 7, 7, 27)     27675       conv0/6_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7_conv2d0 (Conv2D)        (None, 14, 14, 27)   13851       conv1/6_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/7_conv2d0 (Conv2D)        (None, 28, 28, 27)   6939        conv2/6_act0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "yolo_loss (Lambda)              (None, 1)            0           conv0/7_conv2d0[0][0]            \n",
      "                                                                 conv1/7_conv2d0[0][0]            \n",
      "                                                                 conv2/7_conv2d0[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 34,173,585\n",
      "Trainable params: 21,520,465\n",
      "Non-trainable params: 12,653,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_Dir=\"{}/output/synthetic\".format(ROOT)\n",
    "if not os.path.isdir(Model_Dir):\n",
    "    os.mkdir(Model_Dir)\n",
    "\n",
    "config = SyntheticDatasetConfig()\n",
    "model = YoloV4(\"training\", config, Model_Dir, backbone=backbone)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "# For large dataset, we prefer to use `SGD` and data generator `datagen` to digest dataset quickly\n",
    "model.fit(dataset, optimizer_type='sgd')\n",
    "elapsed = timeit.default_timer() - start\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
