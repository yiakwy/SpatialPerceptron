{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多目标检测\n",
    "\n",
    "Lei Wang (lwang11@mtu.edu)\n",
    "\n",
    "### Synthetic Dataset (See [Mask RCNN](https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb) )\n",
    "\n",
    "对于多目标检测来说自由数据标注，难度更大，需要更专业的工具。为了克服这个问题，在小规模数据上，进行算法的实验和验证，我们可以通过合成数据集来完成带标注数据的采集，用来进行算法验证。\n",
    "\n",
    "合成数据集通常用于仿真实验，常用的方法包括标准集合形状，3D仿真渲染等。Intel® `Carla`项目于2017年首次公开虚拟仿真的实验设备：用Ureal4构建的仿真场景，动态仿真障碍物，通过模拟MVP矩阵计算的虚拟照相机。随后多个团队进行了相关工程和算法的跟进和开发，成为GAN之后，最具有希望解决大规模数据标注用于模型训练的方法之一。\n",
    "\n",
    "本文首先使用基于MaskRCNN `ShapeDataset`的`SyntheticDataset`生产数据，然后针对多目标算法重点对One-Stage, Two-Stage的检测方法在合成数据集上，进行了分析和实现，最后对街拍视频进行了实时分析。\n",
    "\n",
    "### One-Stage Algorithm\n",
    "\n",
    "单阶段检测方法，具有比较高的速度优势，非常适合实时性需求比较强的算法环境，比如高速行驶的无人车辆。通过剪枝和NAS优化，还可以达到更加小的体积和推理速度，从而非常合适在端部署。\n",
    "\n",
    "##### YoloV4: YoloV3 with various optimization\n",
    "\n",
    "##### SSD\n",
    "\n",
    "最开始的实现是在caffe上做的，我们将用Tensorflow-Keras重新实现上面的的算法，并且运用最新的优化技巧。\n",
    "\n",
    "\n",
    "### Two-Stage Algorithm\n",
    "\n",
    "\n",
    "##### Maks-RCNN (implemented in PaddlePaddle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.8/bin/python\n",
      "/home/ma-user/work\n",
      "[name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15872484967\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7894393904878223262\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:0c.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!pwd\n",
    "\n",
    "# nvidia-smi executed from modelarts notebook does not work\n",
    "# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "  local_device_protos = device_lib.list_local_devices()\n",
    "  return [device_proto for device_proto in local_device_protos if device_proto.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 15 Jul, 2016\n",
    "\n",
    "@author: wangyi\n",
    "'''\n",
    "\n",
    "import os\n",
    "# from config import cfg\n",
    "import importlib\n",
    "import global_settings\n",
    "\n",
    "ENVIRON_CONFIG = \"config\"\n",
    "\n",
    "try:\n",
    "  basestring\n",
    "except NameError:\n",
    "  basestring = str\n",
    "\n",
    "class ImproperlyConfigured(Exception): pass\n",
    "\n",
    "class Settings:\n",
    "\n",
    "    def __init__(self, custom_settings=None):\n",
    "        # update global settings\n",
    "        for setting in dir(global_settings):\n",
    "            if setting.isupper() and not setting.startswith(\"__\"):\n",
    "                setattr(self, setting, getattr(global_settings, setting))\n",
    "\n",
    "        if custom_settings is None:\n",
    "            custom_settings = os.environ.get(ENVIRON_CONFIG)\n",
    "        if custom_settings is not None and isinstance(custom_settings, basestring):\n",
    "            try:\n",
    "                custom_settings = importlib.import_module(custom_settings)\n",
    "            except Exception as ex:\n",
    "                raise ImproperlyConfigured(\"\")\n",
    "\n",
    "        self._setting_module = custom_settings\n",
    "        if custom_settings is not None:\n",
    "            self._overriden_vals = set()\n",
    "            for setting in dir(custom_settings):\n",
    "                if setting.isupper():\n",
    "                    val = getattr(custom_settings, setting)\n",
    "                    # do some checking\n",
    "\n",
    "                    # overriden\n",
    "                    setattr(self, setting, val)\n",
    "                    self._overriden_vals.add(setting)\n",
    "\n",
    "    def __str__(self):\n",
    "        ret = []\n",
    "        ret.append(\"\\nConfigurations:\\n\")\n",
    "        for setting in dir(self):\n",
    "            if setting.isupper() and not setting.startswith(\"__\"):\n",
    "                ret.append(\"{:30} {}\\n\".format(setting, getattr(self, setting)))\n",
    "        ret.append(\"\\n\")\n",
    "        return \"\".join(ret)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Setting Object: {}>\".format(self._setting_module.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Project Root\n",
    "Project_ROOT = os.path.abspath(\".\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个动态配置文件对象\n",
    "\n",
    "Python提供了descriptor framework，各种工程实践表明，将配置文件通过，局部py配置文件（因为Python本身是动态语言，可以动态加载代码），读取配置文件的加载对象来完成比较好。\n",
    "\n",
    "本例虽然是针对合成数据集做实验，但是仍然使用ImageNet作为预训练模型。因此要求输入图像至少满足`221x221`大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_SHAPE                    [221, 221, 3]\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "VALIDATION_STEPS               5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adapt codes from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
    "class SyntheticDatasetConfig(Settings):\n",
    "    \"\"\"Configuration for training on the toy synthetic dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy synthetic dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "    # dims\n",
    "    # Used for our Image net pretrained model, at last to be 221x221\n",
    "    IMAGE_SHAPE = [221, 221, 3]\n",
    "\n",
    "config = SyntheticDatasetConfig()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 15 Jul, 2019\n",
    "\n",
    "@author: wangyi\n",
    "'''\n",
    "\n",
    "# utils\n",
    "\n",
    "def read_img(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise ValueError(\"Image path [%s] does not exist.\" % (file_path))\n",
    "    im = cv2.imread(file_path)\n",
    "    im = im.astype(np.float32, copy=False)\n",
    "    im = cv2.resize(im, (config.HEIGHT, config.WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    return im\n",
    "\n",
    "def load_images(files):\n",
    "    count = len(files)\n",
    "    X = np.ndarray((count, config.HEIGHT, config.WIDTH, config.CHANNEL), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(files):\n",
    "        image = read_img(image_file)\n",
    "        X[i] = image\n",
    "    return X\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] * (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def IoU(left_box, right_box, left_area, right_area):\n",
    "    # Compute intersection areas\n",
    "    x1 = max(left_box[0], right_box[0])\n",
    "    y1 = max(left_box[1], right_box[1])\n",
    "    x2 = min(left_box[2], right_box[2])\n",
    "    y2 = min(left_box[3], right_box[3])\n",
    "    \n",
    "    h = max(0, y2 - y1)\n",
    "    w = max(0, x2 - x1)\n",
    "    \n",
    "    overlap = float(w * h)\n",
    "    union = left_area + right_area - overlap\n",
    "    iou = overlap / union\n",
    "    return iou\n",
    "\n",
    "# Non-Max Suppression: simliar to tf.image.non_max_suppression for non-symbolic computation\n",
    "# see https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/utils.py\n",
    "def nms(boxes, scores=None, threshold=0.3):\n",
    "    \"\"\"\n",
    "    @param boxes: np.array with standard tensorflow box order, [x1, y1, x2, y2]\n",
    "    @param scores: np.array\n",
    "    @param threshold: float32\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Compute box area: (x2 - x1) * (y2 - y1)\n",
    "    area = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:,1])\n",
    "    \n",
    "    if scores is not None:\n",
    "        # Sort boxes indices by box scores\n",
    "        idx = scores.argsort()[::-1]\n",
    "    else:\n",
    "        # see https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/\n",
    "        # Sort boxes indices by bottom-right y-coordinates of bounding box\n",
    "        idx = np.argsort(boxes[:,3])\n",
    "        \n",
    "    picked = []\n",
    "    \n",
    "    while len(idx) > 0:\n",
    "        # Pick one to the list\n",
    "        i = idx[0]\n",
    "        picked.append(i)\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = np.array([IoU(boxes[i], boxes[j], area[i], area[j]) for j in idx[1:]])\n",
    "        remove_idx = np.where(ious > threshold)[0] + 1\n",
    "        # Remove indices of overlapped boxes\n",
    "        idx = np.delete(idx, remove_idx)\n",
    "        idx = np.delete(idx, 0)\n",
    "    return np.array(picked, dtype=np.int32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 20 May, 2019\n",
    "\n",
    "@author: wangyi\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# visualization toolkits\n",
    "\n",
    "def save_instances(image, boxes, masks, class_ids, class_names, scores):\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "    scores = scores or [1.0] * n_instances\n",
    "    \n",
    "    if not n_instances:\n",
    "        print(\"No instances to display!\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    out = masked_image\n",
    "    \n",
    "    for i in range(n_instances):\n",
    "        color = colors[i]\n",
    "        \n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        \n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        mask = masks[:, :, i]\n",
    "        \n",
    "        class_id = class_ids[i]\n",
    "        score = scores[i]\n",
    "        label = class_names[class_id]\n",
    "        \n",
    "        if label is not 'person':\n",
    "            continue;\n",
    "        \n",
    "        caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        \n",
    "        masked_image = apply_mask(masked_image, mask, color)\n",
    "        masked_image_with_boxes = cv2.rectangle(masked_image, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Mask Polygon\n",
    "        padded_mask = np.zeros(\n",
    "          (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8\n",
    "        )\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        # contours = find_contours(padded_mask, 0.5)\n",
    "        _, contours, _ = cv2.findContours(padded_mask, \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        masked_image_with_contours_plus_boxes = cv2.drawContours(masked_image_with_boxes, contours, -1, (0, 255, 0), 1)\n",
    "        \n",
    "        out = cv2.putText(\n",
    "            masked_image_with_contours_plus_boxes, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "\n",
    "        masked_image = out\n",
    "    return out\n",
    "\n",
    "def display(im, ax=None):\n",
    "    figsize = (16,16)\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "    height, width = im.shape[:2]\n",
    "    size = (width, height)\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(im.astype(np.uint8))\n",
    "    return ax\n",
    "    \n",
    "def set_title(ax, caption):\n",
    "    ax.set_title(caption, fontsize=9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # path, directory utilities\n",
    "import cv2\n",
    "import glob # used for extract images from data_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import colorsys\n",
    "\n",
    "# @todo : TODO\n",
    "class Dataset:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self._name = name\n",
    "        self._class_names = []\n",
    "        self._data_path = None\n",
    "        self._dataset_path = None\n",
    "        self._dataset_meta = {}\n",
    "        self._images_info = []\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "\n",
    "    @property\n",
    "    def images_info(self):\n",
    "        return self._images_info\n",
    "    \n",
    "    @property\n",
    "    def data_path(self):\n",
    "        return self._data_path\n",
    "    \n",
    "    # @todo TODO\n",
    "    def add_class(self):\n",
    "        pass\n",
    "    \n",
    "    def add_image(self, source, image_id, path, **kwargs):\n",
    "        image_info = {\n",
    "            \"source\": source,\n",
    "            \"id\": image_id,\n",
    "            \"path\": path\n",
    "        }\n",
    "        image_info.update(kwargs)\n",
    "        self._images_info.append(image_info)\n",
    "\n",
    "\n",
    "class Preprocessor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.close = False\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.type = \"Images\"\n",
    "\n",
    "    def __call__(self, data, labels=None):\n",
    "        data = data.astype('float32')\n",
    "        if  self.close is False:\n",
    "            self.mean = np.mean(data, axis=(0, 1, 2, 3))\n",
    "            self.std = np.std(data, axis=(0, 1, 2, 3))\n",
    "            self.close = True\n",
    "\n",
    "        data = (data - self.mean) / (self.std + 1e-6)\n",
    "        if  labels is not None:\n",
    "            labels = keras.utils.to_categorical(labels, config.NUM_CLASSES)\n",
    "        return (data, labels)\n",
    "\n",
    "    def save(self, exported_path):\n",
    "        data = {\n",
    "        \"mean\": to_unicode(self.mean),\n",
    "        \"std\": to_unicode(self.std)\n",
    "        }\n",
    "        with io.open(exported_path, 'w', encoding='utf8') as f:\n",
    "            dumped = json.dumps(data,\n",
    "                    indent=4, sort_keys=True,\n",
    "                    separators=(',', ': '), ensure_ascii=False)\n",
    "\n",
    "            f.write(to_unicode(dumped))\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from(exported_path):\n",
    "        with open(exported_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            preprocessor = Preprocessor()\n",
    "            preprocessor.mean = data['mean']\n",
    "            preprocessor.std = data['std']\n",
    "            return preprocessor\n",
    "\n",
    "    \n",
    "# adapt codes from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
    "# we want to use the generated data to train our yolov3 neural network\n",
    "class SyntheticDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mode=None, name=\"SyntheticShapes\", mask_on=True):\n",
    "        Dataset.__init__(self, name)\n",
    "        # _data_path is None\n",
    "        # _dataset_path is None\n",
    "        self._class_names = [\n",
    "            {\"source\": \"\", \"id\": 0, \"name\": \"BG\"},\n",
    "            {\"source\": \"\", \"id\": 1, \"name\": \"Square\"},\n",
    "            {\"source\": \"\", \"id\": 2, \"name\": \"Circle\"},\n",
    "            {\"source\": \"\", \"id\": 3, \"name\": \"Triangle\"}\n",
    "        ]\n",
    "        self._mode = mode # defaults to training\n",
    "        self._mask_on = mask_on\n",
    "        \n",
    "        self._RANDOM_SAMPLING_ON = True\n",
    "        self._rois = []\n",
    "        # images preprocessor\n",
    "        self._preprocessor = Preprocessor()\n",
    "        # data holders\n",
    "        self._train_data = None\n",
    "        self._train_labels = None\n",
    "        self._test_data = None\n",
    "        self._test_labels = None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return [c[\"name\"] for c in self._class_names]\n",
    "    \n",
    "    # TODO: implement `load_${specific_name_for_the_dataset_to_be_loaded}` method\n",
    "    def load_synthetic_geometries(self, count, height, width, test_size=0.25):\n",
    "        self.count = count\n",
    "        # Add images & Rois\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_shape_rois(height, width)\n",
    "            self.add_image(\"\", image_id=i, path=None,\n",
    "                          height=height, width=width,\n",
    "                          bg_color=bg_color, shapes=shapes)\n",
    "            self.add_rois(i)\n",
    "            \n",
    "        \n",
    "        labeled_images = self._images_info\n",
    "        rois = self._rois\n",
    "        train_data, test_data, train_rois, test_rois = train_test_split(labeled_images, rois, test_size=test_size, random_state=10)\n",
    "        \n",
    "        self._train_data = train_data\n",
    "        self._train_rois = train_rois\n",
    "        self._test_data  = test_data\n",
    "        self._test_data  = test_rois\n",
    "        \n",
    "        return (train_data, test_data, train_rois, test_rois)\n",
    "        \n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1,1,3]) * 255 # channel last\n",
    "        background_img = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        background_img = background_img * bg_color.astype(np.uint8)\n",
    "        image = background_img\n",
    "        for shape, color, roi in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, roi, color)\n",
    "            if self._mask_on:\n",
    "                # @todo TODO load mask: This may consume large volumne of memory\n",
    "                pass\n",
    "        return image\n",
    "    \n",
    "    def add_rois(self, image_id):\n",
    "        boxes = self.load_bbox(image_id)\n",
    "        self._rois.append({\n",
    "            \"boxes\": boxes,\n",
    "            \"mask\": None\n",
    "        })\n",
    "    \n",
    "    def load_bbox(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        return [roi for shape, color, roi in info['shapes']]\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        info = self._images_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, roi) in enumerate(shapes):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(), shape, roi, 1)\n",
    "            \n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Extract class_ids\n",
    "        class_ids = np.array([img_desc[0] for img_desc in shapes], dtype=np.int32)\n",
    "        return mask.astype(np.bool), class_ids\n",
    "    \n",
    "    def draw_shape(self, img, shape, roi, color):\n",
    "        x1, y1, x2, y2 = roi\n",
    "        centre_x = int((x1 + x2) / 2)\n",
    "        centre_y = int((y1 + y2) / 2)\n",
    "        r = int((x2 - x1) / 2)\n",
    "        \n",
    "        if hasattr(color, \"__len__\"):\n",
    "            color = list(map(lambda c: c * 255, color))\n",
    "        else:\n",
    "            color = color * 255\n",
    "        \n",
    "        # in OpenCV3, there is no cv2.CV_AA attribute, see http://bugsinmycodes.blogspot.com/2016/11/opencv3-no-attribute-name-cvaa.html\n",
    "        # Despite of choice of integer 8 as line type, I recommend you to use Anti-aliased algorithm: https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm\n",
    "        try:\n",
    "            LINE_TYPE = cv2.CV_AA\n",
    "        except:\n",
    "            LINE_TYPE = cv2.LINE_AA\n",
    "        \n",
    "        class_names = self.class_names\n",
    "        if class_names[shape] == 'Square':\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, -1, lineType=LINE_TYPE, shift=0)\n",
    "        elif class_names[shape] == 'Circle':\n",
    "            cv2.circle(img, (centre_x, centre_y), r, color, -1, lineType=LINE_TYPE, shift=0)\n",
    "        elif class_names[shape] == 'Triangle':\n",
    "            Points = np.array([[\n",
    "                                (centre_x, centre_y-r),\n",
    "                                (centre_x-r/math.sin(math.radians(60)), centre_y+r),\n",
    "                                (centre_x+r/math.sin(math.radians(60)), centre_y+r)\n",
    "                              ]], dtype=np.int32)\n",
    "            # linear scanning algorithm\n",
    "            cv2.fillPoly(img, Points, color, lineType=LINE_TYPE, shift=0)\n",
    "        return img\n",
    "    \n",
    "    # @todo TODO\n",
    "    def random_shape(self, height, width):\n",
    "        # shape\n",
    "        shape = random.choice(range(1,4))\n",
    "        # center x, y\n",
    "        radius = 20\n",
    "        y = random.randint(radius, height - radius - 1)\n",
    "        x = random.randint(radius, width - radius - 1)\n",
    "        # size\n",
    "        r = random.randint(radius, int(height / 4))\n",
    "        roi = (x-r, y-r, x+r, y+r)\n",
    "        return shape, roi\n",
    "    \n",
    "    def random_shape_rois(self, height, width, threshold=0.3):        \n",
    "        # Generate shapes and rois\n",
    "        shapes = []\n",
    "        rois = []\n",
    "        N = random.randint(1, 4)\n",
    "        # Pick a random color for background with sequence 0\n",
    "        colors = random_colors(N+1)\n",
    "        bg_color = colors[0]\n",
    "        for i in range(N):\n",
    "            shape, roi = self.random_shape(height, width)\n",
    "            shapes.append((shape, colors[i+1], roi))\n",
    "            rois.append(roi)\n",
    "            \n",
    "        # Apply Non-Max Suppression (NMS) with the threshold (defaults to 0.3) to avoid shapes covering each other\n",
    "        kept_idx = nms(np.array(rois), np.arange(N), threshold)\n",
    "        shapes = [shape for i, shape in enumerate(shapes) if i in kept_idx]\n",
    "        # \n",
    "        return bg_color, shapes\n",
    "    \n",
    "    def train_reader(self):\n",
    "        \n",
    "        # @todo : TODO\n",
    "        def reader():\n",
    "            pass\n",
    "        \n",
    "        return reader\n",
    "    \n",
    "    def test_reader(self):\n",
    "        \n",
    "        # @todo : TODO\n",
    "        def reader():\n",
    "            pass\n",
    "        \n",
    "        return reader\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集生成测试\n",
    "\n",
    "生成数据的核心是生成需要人工标注的BBouding Box，对于需要做实例分割(Instance Segmentation)的基准真值(Ground True)，还需要生成掩码标注，可以极大的节省人力对模型进行初步训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 24 info:\n",
      "bg_color (0.0, 0.0, 1.0)\n",
      "images 410 info:\n",
      "bg_color (1.0, 0.0, 0.0)\n",
      "images 370 info:\n",
      "bg_color (1.0, 0.0, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/matplotlib/figure.py:2299: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/matplotlib/figure.py:2117: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n",
      "  warnings.warn(\"This figure was using constrained_layout==True, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 201 info:\n",
      "bg_color (1.0, 0.0, 0.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = SyntheticDataset()\n",
    "dataset.load_synthetic_geometries(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "\n",
    "sample_idx = np.random.choice(range(dataset.count), 4)\n",
    "images_info = dataset.images_info\n",
    "N = 4\n",
    "for idx in sample_idx:\n",
    "    info = images_info[idx]\n",
    "    print(\"images %s info:\" % idx)\n",
    "    print(\"bg_color\", info['bg_color'])\n",
    "    \n",
    "    image = dataset.load_image(idx)\n",
    "    boxes = dataset.load_bbox(idx)\n",
    "    masks, class_ids = dataset.load_mask(idx)\n",
    "    \n",
    "    # masked_image = save_instances(image, np.array(boxes), masks, class_ids, dataset.class_names, None)\n",
    "    # display(masked_image)\n",
    "    \n",
    "    n_instances = len(class_ids)\n",
    "    cols = n_instances\n",
    "    mask_color = [1, 1, 1]\n",
    "    \n",
    "    # Since we have various of columns images for each row, \n",
    "    # https://matplotlib.org/3.1.1/tutorials/intermediate/gridspec.html\n",
    "    \n",
    "    figsize = (16, int(16 / (N+1)))\n",
    "\n",
    "    grids_kw = { \n",
    "        \"wspace\": 0.05\n",
    "    }\n",
    "    _, axes = plt.subplots(1, N+1, figsize=figsize,\n",
    "                                      constrained_layout=True,\n",
    "                                      sharey='all',\n",
    "                                      gridspec_kw=grids_kw)\n",
    "    \n",
    "    if cols == 0:\n",
    "        axes = [axes]\n",
    "    display(image, ax=axes[0])\n",
    "    set_title(axes[0], \"{} shapes: H x W = {}x{}\".format(len(info['shapes']), image.shape[0], image.shape[1]))\n",
    "        \n",
    "    for i in range(n_instances):\n",
    "        class_id = class_ids[i]\n",
    "        mask = masks[:, :, i]\n",
    "        masked_image = image.copy()\n",
    "        masked_image = apply_mask(masked_image, mask, mask_color, alpha=1.0)\n",
    "        shape_id = info['shapes'][i][0]\n",
    "        title = dataset.class_names[shape_id]\n",
    "        ax = axes[i+1]\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        ax.imshow(masked_image.astype(np.uint8), cmap=\"Blues_r\",\n",
    "                 norm=None, interpolation=None)\n",
    "    for i in range(n_instances, N):\n",
    "        ax = axes[i+1]\n",
    "        ax.axis(\"off\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YoloV4\n",
    "\n",
    "YoloV4基于YoloV3. YoloV3由imagenet主干网络，ResNet50, ResNet101, DarkNet，组成其前身是yolo, SSD, 成于Faster RCNN， MaskRCNN之后，以较快的速度、较小的模型参数适用在对推理速度，体积大小要求比较高的实时场景：比如无人车感知模块模块，IOT设备中的摄像头感知模块等。\n",
    "\n",
    "除了常用的Data Agumentation，BN，Batch-Optimizer选取等技巧，这里参考Stronger Yolov3[1]的研究成果，通过Keras给出实现（见Keras 2 tensorflow代码用于部署），重点对一下组网模块，在合成数据集进行研究。本文还参考了[2]，尤其是paddleCV[3]对实现进行了改进。\n",
    "\n",
    "- ImageNet特征提取模组\n",
    "    - ResNet50\n",
    "    - Darknet\n",
    "- FPN特征尺度适配模组\n",
    "- cosine learning rate[1]\n",
    "- GIOU[2]\n",
    "\n",
    "在YoloV3输出的每一个像素在深度上，对应一组BBox：每个BBox坐标(4个自由度)，前景概率分数(Objectness)(1个自由度)，以及类别识别分数（C）。因此YoloV3是一个将分类器，回归器都用，回归的目标函数求解的目标检测模型。\n",
    "\n",
    "```txt\n",
    "[1] https://github.com/Stinky-Tofu/Stronger-yolo/tree/master/v2\n",
    "[2] https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/?source=post_page---------------------------\n",
    "[3] https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/yolov3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator # used for data augumentation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import Callback, EarlyStopping, TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.engine as KE\n",
    "import keras.models as KM\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': ['n01440764', 'tench'], '1': ['n01443537', 'goldfish'], '2': ['n01484850', 'great_white_shark'], '3': ['n01491361', 'tiger_shark'], '4': ['n01494475', 'hammerhead'], '5': ['n01496331', 'electric_ray'], '6': ['n01498041', 'stingray'], '7': ['n01514668', 'cock'], '8': ['n01514859', 'hen'], '9': ['n01518878', 'ostrich'], '10': ['n01530575', 'brambling'], '11': ['n01531178', 'goldfinch'], '12': ['n01532829', 'house_finch'], '13': ['n01534433', 'junco'], '14': ['n01537544', 'indigo_bunting'], '15': ['n01558993', 'robin'], '16': ['n01560419', 'bulbul'], '17': ['n01580077', 'jay'], '18': ['n01582220', 'magpie'], '19': ['n01592084', 'chickadee'], '20': ['n01601694', 'water_ouzel'], '21': ['n01608432', 'kite'], '22': ['n01614925', 'bald_eagle'], '23': ['n01616318', 'vulture'], '24': ['n01622779', 'great_grey_owl'], '25': ['n01629819', 'European_fire_salamander'], '26': ['n01630670', 'common_newt'], '27': ['n01631663', 'eft'], '28': ['n01632458', 'spotted_salamander'], '29': ['n01632777', 'axolotl'], '30': ['n01641577', 'bullfrog'], '31': ['n01644373', 'tree_frog'], '32': ['n01644900', 'tailed_frog'], '33': ['n01664065', 'loggerhead'], '34': ['n01665541', 'leatherback_turtle'], '35': ['n01667114', 'mud_turtle'], '36': ['n01667778', 'terrapin'], '37': ['n01669191', 'box_turtle'], '38': ['n01675722', 'banded_gecko'], '39': ['n01677366', 'common_iguana'], '40': ['n01682714', 'American_chameleon'], '41': ['n01685808', 'whiptail'], '42': ['n01687978', 'agama'], '43': ['n01688243', 'frilled_lizard'], '44': ['n01689811', 'alligator_lizard'], '45': ['n01692333', 'Gila_monster'], '46': ['n01693334', 'green_lizard'], '47': ['n01694178', 'African_chameleon'], '48': ['n01695060', 'Komodo_dragon'], '49': ['n01697457', 'African_crocodile'], '50': ['n01698640', 'American_alligator'], '51': ['n01704323', 'triceratops'], '52': ['n01728572', 'thunder_snake'], '53': ['n01728920', 'ringneck_snake'], '54': ['n01729322', 'hognose_snake'], '55': ['n01729977', 'green_snake'], '56': ['n01734418', 'king_snake'], '57': ['n01735189', 'garter_snake'], '58': ['n01737021', 'water_snake'], '59': ['n01739381', 'vine_snake'], '60': ['n01740131', 'night_snake'], '61': ['n01742172', 'boa_constrictor'], '62': ['n01744401', 'rock_python'], '63': ['n01748264', 'Indian_cobra'], '64': ['n01749939', 'green_mamba'], '65': ['n01751748', 'sea_snake'], '66': ['n01753488', 'horned_viper'], '67': ['n01755581', 'diamondback'], '68': ['n01756291', 'sidewinder'], '69': ['n01768244', 'trilobite'], '70': ['n01770081', 'harvestman'], '71': ['n01770393', 'scorpion'], '72': ['n01773157', 'black_and_gold_garden_spider'], '73': ['n01773549', 'barn_spider'], '74': ['n01773797', 'garden_spider'], '75': ['n01774384', 'black_widow'], '76': ['n01774750', 'tarantula'], '77': ['n01775062', 'wolf_spider'], '78': ['n01776313', 'tick'], '79': ['n01784675', 'centipede'], '80': ['n01795545', 'black_grouse'], '81': ['n01796340', 'ptarmigan'], '82': ['n01797886', 'ruffed_grouse'], '83': ['n01798484', 'prairie_chicken'], '84': ['n01806143', 'peacock'], '85': ['n01806567', 'quail'], '86': ['n01807496', 'partridge'], '87': ['n01817953', 'African_grey'], '88': ['n01818515', 'macaw'], '89': ['n01819313', 'sulphur-crested_cockatoo'], '90': ['n01820546', 'lorikeet'], '91': ['n01824575', 'coucal'], '92': ['n01828970', 'bee_eater'], '93': ['n01829413', 'hornbill'], '94': ['n01833805', 'hummingbird'], '95': ['n01843065', 'jacamar'], '96': ['n01843383', 'toucan'], '97': ['n01847000', 'drake'], '98': ['n01855032', 'red-breasted_merganser'], '99': ['n01855672', 'goose'], '100': ['n01860187', 'black_swan'], '101': ['n01871265', 'tusker'], '102': ['n01872401', 'echidna'], '103': ['n01873310', 'platypus'], '104': ['n01877812', 'wallaby'], '105': ['n01882714', 'koala'], '106': ['n01883070', 'wombat'], '107': ['n01910747', 'jellyfish'], '108': ['n01914609', 'sea_anemone'], '109': ['n01917289', 'brain_coral'], '110': ['n01924916', 'flatworm'], '111': ['n01930112', 'nematode'], '112': ['n01943899', 'conch'], '113': ['n01944390', 'snail'], '114': ['n01945685', 'slug'], '115': ['n01950731', 'sea_slug'], '116': ['n01955084', 'chiton'], '117': ['n01968897', 'chambered_nautilus'], '118': ['n01978287', 'Dungeness_crab'], '119': ['n01978455', 'rock_crab'], '120': ['n01980166', 'fiddler_crab'], '121': ['n01981276', 'king_crab'], '122': ['n01983481', 'American_lobster'], '123': ['n01984695', 'spiny_lobster'], '124': ['n01985128', 'crayfish'], '125': ['n01986214', 'hermit_crab'], '126': ['n01990800', 'isopod'], '127': ['n02002556', 'white_stork'], '128': ['n02002724', 'black_stork'], '129': ['n02006656', 'spoonbill'], '130': ['n02007558', 'flamingo'], '131': ['n02009229', 'little_blue_heron'], '132': ['n02009912', 'American_egret'], '133': ['n02011460', 'bittern'], '134': ['n02012849', 'crane'], '135': ['n02013706', 'limpkin'], '136': ['n02017213', 'European_gallinule'], '137': ['n02018207', 'American_coot'], '138': ['n02018795', 'bustard'], '139': ['n02025239', 'ruddy_turnstone'], '140': ['n02027492', 'red-backed_sandpiper'], '141': ['n02028035', 'redshank'], '142': ['n02033041', 'dowitcher'], '143': ['n02037110', 'oystercatcher'], '144': ['n02051845', 'pelican'], '145': ['n02056570', 'king_penguin'], '146': ['n02058221', 'albatross'], '147': ['n02066245', 'grey_whale'], '148': ['n02071294', 'killer_whale'], '149': ['n02074367', 'dugong'], '150': ['n02077923', 'sea_lion'], '151': ['n02085620', 'Chihuahua'], '152': ['n02085782', 'Japanese_spaniel'], '153': ['n02085936', 'Maltese_dog'], '154': ['n02086079', 'Pekinese'], '155': ['n02086240', 'Shih-Tzu'], '156': ['n02086646', 'Blenheim_spaniel'], '157': ['n02086910', 'papillon'], '158': ['n02087046', 'toy_terrier'], '159': ['n02087394', 'Rhodesian_ridgeback'], '160': ['n02088094', 'Afghan_hound'], '161': ['n02088238', 'basset'], '162': ['n02088364', 'beagle'], '163': ['n02088466', 'bloodhound'], '164': ['n02088632', 'bluetick'], '165': ['n02089078', 'black-and-tan_coonhound'], '166': ['n02089867', 'Walker_hound'], '167': ['n02089973', 'English_foxhound'], '168': ['n02090379', 'redbone'], '169': ['n02090622', 'borzoi'], '170': ['n02090721', 'Irish_wolfhound'], '171': ['n02091032', 'Italian_greyhound'], '172': ['n02091134', 'whippet'], '173': ['n02091244', 'Ibizan_hound'], '174': ['n02091467', 'Norwegian_elkhound'], '175': ['n02091635', 'otterhound'], '176': ['n02091831', 'Saluki'], '177': ['n02092002', 'Scottish_deerhound'], '178': ['n02092339', 'Weimaraner'], '179': ['n02093256', 'Staffordshire_bullterrier'], '180': ['n02093428', 'American_Staffordshire_terrier'], '181': ['n02093647', 'Bedlington_terrier'], '182': ['n02093754', 'Border_terrier'], '183': ['n02093859', 'Kerry_blue_terrier'], '184': ['n02093991', 'Irish_terrier'], '185': ['n02094114', 'Norfolk_terrier'], '186': ['n02094258', 'Norwich_terrier'], '187': ['n02094433', 'Yorkshire_terrier'], '188': ['n02095314', 'wire-haired_fox_terrier'], '189': ['n02095570', 'Lakeland_terrier'], '190': ['n02095889', 'Sealyham_terrier'], '191': ['n02096051', 'Airedale'], '192': ['n02096177', 'cairn'], '193': ['n02096294', 'Australian_terrier'], '194': ['n02096437', 'Dandie_Dinmont'], '195': ['n02096585', 'Boston_bull'], '196': ['n02097047', 'miniature_schnauzer'], '197': ['n02097130', 'giant_schnauzer'], '198': ['n02097209', 'standard_schnauzer'], '199': ['n02097298', 'Scotch_terrier'], '200': ['n02097474', 'Tibetan_terrier'], '201': ['n02097658', 'silky_terrier'], '202': ['n02098105', 'soft-coated_wheaten_terrier'], '203': ['n02098286', 'West_Highland_white_terrier'], '204': ['n02098413', 'Lhasa'], '205': ['n02099267', 'flat-coated_retriever'], '206': ['n02099429', 'curly-coated_retriever'], '207': ['n02099601', 'golden_retriever'], '208': ['n02099712', 'Labrador_retriever'], '209': ['n02099849', 'Chesapeake_Bay_retriever'], '210': ['n02100236', 'German_short-haired_pointer'], '211': ['n02100583', 'vizsla'], '212': ['n02100735', 'English_setter'], '213': ['n02100877', 'Irish_setter'], '214': ['n02101006', 'Gordon_setter'], '215': ['n02101388', 'Brittany_spaniel'], '216': ['n02101556', 'clumber'], '217': ['n02102040', 'English_springer'], '218': ['n02102177', 'Welsh_springer_spaniel'], '219': ['n02102318', 'cocker_spaniel'], '220': ['n02102480', 'Sussex_spaniel'], '221': ['n02102973', 'Irish_water_spaniel'], '222': ['n02104029', 'kuvasz'], '223': ['n02104365', 'schipperke'], '224': ['n02105056', 'groenendael'], '225': ['n02105162', 'malinois'], '226': ['n02105251', 'briard'], '227': ['n02105412', 'kelpie'], '228': ['n02105505', 'komondor'], '229': ['n02105641', 'Old_English_sheepdog'], '230': ['n02105855', 'Shetland_sheepdog'], '231': ['n02106030', 'collie'], '232': ['n02106166', 'Border_collie'], '233': ['n02106382', 'Bouvier_des_Flandres'], '234': ['n02106550', 'Rottweiler'], '235': ['n02106662', 'German_shepherd'], '236': ['n02107142', 'Doberman'], '237': ['n02107312', 'miniature_pinscher'], '238': ['n02107574', 'Greater_Swiss_Mountain_dog'], '239': ['n02107683', 'Bernese_mountain_dog'], '240': ['n02107908', 'Appenzeller'], '241': ['n02108000', 'EntleBucher'], '242': ['n02108089', 'boxer'], '243': ['n02108422', 'bull_mastiff'], '244': ['n02108551', 'Tibetan_mastiff'], '245': ['n02108915', 'French_bulldog'], '246': ['n02109047', 'Great_Dane'], '247': ['n02109525', 'Saint_Bernard'], '248': ['n02109961', 'Eskimo_dog'], '249': ['n02110063', 'malamute'], '250': ['n02110185', 'Siberian_husky'], '251': ['n02110341', 'dalmatian'], '252': ['n02110627', 'affenpinscher'], '253': ['n02110806', 'basenji'], '254': ['n02110958', 'pug'], '255': ['n02111129', 'Leonberg'], '256': ['n02111277', 'Newfoundland'], '257': ['n02111500', 'Great_Pyrenees'], '258': ['n02111889', 'Samoyed'], '259': ['n02112018', 'Pomeranian'], '260': ['n02112137', 'chow'], '261': ['n02112350', 'keeshond'], '262': ['n02112706', 'Brabancon_griffon'], '263': ['n02113023', 'Pembroke'], '264': ['n02113186', 'Cardigan'], '265': ['n02113624', 'toy_poodle'], '266': ['n02113712', 'miniature_poodle'], '267': ['n02113799', 'standard_poodle'], '268': ['n02113978', 'Mexican_hairless'], '269': ['n02114367', 'timber_wolf'], '270': ['n02114548', 'white_wolf'], '271': ['n02114712', 'red_wolf'], '272': ['n02114855', 'coyote'], '273': ['n02115641', 'dingo'], '274': ['n02115913', 'dhole'], '275': ['n02116738', 'African_hunting_dog'], '276': ['n02117135', 'hyena'], '277': ['n02119022', 'red_fox'], '278': ['n02119789', 'kit_fox'], '279': ['n02120079', 'Arctic_fox'], '280': ['n02120505', 'grey_fox'], '281': ['n02123045', 'tabby'], '282': ['n02123159', 'tiger_cat'], '283': ['n02123394', 'Persian_cat'], '284': ['n02123597', 'Siamese_cat'], '285': ['n02124075', 'Egyptian_cat'], '286': ['n02125311', 'cougar'], '287': ['n02127052', 'lynx'], '288': ['n02128385', 'leopard'], '289': ['n02128757', 'snow_leopard'], '290': ['n02128925', 'jaguar'], '291': ['n02129165', 'lion'], '292': ['n02129604', 'tiger'], '293': ['n02130308', 'cheetah'], '294': ['n02132136', 'brown_bear'], '295': ['n02133161', 'American_black_bear'], '296': ['n02134084', 'ice_bear'], '297': ['n02134418', 'sloth_bear'], '298': ['n02137549', 'mongoose'], '299': ['n02138441', 'meerkat'], '300': ['n02165105', 'tiger_beetle'], '301': ['n02165456', 'ladybug'], '302': ['n02167151', 'ground_beetle'], '303': ['n02168699', 'long-horned_beetle'], '304': ['n02169497', 'leaf_beetle'], '305': ['n02172182', 'dung_beetle'], '306': ['n02174001', 'rhinoceros_beetle'], '307': ['n02177972', 'weevil'], '308': ['n02190166', 'fly'], '309': ['n02206856', 'bee'], '310': ['n02219486', 'ant'], '311': ['n02226429', 'grasshopper'], '312': ['n02229544', 'cricket'], '313': ['n02231487', 'walking_stick'], '314': ['n02233338', 'cockroach'], '315': ['n02236044', 'mantis'], '316': ['n02256656', 'cicada'], '317': ['n02259212', 'leafhopper'], '318': ['n02264363', 'lacewing'], '319': ['n02268443', 'dragonfly'], '320': ['n02268853', 'damselfly'], '321': ['n02276258', 'admiral'], '322': ['n02277742', 'ringlet'], '323': ['n02279972', 'monarch'], '324': ['n02280649', 'cabbage_butterfly'], '325': ['n02281406', 'sulphur_butterfly'], '326': ['n02281787', 'lycaenid'], '327': ['n02317335', 'starfish'], '328': ['n02319095', 'sea_urchin'], '329': ['n02321529', 'sea_cucumber'], '330': ['n02325366', 'wood_rabbit'], '331': ['n02326432', 'hare'], '332': ['n02328150', 'Angora'], '333': ['n02342885', 'hamster'], '334': ['n02346627', 'porcupine'], '335': ['n02356798', 'fox_squirrel'], '336': ['n02361337', 'marmot'], '337': ['n02363005', 'beaver'], '338': ['n02364673', 'guinea_pig'], '339': ['n02389026', 'sorrel'], '340': ['n02391049', 'zebra'], '341': ['n02395406', 'hog'], '342': ['n02396427', 'wild_boar'], '343': ['n02397096', 'warthog'], '344': ['n02398521', 'hippopotamus'], '345': ['n02403003', 'ox'], '346': ['n02408429', 'water_buffalo'], '347': ['n02410509', 'bison'], '348': ['n02412080', 'ram'], '349': ['n02415577', 'bighorn'], '350': ['n02417914', 'ibex'], '351': ['n02422106', 'hartebeest'], '352': ['n02422699', 'impala'], '353': ['n02423022', 'gazelle'], '354': ['n02437312', 'Arabian_camel'], '355': ['n02437616', 'llama'], '356': ['n02441942', 'weasel'], '357': ['n02442845', 'mink'], '358': ['n02443114', 'polecat'], '359': ['n02443484', 'black-footed_ferret'], '360': ['n02444819', 'otter'], '361': ['n02445715', 'skunk'], '362': ['n02447366', 'badger'], '363': ['n02454379', 'armadillo'], '364': ['n02457408', 'three-toed_sloth'], '365': ['n02480495', 'orangutan'], '366': ['n02480855', 'gorilla'], '367': ['n02481823', 'chimpanzee'], '368': ['n02483362', 'gibbon'], '369': ['n02483708', 'siamang'], '370': ['n02484975', 'guenon'], '371': ['n02486261', 'patas'], '372': ['n02486410', 'baboon'], '373': ['n02487347', 'macaque'], '374': ['n02488291', 'langur'], '375': ['n02488702', 'colobus'], '376': ['n02489166', 'proboscis_monkey'], '377': ['n02490219', 'marmoset'], '378': ['n02492035', 'capuchin'], '379': ['n02492660', 'howler_monkey'], '380': ['n02493509', 'titi'], '381': ['n02493793', 'spider_monkey'], '382': ['n02494079', 'squirrel_monkey'], '383': ['n02497673', 'Madagascar_cat'], '384': ['n02500267', 'indri'], '385': ['n02504013', 'Indian_elephant'], '386': ['n02504458', 'African_elephant'], '387': ['n02509815', 'lesser_panda'], '388': ['n02510455', 'giant_panda'], '389': ['n02514041', 'barracouta'], '390': ['n02526121', 'eel'], '391': ['n02536864', 'coho'], '392': ['n02606052', 'rock_beauty'], '393': ['n02607072', 'anemone_fish'], '394': ['n02640242', 'sturgeon'], '395': ['n02641379', 'gar'], '396': ['n02643566', 'lionfish'], '397': ['n02655020', 'puffer'], '398': ['n02666196', 'abacus'], '399': ['n02667093', 'abaya'], '400': ['n02669723', 'academic_gown'], '401': ['n02672831', 'accordion'], '402': ['n02676566', 'acoustic_guitar'], '403': ['n02687172', 'aircraft_carrier'], '404': ['n02690373', 'airliner'], '405': ['n02692877', 'airship'], '406': ['n02699494', 'altar'], '407': ['n02701002', 'ambulance'], '408': ['n02704792', 'amphibian'], '409': ['n02708093', 'analog_clock'], '410': ['n02727426', 'apiary'], '411': ['n02730930', 'apron'], '412': ['n02747177', 'ashcan'], '413': ['n02749479', 'assault_rifle'], '414': ['n02769748', 'backpack'], '415': ['n02776631', 'bakery'], '416': ['n02777292', 'balance_beam'], '417': ['n02782093', 'balloon'], '418': ['n02783161', 'ballpoint'], '419': ['n02786058', 'Band_Aid'], '420': ['n02787622', 'banjo'], '421': ['n02788148', 'bannister'], '422': ['n02790996', 'barbell'], '423': ['n02791124', 'barber_chair'], '424': ['n02791270', 'barbershop'], '425': ['n02793495', 'barn'], '426': ['n02794156', 'barometer'], '427': ['n02795169', 'barrel'], '428': ['n02797295', 'barrow'], '429': ['n02799071', 'baseball'], '430': ['n02802426', 'basketball'], '431': ['n02804414', 'bassinet'], '432': ['n02804610', 'bassoon'], '433': ['n02807133', 'bathing_cap'], '434': ['n02808304', 'bath_towel'], '435': ['n02808440', 'bathtub'], '436': ['n02814533', 'beach_wagon'], '437': ['n02814860', 'beacon'], '438': ['n02815834', 'beaker'], '439': ['n02817516', 'bearskin'], '440': ['n02823428', 'beer_bottle'], '441': ['n02823750', 'beer_glass'], '442': ['n02825657', 'bell_cote'], '443': ['n02834397', 'bib'], '444': ['n02835271', 'bicycle-built-for-two'], '445': ['n02837789', 'bikini'], '446': ['n02840245', 'binder'], '447': ['n02841315', 'binoculars'], '448': ['n02843684', 'birdhouse'], '449': ['n02859443', 'boathouse'], '450': ['n02860847', 'bobsled'], '451': ['n02865351', 'bolo_tie'], '452': ['n02869837', 'bonnet'], '453': ['n02870880', 'bookcase'], '454': ['n02871525', 'bookshop'], '455': ['n02877765', 'bottlecap'], '456': ['n02879718', 'bow'], '457': ['n02883205', 'bow_tie'], '458': ['n02892201', 'brass'], '459': ['n02892767', 'brassiere'], '460': ['n02894605', 'breakwater'], '461': ['n02895154', 'breastplate'], '462': ['n02906734', 'broom'], '463': ['n02909870', 'bucket'], '464': ['n02910353', 'buckle'], '465': ['n02916936', 'bulletproof_vest'], '466': ['n02917067', 'bullet_train'], '467': ['n02927161', 'butcher_shop'], '468': ['n02930766', 'cab'], '469': ['n02939185', 'caldron'], '470': ['n02948072', 'candle'], '471': ['n02950826', 'cannon'], '472': ['n02951358', 'canoe'], '473': ['n02951585', 'can_opener'], '474': ['n02963159', 'cardigan'], '475': ['n02965783', 'car_mirror'], '476': ['n02966193', 'carousel'], '477': ['n02966687', \"carpenter's_kit\"], '478': ['n02971356', 'carton'], '479': ['n02974003', 'car_wheel'], '480': ['n02977058', 'cash_machine'], '481': ['n02978881', 'cassette'], '482': ['n02979186', 'cassette_player'], '483': ['n02980441', 'castle'], '484': ['n02981792', 'catamaran'], '485': ['n02988304', 'CD_player'], '486': ['n02992211', 'cello'], '487': ['n02992529', 'cellular_telephone'], '488': ['n02999410', 'chain'], '489': ['n03000134', 'chainlink_fence'], '490': ['n03000247', 'chain_mail'], '491': ['n03000684', 'chain_saw'], '492': ['n03014705', 'chest'], '493': ['n03016953', 'chiffonier'], '494': ['n03017168', 'chime'], '495': ['n03018349', 'china_cabinet'], '496': ['n03026506', 'Christmas_stocking'], '497': ['n03028079', 'church'], '498': ['n03032252', 'cinema'], '499': ['n03041632', 'cleaver'], '500': ['n03042490', 'cliff_dwelling'], '501': ['n03045698', 'cloak'], '502': ['n03047690', 'clog'], '503': ['n03062245', 'cocktail_shaker'], '504': ['n03063599', 'coffee_mug'], '505': ['n03063689', 'coffeepot'], '506': ['n03065424', 'coil'], '507': ['n03075370', 'combination_lock'], '508': ['n03085013', 'computer_keyboard'], '509': ['n03089624', 'confectionery'], '510': ['n03095699', 'container_ship'], '511': ['n03100240', 'convertible'], '512': ['n03109150', 'corkscrew'], '513': ['n03110669', 'cornet'], '514': ['n03124043', 'cowboy_boot'], '515': ['n03124170', 'cowboy_hat'], '516': ['n03125729', 'cradle'], '517': ['n03126707', 'crane'], '518': ['n03127747', 'crash_helmet'], '519': ['n03127925', 'crate'], '520': ['n03131574', 'crib'], '521': ['n03133878', 'Crock_Pot'], '522': ['n03134739', 'croquet_ball'], '523': ['n03141823', 'crutch'], '524': ['n03146219', 'cuirass'], '525': ['n03160309', 'dam'], '526': ['n03179701', 'desk'], '527': ['n03180011', 'desktop_computer'], '528': ['n03187595', 'dial_telephone'], '529': ['n03188531', 'diaper'], '530': ['n03196217', 'digital_clock'], '531': ['n03197337', 'digital_watch'], '532': ['n03201208', 'dining_table'], '533': ['n03207743', 'dishrag'], '534': ['n03207941', 'dishwasher'], '535': ['n03208938', 'disk_brake'], '536': ['n03216828', 'dock'], '537': ['n03218198', 'dogsled'], '538': ['n03220513', 'dome'], '539': ['n03223299', 'doormat'], '540': ['n03240683', 'drilling_platform'], '541': ['n03249569', 'drum'], '542': ['n03250847', 'drumstick'], '543': ['n03255030', 'dumbbell'], '544': ['n03259280', 'Dutch_oven'], '545': ['n03271574', 'electric_fan'], '546': ['n03272010', 'electric_guitar'], '547': ['n03272562', 'electric_locomotive'], '548': ['n03290653', 'entertainment_center'], '549': ['n03291819', 'envelope'], '550': ['n03297495', 'espresso_maker'], '551': ['n03314780', 'face_powder'], '552': ['n03325584', 'feather_boa'], '553': ['n03337140', 'file'], '554': ['n03344393', 'fireboat'], '555': ['n03345487', 'fire_engine'], '556': ['n03347037', 'fire_screen'], '557': ['n03355925', 'flagpole'], '558': ['n03372029', 'flute'], '559': ['n03376595', 'folding_chair'], '560': ['n03379051', 'football_helmet'], '561': ['n03384352', 'forklift'], '562': ['n03388043', 'fountain'], '563': ['n03388183', 'fountain_pen'], '564': ['n03388549', 'four-poster'], '565': ['n03393912', 'freight_car'], '566': ['n03394916', 'French_horn'], '567': ['n03400231', 'frying_pan'], '568': ['n03404251', 'fur_coat'], '569': ['n03417042', 'garbage_truck'], '570': ['n03424325', 'gasmask'], '571': ['n03425413', 'gas_pump'], '572': ['n03443371', 'goblet'], '573': ['n03444034', 'go-kart'], '574': ['n03445777', 'golf_ball'], '575': ['n03445924', 'golfcart'], '576': ['n03447447', 'gondola'], '577': ['n03447721', 'gong'], '578': ['n03450230', 'gown'], '579': ['n03452741', 'grand_piano'], '580': ['n03457902', 'greenhouse'], '581': ['n03459775', 'grille'], '582': ['n03461385', 'grocery_store'], '583': ['n03467068', 'guillotine'], '584': ['n03476684', 'hair_slide'], '585': ['n03476991', 'hair_spray'], '586': ['n03478589', 'half_track'], '587': ['n03481172', 'hammer'], '588': ['n03482405', 'hamper'], '589': ['n03483316', 'hand_blower'], '590': ['n03485407', 'hand-held_computer'], '591': ['n03485794', 'handkerchief'], '592': ['n03492542', 'hard_disc'], '593': ['n03494278', 'harmonica'], '594': ['n03495258', 'harp'], '595': ['n03496892', 'harvester'], '596': ['n03498962', 'hatchet'], '597': ['n03527444', 'holster'], '598': ['n03529860', 'home_theater'], '599': ['n03530642', 'honeycomb'], '600': ['n03532672', 'hook'], '601': ['n03534580', 'hoopskirt'], '602': ['n03535780', 'horizontal_bar'], '603': ['n03538406', 'horse_cart'], '604': ['n03544143', 'hourglass'], '605': ['n03584254', 'iPod'], '606': ['n03584829', 'iron'], '607': ['n03590841', \"jack-o'-lantern\"], '608': ['n03594734', 'jean'], '609': ['n03594945', 'jeep'], '610': ['n03595614', 'jersey'], '611': ['n03598930', 'jigsaw_puzzle'], '612': ['n03599486', 'jinrikisha'], '613': ['n03602883', 'joystick'], '614': ['n03617480', 'kimono'], '615': ['n03623198', 'knee_pad'], '616': ['n03627232', 'knot'], '617': ['n03630383', 'lab_coat'], '618': ['n03633091', 'ladle'], '619': ['n03637318', 'lampshade'], '620': ['n03642806', 'laptop'], '621': ['n03649909', 'lawn_mower'], '622': ['n03657121', 'lens_cap'], '623': ['n03658185', 'letter_opener'], '624': ['n03661043', 'library'], '625': ['n03662601', 'lifeboat'], '626': ['n03666591', 'lighter'], '627': ['n03670208', 'limousine'], '628': ['n03673027', 'liner'], '629': ['n03676483', 'lipstick'], '630': ['n03680355', 'Loafer'], '631': ['n03690938', 'lotion'], '632': ['n03691459', 'loudspeaker'], '633': ['n03692522', 'loupe'], '634': ['n03697007', 'lumbermill'], '635': ['n03706229', 'magnetic_compass'], '636': ['n03709823', 'mailbag'], '637': ['n03710193', 'mailbox'], '638': ['n03710637', 'maillot'], '639': ['n03710721', 'maillot'], '640': ['n03717622', 'manhole_cover'], '641': ['n03720891', 'maraca'], '642': ['n03721384', 'marimba'], '643': ['n03724870', 'mask'], '644': ['n03729826', 'matchstick'], '645': ['n03733131', 'maypole'], '646': ['n03733281', 'maze'], '647': ['n03733805', 'measuring_cup'], '648': ['n03742115', 'medicine_chest'], '649': ['n03743016', 'megalith'], '650': ['n03759954', 'microphone'], '651': ['n03761084', 'microwave'], '652': ['n03763968', 'military_uniform'], '653': ['n03764736', 'milk_can'], '654': ['n03769881', 'minibus'], '655': ['n03770439', 'miniskirt'], '656': ['n03770679', 'minivan'], '657': ['n03773504', 'missile'], '658': ['n03775071', 'mitten'], '659': ['n03775546', 'mixing_bowl'], '660': ['n03776460', 'mobile_home'], '661': ['n03777568', 'Model_T'], '662': ['n03777754', 'modem'], '663': ['n03781244', 'monastery'], '664': ['n03782006', 'monitor'], '665': ['n03785016', 'moped'], '666': ['n03786901', 'mortar'], '667': ['n03787032', 'mortarboard'], '668': ['n03788195', 'mosque'], '669': ['n03788365', 'mosquito_net'], '670': ['n03791053', 'motor_scooter'], '671': ['n03792782', 'mountain_bike'], '672': ['n03792972', 'mountain_tent'], '673': ['n03793489', 'mouse'], '674': ['n03794056', 'mousetrap'], '675': ['n03796401', 'moving_van'], '676': ['n03803284', 'muzzle'], '677': ['n03804744', 'nail'], '678': ['n03814639', 'neck_brace'], '679': ['n03814906', 'necklace'], '680': ['n03825788', 'nipple'], '681': ['n03832673', 'notebook'], '682': ['n03837869', 'obelisk'], '683': ['n03838899', 'oboe'], '684': ['n03840681', 'ocarina'], '685': ['n03841143', 'odometer'], '686': ['n03843555', 'oil_filter'], '687': ['n03854065', 'organ'], '688': ['n03857828', 'oscilloscope'], '689': ['n03866082', 'overskirt'], '690': ['n03868242', 'oxcart'], '691': ['n03868863', 'oxygen_mask'], '692': ['n03871628', 'packet'], '693': ['n03873416', 'paddle'], '694': ['n03874293', 'paddlewheel'], '695': ['n03874599', 'padlock'], '696': ['n03876231', 'paintbrush'], '697': ['n03877472', 'pajama'], '698': ['n03877845', 'palace'], '699': ['n03884397', 'panpipe'], '700': ['n03887697', 'paper_towel'], '701': ['n03888257', 'parachute'], '702': ['n03888605', 'parallel_bars'], '703': ['n03891251', 'park_bench'], '704': ['n03891332', 'parking_meter'], '705': ['n03895866', 'passenger_car'], '706': ['n03899768', 'patio'], '707': ['n03902125', 'pay-phone'], '708': ['n03903868', 'pedestal'], '709': ['n03908618', 'pencil_box'], '710': ['n03908714', 'pencil_sharpener'], '711': ['n03916031', 'perfume'], '712': ['n03920288', 'Petri_dish'], '713': ['n03924679', 'photocopier'], '714': ['n03929660', 'pick'], '715': ['n03929855', 'pickelhaube'], '716': ['n03930313', 'picket_fence'], '717': ['n03930630', 'pickup'], '718': ['n03933933', 'pier'], '719': ['n03935335', 'piggy_bank'], '720': ['n03937543', 'pill_bottle'], '721': ['n03938244', 'pillow'], '722': ['n03942813', 'ping-pong_ball'], '723': ['n03944341', 'pinwheel'], '724': ['n03947888', 'pirate'], '725': ['n03950228', 'pitcher'], '726': ['n03954731', 'plane'], '727': ['n03956157', 'planetarium'], '728': ['n03958227', 'plastic_bag'], '729': ['n03961711', 'plate_rack'], '730': ['n03967562', 'plow'], '731': ['n03970156', 'plunger'], '732': ['n03976467', 'Polaroid_camera'], '733': ['n03976657', 'pole'], '734': ['n03977966', 'police_van'], '735': ['n03980874', 'poncho'], '736': ['n03982430', 'pool_table'], '737': ['n03983396', 'pop_bottle'], '738': ['n03991062', 'pot'], '739': ['n03992509', \"potter's_wheel\"], '740': ['n03995372', 'power_drill'], '741': ['n03998194', 'prayer_rug'], '742': ['n04004767', 'printer'], '743': ['n04005630', 'prison'], '744': ['n04008634', 'projectile'], '745': ['n04009552', 'projector'], '746': ['n04019541', 'puck'], '747': ['n04023962', 'punching_bag'], '748': ['n04026417', 'purse'], '749': ['n04033901', 'quill'], '750': ['n04033995', 'quilt'], '751': ['n04037443', 'racer'], '752': ['n04039381', 'racket'], '753': ['n04040759', 'radiator'], '754': ['n04041544', 'radio'], '755': ['n04044716', 'radio_telescope'], '756': ['n04049303', 'rain_barrel'], '757': ['n04065272', 'recreational_vehicle'], '758': ['n04067472', 'reel'], '759': ['n04069434', 'reflex_camera'], '760': ['n04070727', 'refrigerator'], '761': ['n04074963', 'remote_control'], '762': ['n04081281', 'restaurant'], '763': ['n04086273', 'revolver'], '764': ['n04090263', 'rifle'], '765': ['n04099969', 'rocking_chair'], '766': ['n04111531', 'rotisserie'], '767': ['n04116512', 'rubber_eraser'], '768': ['n04118538', 'rugby_ball'], '769': ['n04118776', 'rule'], '770': ['n04120489', 'running_shoe'], '771': ['n04125021', 'safe'], '772': ['n04127249', 'safety_pin'], '773': ['n04131690', 'saltshaker'], '774': ['n04133789', 'sandal'], '775': ['n04136333', 'sarong'], '776': ['n04141076', 'sax'], '777': ['n04141327', 'scabbard'], '778': ['n04141975', 'scale'], '779': ['n04146614', 'school_bus'], '780': ['n04147183', 'schooner'], '781': ['n04149813', 'scoreboard'], '782': ['n04152593', 'screen'], '783': ['n04153751', 'screw'], '784': ['n04154565', 'screwdriver'], '785': ['n04162706', 'seat_belt'], '786': ['n04179913', 'sewing_machine'], '787': ['n04192698', 'shield'], '788': ['n04200800', 'shoe_shop'], '789': ['n04201297', 'shoji'], '790': ['n04204238', 'shopping_basket'], '791': ['n04204347', 'shopping_cart'], '792': ['n04208210', 'shovel'], '793': ['n04209133', 'shower_cap'], '794': ['n04209239', 'shower_curtain'], '795': ['n04228054', 'ski'], '796': ['n04229816', 'ski_mask'], '797': ['n04235860', 'sleeping_bag'], '798': ['n04238763', 'slide_rule'], '799': ['n04239074', 'sliding_door'], '800': ['n04243546', 'slot'], '801': ['n04251144', 'snorkel'], '802': ['n04252077', 'snowmobile'], '803': ['n04252225', 'snowplow'], '804': ['n04254120', 'soap_dispenser'], '805': ['n04254680', 'soccer_ball'], '806': ['n04254777', 'sock'], '807': ['n04258138', 'solar_dish'], '808': ['n04259630', 'sombrero'], '809': ['n04263257', 'soup_bowl'], '810': ['n04264628', 'space_bar'], '811': ['n04265275', 'space_heater'], '812': ['n04266014', 'space_shuttle'], '813': ['n04270147', 'spatula'], '814': ['n04273569', 'speedboat'], '815': ['n04275548', 'spider_web'], '816': ['n04277352', 'spindle'], '817': ['n04285008', 'sports_car'], '818': ['n04286575', 'spotlight'], '819': ['n04296562', 'stage'], '820': ['n04310018', 'steam_locomotive'], '821': ['n04311004', 'steel_arch_bridge'], '822': ['n04311174', 'steel_drum'], '823': ['n04317175', 'stethoscope'], '824': ['n04325704', 'stole'], '825': ['n04326547', 'stone_wall'], '826': ['n04328186', 'stopwatch'], '827': ['n04330267', 'stove'], '828': ['n04332243', 'strainer'], '829': ['n04335435', 'streetcar'], '830': ['n04336792', 'stretcher'], '831': ['n04344873', 'studio_couch'], '832': ['n04346328', 'stupa'], '833': ['n04347754', 'submarine'], '834': ['n04350905', 'suit'], '835': ['n04355338', 'sundial'], '836': ['n04355933', 'sunglass'], '837': ['n04356056', 'sunglasses'], '838': ['n04357314', 'sunscreen'], '839': ['n04366367', 'suspension_bridge'], '840': ['n04367480', 'swab'], '841': ['n04370456', 'sweatshirt'], '842': ['n04371430', 'swimming_trunks'], '843': ['n04371774', 'swing'], '844': ['n04372370', 'switch'], '845': ['n04376876', 'syringe'], '846': ['n04380533', 'table_lamp'], '847': ['n04389033', 'tank'], '848': ['n04392985', 'tape_player'], '849': ['n04398044', 'teapot'], '850': ['n04399382', 'teddy'], '851': ['n04404412', 'television'], '852': ['n04409515', 'tennis_ball'], '853': ['n04417672', 'thatch'], '854': ['n04418357', 'theater_curtain'], '855': ['n04423845', 'thimble'], '856': ['n04428191', 'thresher'], '857': ['n04429376', 'throne'], '858': ['n04435653', 'tile_roof'], '859': ['n04442312', 'toaster'], '860': ['n04443257', 'tobacco_shop'], '861': ['n04447861', 'toilet_seat'], '862': ['n04456115', 'torch'], '863': ['n04458633', 'totem_pole'], '864': ['n04461696', 'tow_truck'], '865': ['n04462240', 'toyshop'], '866': ['n04465501', 'tractor'], '867': ['n04467665', 'trailer_truck'], '868': ['n04476259', 'tray'], '869': ['n04479046', 'trench_coat'], '870': ['n04482393', 'tricycle'], '871': ['n04483307', 'trimaran'], '872': ['n04485082', 'tripod'], '873': ['n04486054', 'triumphal_arch'], '874': ['n04487081', 'trolleybus'], '875': ['n04487394', 'trombone'], '876': ['n04493381', 'tub'], '877': ['n04501370', 'turnstile'], '878': ['n04505470', 'typewriter_keyboard'], '879': ['n04507155', 'umbrella'], '880': ['n04509417', 'unicycle'], '881': ['n04515003', 'upright'], '882': ['n04517823', 'vacuum'], '883': ['n04522168', 'vase'], '884': ['n04523525', 'vault'], '885': ['n04525038', 'velvet'], '886': ['n04525305', 'vending_machine'], '887': ['n04532106', 'vestment'], '888': ['n04532670', 'viaduct'], '889': ['n04536866', 'violin'], '890': ['n04540053', 'volleyball'], '891': ['n04542943', 'waffle_iron'], '892': ['n04548280', 'wall_clock'], '893': ['n04548362', 'wallet'], '894': ['n04550184', 'wardrobe'], '895': ['n04552348', 'warplane'], '896': ['n04553703', 'washbasin'], '897': ['n04554684', 'washer'], '898': ['n04557648', 'water_bottle'], '899': ['n04560804', 'water_jug'], '900': ['n04562935', 'water_tower'], '901': ['n04579145', 'whiskey_jug'], '902': ['n04579432', 'whistle'], '903': ['n04584207', 'wig'], '904': ['n04589890', 'window_screen'], '905': ['n04590129', 'window_shade'], '906': ['n04591157', 'Windsor_tie'], '907': ['n04591713', 'wine_bottle'], '908': ['n04592741', 'wing'], '909': ['n04596742', 'wok'], '910': ['n04597913', 'wooden_spoon'], '911': ['n04599235', 'wool'], '912': ['n04604644', 'worm_fence'], '913': ['n04606251', 'wreck'], '914': ['n04612504', 'yawl'], '915': ['n04613696', 'yurt'], '916': ['n06359193', 'web_site'], '917': ['n06596364', 'comic_book'], '918': ['n06785654', 'crossword_puzzle'], '919': ['n06794110', 'street_sign'], '920': ['n06874185', 'traffic_light'], '921': ['n07248320', 'book_jacket'], '922': ['n07565083', 'menu'], '923': ['n07579787', 'plate'], '924': ['n07583066', 'guacamole'], '925': ['n07584110', 'consomme'], '926': ['n07590611', 'hot_pot'], '927': ['n07613480', 'trifle'], '928': ['n07614500', 'ice_cream'], '929': ['n07615774', 'ice_lolly'], '930': ['n07684084', 'French_loaf'], '931': ['n07693725', 'bagel'], '932': ['n07695742', 'pretzel'], '933': ['n07697313', 'cheeseburger'], '934': ['n07697537', 'hotdog'], '935': ['n07711569', 'mashed_potato'], '936': ['n07714571', 'head_cabbage'], '937': ['n07714990', 'broccoli'], '938': ['n07715103', 'cauliflower'], '939': ['n07716358', 'zucchini'], '940': ['n07716906', 'spaghetti_squash'], '941': ['n07717410', 'acorn_squash'], '942': ['n07717556', 'butternut_squash'], '943': ['n07718472', 'cucumber'], '944': ['n07718747', 'artichoke'], '945': ['n07720875', 'bell_pepper'], '946': ['n07730033', 'cardoon'], '947': ['n07734744', 'mushroom'], '948': ['n07742313', 'Granny_Smith'], '949': ['n07745940', 'strawberry'], '950': ['n07747607', 'orange'], '951': ['n07749582', 'lemon'], '952': ['n07753113', 'fig'], '953': ['n07753275', 'pineapple'], '954': ['n07753592', 'banana'], '955': ['n07754684', 'jackfruit'], '956': ['n07760859', 'custard_apple'], '957': ['n07768694', 'pomegranate'], '958': ['n07802026', 'hay'], '959': ['n07831146', 'carbonara'], '960': ['n07836838', 'chocolate_sauce'], '961': ['n07860988', 'dough'], '962': ['n07871810', 'meat_loaf'], '963': ['n07873807', 'pizza'], '964': ['n07875152', 'potpie'], '965': ['n07880968', 'burrito'], '966': ['n07892512', 'red_wine'], '967': ['n07920052', 'espresso'], '968': ['n07930864', 'cup'], '969': ['n07932039', 'eggnog'], '970': ['n09193705', 'alp'], '971': ['n09229709', 'bubble'], '972': ['n09246464', 'cliff'], '973': ['n09256479', 'coral_reef'], '974': ['n09288635', 'geyser'], '975': ['n09332890', 'lakeside'], '976': ['n09399592', 'promontory'], '977': ['n09421951', 'sandbar'], '978': ['n09428293', 'seashore'], '979': ['n09468604', 'valley'], '980': ['n09472597', 'volcano'], '981': ['n09835506', 'ballplayer'], '982': ['n10148035', 'groom'], '983': ['n10565667', 'scuba_diver'], '984': ['n11879895', 'rapeseed'], '985': ['n11939491', 'daisy'], '986': ['n12057211', \"yellow_lady's_slipper\"], '987': ['n12144580', 'corn'], '988': ['n12267677', 'acorn'], '989': ['n12620546', 'hip'], '990': ['n12768682', 'buckeye'], '991': ['n12985857', 'coral_fungus'], '992': ['n12998815', 'agaric'], '993': ['n13037406', 'gyromitra'], '994': ['n13040303', 'stinkhorn'], '995': ['n13044778', 'earthstar'], '996': ['n13052670', 'hen-of-the-woods'], '997': ['n13054560', 'bolete'], '998': ['n13133613', 'ear'], '999': ['n15075141', 'toilet_tissue']}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.utils as keras_utils\n",
    "import json\n",
    "\n",
    "ROOT=\"/home/ma-user/work\" # see !pwd\n",
    "os.system(\"mkdir -p {}/output\".format(ROOT))\n",
    "\n",
    "CLASS_INDEX = None\n",
    "CLASS_INDEX_PATH = ('https://storage.googleapis.com/download.tensorflow.org/'\n",
    "                    'data/imagenet_class_index.json')\n",
    "\n",
    "cache_dir=\"{}/output/imagenet\".format(ROOT)\n",
    "if not os.path.isdir(cache_dir):\n",
    "    os.mkdir(cache_dir)\n",
    "\n",
    "fpath = keras_utils.get_file(\n",
    "    'imagenet_class_index.json',\n",
    "    CLASS_INDEX_PATH,\n",
    "    cache_subdir=cache_dir,\n",
    "    file_hash='c2c37ea517e94d9795004a39431a14cb'\n",
    ")\n",
    "\n",
    "with open(fpath) as f:\n",
    "    CLASS_INDEX = json.load(f)\n",
    "    \n",
    "print(CLASS_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for decode predictions\n",
    "!cp ./output/imagenet/imagenet_class_index.json /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/keras_applications/\n",
    "# In some machines, you should use \"/opt/conda/envs/python36_tf/lib/python3.6/site-packages/keras_applications/\" instead. Check sys.executable inside python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model: DenseNet\n",
    "\n",
    "DenseNet作为特征提取层具有均衡的准确度和大小尺度。Keras团队的实现的benchmark可以支持这个观点：\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th align=\"right\">Size</th>\n",
    "<th align=\"right\">Top-1 Accuracy</th>\n",
    "<th align=\"right\">Top-5 Accuracy</th>\n",
    "<th align=\"right\">Parameters</th>\n",
    "<th align=\"right\">Depth</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><a href=\"#xception\">Xception</a></td>\n",
    "<td align=\"right\">88 MB</td>\n",
    "<td align=\"right\">0.790</td>\n",
    "<td align=\"right\">0.945</td>\n",
    "<td align=\"right\">22,910,480</td>\n",
    "<td align=\"right\">126</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#vgg16\">VGG16</a></td>\n",
    "<td align=\"right\">528 MB</td>\n",
    "<td align=\"right\">0.713</td>\n",
    "<td align=\"right\">0.901</td>\n",
    "<td align=\"right\">138,357,544</td>\n",
    "<td align=\"right\">23</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#vgg19\">VGG19</a></td>\n",
    "<td align=\"right\">549 MB</td>\n",
    "<td align=\"right\">0.713</td>\n",
    "<td align=\"right\">0.900</td>\n",
    "<td align=\"right\">143,667,240</td>\n",
    "<td align=\"right\">26</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet50</a></td>\n",
    "<td align=\"right\">98 MB</td>\n",
    "<td align=\"right\">0.749</td>\n",
    "<td align=\"right\">0.921</td>\n",
    "<td align=\"right\">25,636,712</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet101</a></td>\n",
    "<td align=\"right\">171 MB</td>\n",
    "<td align=\"right\">0.764</td>\n",
    "<td align=\"right\">0.928</td>\n",
    "<td align=\"right\">44,707,176</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet152</a></td>\n",
    "<td align=\"right\">232 MB</td>\n",
    "<td align=\"right\">0.766</td>\n",
    "<td align=\"right\">0.931</td>\n",
    "<td align=\"right\">60,419,944</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet50V2</a></td>\n",
    "<td align=\"right\">98 MB</td>\n",
    "<td align=\"right\">0.760</td>\n",
    "<td align=\"right\">0.930</td>\n",
    "<td align=\"right\">25,613,800</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet101V2</a></td>\n",
    "<td align=\"right\">171 MB</td>\n",
    "<td align=\"right\">0.772</td>\n",
    "<td align=\"right\">0.938</td>\n",
    "<td align=\"right\">44,675,560</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNet152V2</a></td>\n",
    "<td align=\"right\">232 MB</td>\n",
    "<td align=\"right\">0.780</td>\n",
    "<td align=\"right\">0.942</td>\n",
    "<td align=\"right\">60,380,648</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNeXt50</a></td>\n",
    "<td align=\"right\">96 MB</td>\n",
    "<td align=\"right\">0.777</td>\n",
    "<td align=\"right\">0.938</td>\n",
    "<td align=\"right\">25,097,128</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#resnet\">ResNeXt101</a></td>\n",
    "<td align=\"right\">170 MB</td>\n",
    "<td align=\"right\">0.787</td>\n",
    "<td align=\"right\">0.943</td>\n",
    "<td align=\"right\">44,315,560</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#inceptionv3\">InceptionV3</a></td>\n",
    "<td align=\"right\">92 MB</td>\n",
    "<td align=\"right\">0.779</td>\n",
    "<td align=\"right\">0.937</td>\n",
    "<td align=\"right\">23,851,784</td>\n",
    "<td align=\"right\">159</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#inceptionresnetv2\">InceptionResNetV2</a></td>\n",
    "<td align=\"right\">215 MB</td>\n",
    "<td align=\"right\">0.803</td>\n",
    "<td align=\"right\">0.953</td>\n",
    "<td align=\"right\">55,873,736</td>\n",
    "<td align=\"right\">572</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#mobilenet\">MobileNet</a></td>\n",
    "<td align=\"right\">16 MB</td>\n",
    "<td align=\"right\">0.704</td>\n",
    "<td align=\"right\">0.895</td>\n",
    "<td align=\"right\">4,253,864</td>\n",
    "<td align=\"right\">88</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#mobilenetv2\">MobileNetV2</a></td>\n",
    "<td align=\"right\">14 MB</td>\n",
    "<td align=\"right\">0.713</td>\n",
    "<td align=\"right\">0.901</td>\n",
    "<td align=\"right\">3,538,984</td>\n",
    "<td align=\"right\">88</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#densenet\">DenseNet121</a></td>\n",
    "<td align=\"right\">33 MB</td>\n",
    "<td align=\"right\">0.750</td>\n",
    "<td align=\"right\">0.923</td>\n",
    "<td align=\"right\">8,062,504</td>\n",
    "<td align=\"right\">121</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#densenet\">DenseNet169</a></td>\n",
    "<td align=\"right\">57 MB</td>\n",
    "<td align=\"right\">0.762</td>\n",
    "<td align=\"right\">0.932</td>\n",
    "<td align=\"right\">14,307,880</td>\n",
    "<td align=\"right\">169</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#densenet\">DenseNet201</a></td>\n",
    "<td align=\"right\">80 MB</td>\n",
    "<td align=\"right\">0.773</td>\n",
    "<td align=\"right\">0.936</td>\n",
    "<td align=\"right\">20,242,984</td>\n",
    "<td align=\"right\">201</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#nasnet\">NASNetMobile</a></td>\n",
    "<td align=\"right\">23 MB</td>\n",
    "<td align=\"right\">0.744</td>\n",
    "<td align=\"right\">0.919</td>\n",
    "<td align=\"right\">5,326,716</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><a href=\"#nasnet\">NASNetLarge</a></td>\n",
    "<td align=\"right\">343 MB</td>\n",
    "<td align=\"right\">0.825</td>\n",
    "<td align=\"right\">0.960</td>\n",
    "<td align=\"right\">88,949,818</td>\n",
    "<td align=\"right\">-</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "在上一期，我们通过调整一些感受野尺寸的，数据增强，预训练模型，以及通过增加新算子调整卷积块结构，获得了较强的vgg16模型。除了vgg16，imagenet还涌现了许多模型，但因为没有ROI提取功能，不适合多目标检测，还不是十分实用。现在我们将通过预训练使用它们进行组网，写新的模型YoloV3变种YoloV4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "53182464/53178568 [==============================] - 40s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# loading pretrained model\n",
    "from keras.applications.densenet import DenseNet169, preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# exclude fully connected layers\n",
    "base_model = DenseNet169(include_top=False, weights='imagenet', \n",
    "                         input_tensor=None, input_shape=(config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], config.IMAGE_SHAPE[2]), pooling='avg_pool', \n",
    "                         classes=config.NUM_CLASSES)\n",
    "\n",
    "def init_base_model(base_model):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return base_model\n",
    "        \n",
    "backbone = init_base_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 221, 221, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 227, 227, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 111, 111, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 111, 111, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 111, 111, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 113, 113, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1280) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 640)  819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 640)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 640)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 640)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 672)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 672)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 704)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 704)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 736)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 736)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 768)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 768)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 800)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 800)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 800)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 832)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 832)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 832)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 864)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 864)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 864)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 896)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 896)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 896)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 928)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 960)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 992)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 1024)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1024)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 1024)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 1056)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1056)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 1056)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 1088)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1088)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 1088)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 1120)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1120)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 1120)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1152)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1152)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 7, 7, 1152)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 7, 7, 1184)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 7, 7, 1216)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 7, 7, 1248)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 7, 7, 1280)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 7, 7, 1312)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 7, 7, 1344)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 7, 7, 1376)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 7, 7, 1408)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 7, 7, 1440)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 7, 7, 1472)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 7, 7, 1504)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 7, 7, 1536)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 7, 7, 1568)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 7, 7, 1600)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 12,642,880\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,642,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YoloV4 Architecture\n",
    "\n",
    "YoloV4和YoloV3相似。首先通过DarkNet获取3个尺度的特征。至于为什么没有使用FPN的bottom-up和top-down模组组网，是一个需要进一步研究的问题。初步猜测，YoloV3的主要优势还是在比较高的速度上，还获得接近其他模型的准确度，因此为了保持速度优势，没有加入FPN模组组网。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.merge.Concatenate object at 0x7fae12f08fd0>\n",
      "<keras.layers.merge.Concatenate object at 0x7fae07403dd8>\n",
      "<keras.layers.merge.Concatenate object at 0x7fae03a81860>\n"
     ]
    }
   ],
   "source": [
    "def extract_densenet169_residual_route(backbone):\n",
    "    \"\"\"\n",
    "    Keras denset169 implements 5 stages residual blocks (named as \"dense_block\"). Each residual blocks\n",
    "    correspond to sequence of [6, 12, 32, 32].\n",
    "    \n",
    "    The numbers of filters of each 2d convolution used for the internal simple residual block are fixed at 128 and 32 with 1x1 and 3x3\n",
    "    kernels in order.\n",
    "    \n",
    "    In this experiment, since we want to use parameters trained on imagenet, we use that simple residual block. However,\n",
    "    as you can figure out from my other implementation of residual block, we can promise you a better one.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    model_name = 'densenet169'\n",
    "    stage_tmpl = \"conv{}_block{}_concat\"\n",
    "    conv_repeated_series = [12, 32, 32]\n",
    "    for seq, conv_repeated in enumerate(conv_repeated_series):\n",
    "        blocks.append(backbone.get_layer(stage_tmpl.format(seq+3, conv_repeated)))\n",
    "    return blocks\n",
    "\n",
    "# Not let's check it\n",
    "blocks = extract_densenet169_residual_route(backbone)\n",
    "for block in blocks:\n",
    "    print(block)\n",
    "# We've done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://keras.io/activations/\n",
    "try:\n",
    "    from keras.layers.advanced_activations import LeakyReLU\n",
    "except:\n",
    "    from keras.layers import LeakyReLu\n",
    "import skimage.transform\n",
    "    \n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "def lr_schedule_callback(epoch):\n",
    "    lr = 1e-2\n",
    "    if epoch > 75:\n",
    "        lr = 5*1e-4\n",
    "    elif epoch > 100:\n",
    "        lr = 3*1e-4\n",
    "    return lr\n",
    "\n",
    "def Conv2DBlock(inp, filters, kernel_size=(3, 3), dropouts=None, conv_repeated=1, pooling=False, padding='same', stage=None):\n",
    "    name = 'conv%s_' % stage\n",
    "    out = inp\n",
    "    for i in range(conv_repeated):\n",
    "        conv = KL.Conv2D(filters, kernel_size, padding=padding, name=\"{}_conv2d{}\".format(name, i)) (out)\n",
    "        bn = BatchNorm(name=\"{}_bn{}\".format(name, i))(conv, training=True)\n",
    "        # using LeakyRelu with alpah equal to 0.1\n",
    "        act = KL.LeakyReLU(alpha=0.1, name=\"{}_act{}\".format(name, i))(bn)\n",
    "        if dropouts is not None and len(dropouts) > 0:\n",
    "            dropout = KL.Dropout(dropouts[i], name=\"{}_dp{}\".format(name, i))(act)\n",
    "        out = act\n",
    "    \n",
    "    if pooling:\n",
    "        pooled = KL.MaxPooling2D(pool_size=(2,2), name=\"{}_maxpooling2d{}\".format(name_stage))(out)\n",
    "        out = pooled\n",
    "    return out\n",
    "\n",
    "def Stack(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "def Conv2BBox(inp, filters, boxes_dim, stage):\n",
    "    conv = Stack(\n",
    "        Conv2DBlock(filters, (1,1), stage=stage+\"/1\"),\n",
    "        Conv2DBlock(filters*2, (3,3), stage=stage+\"/2\"),\n",
    "        Conv2DBlock(filters, (1,1), stage=stage+\"/3\"),\n",
    "        Conv2DBlock(filters*2, (3,3), stage=stage+\"/4\"),\n",
    "        Conv2DBlock(filters, (1,1), stage=stage+\"/5\")\n",
    "    )(inp)\n",
    "    out = Stack(\n",
    "        Conv2DBlock(filters*2,(3,3), stage=stage+\"/6\"),\n",
    "        KL.Conv2D(boxes_dim, (1,1), name=\"conv{}_conv2d{}\".format(stage+\"/7\", 0))\n",
    "    )(conv)\n",
    "    return conv, out\n",
    "\n",
    "def UpSampling_BilinearInterpolation(inp, factor):\n",
    "    return KL.Lambda(lambda featmap: skimage.transform.rescale(featmap, \n",
    "                                                               factor, \n",
    "                                                               mode='constant', cval=0, order=1))(inp)\n",
    "\n",
    "# also see implementation for other models in SpatialDetectron\n",
    "class YoloV4(object):\n",
    "    \n",
    "    def __init__(self, mode, config, model_dir,\n",
    "                 backbone=None):\n",
    "        self.mode = mode\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.backbone = backbone\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        self.scales = 3\n",
    "        # Here we use customer loss\n",
    "        self.loss = None\n",
    "        self.model = self.get_model(mode=self.mode, backbone=self.backbone)\n",
    "        \n",
    "    def get_model(self, mode, backbone):\n",
    "        # Darknet feature pyramid\n",
    "        if backbone is None:\n",
    "            base_model = DenseNet169(include_top=False, weights='imagenet', \n",
    "                         input_tensor=None, input_shape=(config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], config.IMAGE_SHAPE[2]), pooling='avg_pool', \n",
    "                         classes=config.NUM_CLASSES)\n",
    "            backbone = init_base_model(base_model)\n",
    "            blocks = extract_densenet169_residual_route(backbone)\n",
    "        \n",
    "        self.inputs = backbone.inputs\n",
    "        H, W, CHANNELS = config.IMAGE_SHAPE\n",
    "        self.outputs = []\n",
    "        self.gt_per_grid = 3\n",
    "        \n",
    "        # YoloV4 Detectron Body\n",
    "        # make bolcks in reverse order\n",
    "        blocks = blocks[::-1]\n",
    "        # the darknet output for small objects\n",
    "        x = blocks[0]\n",
    "        boxes_dim = self.gt_per_grid * (config.NUM_CLASSES+5)\n",
    "        filters = [512, 256, 128]\n",
    "        self.featmaps = []\n",
    "        for i, block in enumerate(blocks):\n",
    "            if i > 0:\n",
    "                x = Conv2DBlock(filters[i], (1,1), stage=i+\"/0\")\n",
    "                x = UpSampling_BilinearInterpolation(x, 2)\n",
    "                x = Cancatenate([x, block])\n",
    "                \n",
    "            x, out = Conv2BBox(x, filters[i], boxes_dim, stage=i)\n",
    "            self.featmaps.append(out)\n",
    "        \n",
    "        # YoloV3 Losses: the key part of the detectron\n",
    "        scales = [32, 16, 8]\n",
    "        y_true = [KL.Input(shape=(int(H/scales[scale_idx]), int(W/scales[scale_idx]), self.gt_per_grid/3, config.NUM_CLASSES+5)) for scale_idx in range(self.scales)]\n",
    "        loss = KL.Lambda(self.loss, output_shape=(1,), name=\"yolo_loss\")(feat_map, y_true)\n",
    "        self._loss = loss\n",
    "        \n",
    "        # Model\n",
    "        model = KM.Model([self.inputs[0], *y_true], loss)\n",
    "        return model\n",
    "    \n",
    "    # TODO\n",
    "    def loss(self, featmaps, y_true):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_data, train_labels, optimizer_type='rmsprop', data_augumented=True):\n",
    "        model = self.model\n",
    "        # Initate optimizer\n",
    "        if optimizer_type is 'rmsprop':\n",
    "            optimizer = RMSprop(lr=1e-2, decay=1e-6)\n",
    "        else:\n",
    "            optimizer = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "        # compile the program\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # early stopping策略\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') \n",
    "        history = LossHistory()\n",
    "        \n",
    "        filepath=\"{}/weights.best.checkpoint.hdf5\".format(self.model_dir)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        \n",
    "        learning_rate_schedule = LearningRateScheduler(lr_schedule_callback)\n",
    "        \n",
    "        # data augumentation\n",
    "        # adapted from https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "            width_shift_range=0.1,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split=0.25)\n",
    "        \n",
    "        # begin to train\n",
    "        if not data_augumented:\n",
    "            model.fit(\n",
    "                train_data,\n",
    "                train_label,\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                epochs=self.config.EPOCHES,\n",
    "                validation_split=0.25, # 训练数据中，抽取25%的数据作为验证数据\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                callbacks=[history, early_stopping, checkpoint, learning_rate_schedule])\n",
    "        else:\n",
    "            # 特征正则处理\n",
    "            datagen.fit(train_data)\n",
    "            # 训练\n",
    "            train_reader = datagen.flow(train_data, train_label, batch_size=self.config.BATCH_SIZE, subset='training')\n",
    "            val_reader = datagen.flow(train_data, train_label, batch_size=self.config.BATCH_SIZE, subset='validation')\n",
    "            \n",
    "            model.fit_generator(train_reader,\n",
    "                                validation_data=val_reader,\n",
    "                                epochs=self.config.EPOCHES,\n",
    "                                workers=8,\n",
    "                                verbose=2,\n",
    "                                callbacks=[history, checkpoint])\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def load_weights(self, weights=None):\n",
    "        if weights is None:\n",
    "            filepath=\"{}/weights.best.checkpoint.hdf5\".format(self.model_dir)\n",
    "        else:\n",
    "            filepath=weights\n",
    "            \n",
    "        if os.path.isfile(filepath):\n",
    "            model = self.model\n",
    "            model.load_weights(filepath)\n",
    "        else:\n",
    "            print(\"{} does not exit!\".format(filepath))\n",
    "    \n",
    "    def infer(self, imgs, verbose=0):\n",
    "        model = self.model\n",
    "        results = model.predict(imgs, verbose=verbose)\n",
    "        return results\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "    \n",
    "    def get_layers(self):\n",
    "        return self.model.layers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.8",
   "language": "python",
   "name": "tensorflow-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
